{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.example_selectors import MaxMarginalRelevanceExampleSelector\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from ollama import Client\n",
    "import json\n",
    "import subprocess\n",
    "import time\n",
    "import ipaddress\n",
    "\n",
    "from datetime import datetime\n",
    "import shlex\n",
    "import math\n",
    "from typing import Optional, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONOS Controller Details\n",
    "ONOS_BASE_URL = \"http://10.23.7.63:8182/onos/v1/flows\" #use localhost ip if needed and use correct ONOS port number\n",
    "USERNAME = \"onos\"\n",
    "PASSWORD = \"rocks\"  # Replace with your ONOS credentials\n",
    "ONOS_API_ROOT = ONOS_BASE_URL.rsplit(\"/flows\", 1)[0]\n",
    "\n",
    "# Define sudo password\n",
    "sudo_password = \"password\" #your localhost password\n",
    "\n",
    "ip_to_host = {\n",
    "    \"10.0.1.1\": \"h1onos\",\n",
    "    \"10.0.1.2\": \"h2onos\",\n",
    "    \"10.0.1.3\": \"h3onos\",\n",
    "    \"10.0.1.4\": \"h4onos\"\n",
    "            }\n",
    "\n",
    "host_to_ip = {\n",
    "    \"h1\": \"10.0.1.1\",\n",
    "    \"h2\": \"10.0.1.2\",\n",
    "    \"h3\": \"10.0.1.3\",\n",
    "    \"h4\": \"10.0.1.4\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "switch_id_for_llm_assurance = None\n",
    "llm_caller_flag = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_flow_rule_ONOS(device_id, flow_id):\n",
    "    \"\"\"\n",
    "    Delete a specific flow rule from an ONOS device by device_id and flow_id.\n",
    "    \n",
    "    Parameters:\n",
    "        device_id (str): The ONOS switch ID (e.g., \"of:0000000000000002\").\n",
    "        flow_id (str or int): The ONOS flow rule ID (as returned from push or get).\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if deleted successfully, False otherwise.\n",
    "    \"\"\"\n",
    "    url = f\"{ONOS_BASE_URL}/{device_id}/{flow_id}\"\n",
    "    headers = {\n",
    "        \"Accept\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.delete(url, auth=(USERNAME, PASSWORD), headers=headers)\n",
    "        if response.status_code in [200, 204]:\n",
    "            print(f\"Successfully deleted flow rule from ONOS (Device ID: {device_id}, Flow ID: {flow_id})\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Failed to delete flow rule. Status Code: {response.status_code}, Response: {response.text}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred while deleting flow rule: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def get_flows_for_device_ONOS(device_id):\n",
    "    \"\"\"\n",
    "    Retrieve all flows for a specific ONOS device (switch).\n",
    "    \n",
    "    Parameters:\n",
    "        device_id (str): The ONOS switch ID (e.g., \"of:0000000000000002\").\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of flow JSON objects for the given switch.\n",
    "    \"\"\"\n",
    "    url = f\"{ONOS_BASE_URL}/{device_id}\"\n",
    "    headers = {\"Accept\": \"application/json\"}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, auth=(USERNAME, PASSWORD), headers=headers)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        data = response.json()\n",
    "        return data.get(\"flows\", [])\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching flows for device {device_id}:\", e)\n",
    "        return []\n",
    "\n",
    "def extract_switch_id_ONOS(intent: str):\n",
    "    \"\"\"\n",
    "    Extract the switch ID from a natural language intent for ONOS JSON format.\n",
    "    \n",
    "    Parameters:\n",
    "        intent (str): The natural language intent.\n",
    "    \n",
    "    Returns:\n",
    "        str: Extracted switch ID (e.g., 'of:0000000000000001') or None if not found.\n",
    "    \"\"\"\n",
    "    # Mapping of ordinal words to numeric values\n",
    "    ordinals = {\n",
    "        \"first\": 1,\n",
    "        \"second\": 2,\n",
    "        \"third\": 3,\n",
    "        \"fourth\": 4,\n",
    "        \"fifth\": 5,\n",
    "        \"sixth\": 6,\n",
    "        \"seventh\": 7,\n",
    "        \"eighth\": 8,\n",
    "        \"ninth\": 9,\n",
    "        \"tenth\": 10\n",
    "    }\n",
    "\n",
    "    # Match patterns like 'switch 1', 'router 2', 'node 3'\n",
    "    match = re.search(r'\\b(?:switch|router|node|device)(?:\\s*number)?\\s*(\\d+)', intent, re.IGNORECASE)\n",
    "    if match:\n",
    "        switch_number = int(match.group(1))\n",
    "        return f\"of:{switch_number:016x}\"  # Convert to ONOS 16-digit hex format\n",
    "\n",
    "    # Match ordinal words (e.g., 'fourth switch', 'second router')\n",
    "    match = re.search(r'\\b(?:switch|router|node|device)\\s*(\\w+)', intent, re.IGNORECASE)\n",
    "    if match:\n",
    "        ordinal_word = match.group(1).lower()\n",
    "        if ordinal_word in ordinals:\n",
    "            switch_number = ordinals[ordinal_word]\n",
    "            return f\"of:{switch_number:016x}\"  # Convert to ONOS 16-digit hex format\n",
    "\n",
    "    # Match standalone ordinal words (e.g., 'fourth' without 'switch')\n",
    "    for word, number in ordinals.items():\n",
    "        if word in intent.lower():\n",
    "            return f\"of:{number:016x}\"  # Convert to ONOS 16-digit hex format\n",
    "\n",
    "    return None\n",
    "\n",
    "def push_flow_rule(device_id, flow_json):\n",
    "    \"\"\"\n",
    "    Push a flow rule to ONOS and retrieve the flow ID.\n",
    "    \"\"\"\n",
    "    url = f\"{ONOS_BASE_URL}\"\n",
    "    HEADERS = { \n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Accept\": \"application/json\"\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, headers=HEADERS, auth=(USERNAME, PASSWORD), data=json.dumps(flow_json))\n",
    "        if response.status_code in [200, 201]:\n",
    "            response_data = response.json()\n",
    "            if \"flows\" in response_data and len(response_data[\"flows\"]) > 0:\n",
    "                flow_id = response_data[\"flows\"][0].get(\"flowId\")\n",
    "                print(f\"Successfully pushed flow rule to ONOS (Device ID: {device_id}, Flow ID: {flow_id})\")\n",
    "                return flow_id  # Return the flow ID for later verification\n",
    "            else:\n",
    "                print(\"Flow rule pushed but no Flow ID returned by ONOS.\")\n",
    "                return None\n",
    "        else:\n",
    "            print(f\"Failed to push flow rule to ONOS. Status Code: {response.status_code}, Response: {response.text}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred while pushing flow rule: {e}\")\n",
    "        return None\n",
    "    \n",
    "def verify_flow_rule(device_id, flow_id):\n",
    "    \"\"\"\n",
    "    Verify if the flow rule exists in ONOS using the retrieved Flow ID.\n",
    "    \"\"\"\n",
    "    if not flow_id:\n",
    "        print(\"\\nInvalid Flow ID provided for verification. Check ONOS response after rule posting.\\n\")\n",
    "        return False, None\n",
    "\n",
    "    url = f\"{ONOS_BASE_URL}/{device_id}\"\n",
    "    HEADERS = {\"Accept\": \"application/json\"}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS, auth=(USERNAME, PASSWORD))\n",
    "        if response.status_code == 200:\n",
    "            flows = response.json().get(\"flows\", [])\n",
    "            for flow in flows:\n",
    "                if flow.get(\"id\") == flow_id:\n",
    "                    #print(f\"Flow rule exists in ONOS (Flow ID: {flow_id})\")\n",
    "                    return True, flow\n",
    "            print(f\"Flow rule NOT found in ONOS (Flow ID: {flow_id})\")\n",
    "            return False, None\n",
    "        else:\n",
    "            print(f\"Failed to query ONOS. Status Code: {response.status_code}, Response: {response.text}\")\n",
    "            return False, None\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred while verifying flow rule: {e}\")\n",
    "        return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSLATION_PROMPT_ONOS = \"\"\"Your task is to transform natural language network intents into JSON-formatted network policies compatible with the ONOS SDN controller.\n",
    "\n",
    "You only reply in JSON, no natural language. The network intents can represent different traffic control behaviors, such as:\n",
    "\n",
    "1. **Traffic Forwarding, Queue Assignment, and VLAN Rules:** Define rules for forwarding traffic based on IPv4/IPv6 destination, TCP/UDP ports, and optionally assign traffic to specific queues or vlans.\n",
    "2. **Blocking or Dropping Rule:** Define rules to drop traffic based on specific match criteria (e.g., source IP, destination IP). In ONOS, this is done by omitting the `\"treatment\"` field.\n",
    "\n",
    "### **JSON STRUCTUREs FOR ONOS**\n",
    "\n",
    "1. **Traffic Forwarding, Queue Assignment, and VLAN Rules:**  \n",
    "\n",
    "```json\n",
    "{\n",
    "    \"flows\": [\n",
    "        {\n",
    "            \"priority\": <integer>,\n",
    "            \"timeout\": <integer>, // Default: 0\n",
    "            \"isPermanent\": \"true\",\n",
    "            \"deviceId\": \"<switch_id>\",\n",
    "            \"treatment\": {\n",
    "                \"instructions\": [\n",
    "                    {\n",
    "                        \"type\": \"QUEUE\",\n",
    "                        \"queueId\": <integer>\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"L2MODIFICATION\",\n",
    "                        \"subtype\": \"VLAN_ID\",\n",
    "                        \"vlanId\": <integer> // Example: 100 for VLAN tagging\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"OUTPUT\",\n",
    "                        \"port\": \"<integer>\"\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            \"selector\": {\n",
    "                \"criteria\": [\n",
    "                    {\n",
    "                        \"type\": \"ETH_TYPE\",\n",
    "                        \"ethType\": \"<string>\" // Example: \"0x800\" for IPv4\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"IPV4_SRC\",\n",
    "                        \"ip\": \"<ip_address/mask>\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"IPV4_DST\",\n",
    "                        \"ip\": \"<ip_address/mask>\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"IP_PROTO\",\n",
    "                        \"protocol\": <integer> // Example: 6 for TCP, 17 for UDP\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"TCP_DST\",\n",
    "                        \"tcpPort\": <integer>\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"UDP_DST\",\n",
    "                        \"udpPort\": <integer>\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"IN_PORT\",\n",
    "                        \"port\": \"<integer>\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "2. **Blocking or Dropping Rule:**\n",
    "\n",
    "{\n",
    "    \"flows\": [\n",
    "        {\n",
    "            \"priority\": <integer>,\n",
    "            \"timeout\": 0,\n",
    "            \"isPermanent\": \"true\",\n",
    "            \"deviceId\": \"<switch_id>\",\n",
    "            \"selector\": {\n",
    "                \"criteria\": [\n",
    "                    {\n",
    "                        \"type\": \"ETH_TYPE\",\n",
    "                        \"ethType\": \"<string>\" // Example: \"0x800\" for IPv4\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"IPV4_SRC\",\n",
    "                        \"ip\": \"<ip_address/mask>\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"IPV4_DST\",\n",
    "                        \"ip\": \"<ip_address/mask>\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "Field Descriptions\n",
    "priority (Mandatory): Priority level (higher numbers indicate higher priority). For Queue, Blocking or firewall rules, assign a priority greater than 40000.\n",
    "timeout (Mandatory): Timeout in seconds after which the flow is removed (Default: 0).\n",
    "isPermanent (Mandatory): \"true\" (always in quotes, per user preference).\n",
    "deviceId (Mandatory): Switch ID where the rule is installed.\n",
    "ethType (Mandatory): Ethernet protocol type. Use \"0x800\" for IPv4, \"0x86DD\" for IPv6, \"0x806\" for ARP.\n",
    "IPV4_DST (Optional): IPv4 address in CIDR notation (e.g., \"10.0.0.1/32\"). Include only if explicitly mentioned.\n",
    "IPV4_SRC (Optional): Source IP address (include only if explicitly mentioned).\n",
    "IP_PROTO (Optional): Transport layer protocol (6 for TCP, 17 for UDP, 1 for ICMP).\n",
    "TCP_DST (Optional): TCP destination port (e.g., 80 for HTTP).\n",
    "UDP_DST (Optional): UDP destination port (e.g., 161 for SNMP).\n",
    "IN_PORT (Optional): Incoming interface port number (use in port-based forwarding).\n",
    "QUEUE (Optional): Use \"QUEUE\" with \"queueId\" to specify a QoS queue (queue ID is an integer, 0 is default).\n",
    "OUTPUT (Optional): \"OUTPUT\" with \"port\" specifies the output port.\n",
    "VLAN_ID (Optional): Use \"L2MODIFICATION\" with \"subtype\": \"VLAN_ID\" and \"vlanId\" to set a VLAN tag.\n",
    "\n",
    "Rules for Translation\n",
    "Each \"priority\" must be unique.\n",
    "Set priority very high (e.g., 40000) for queue and security related rules.\n",
    "Do not include VLAN-related fields unless explicitly mentioned in the intent.\n",
    "Do not include optional fields unless explicitly mentioned in the intent.\n",
    "Ensure valid ONOS-compliant JSON syntax.\n",
    "Verify JSON structure before responding.\n",
    "Always respond in valid JSON format only, without comments, explanations, or additional text.\n",
    "If the intent cannot be mapped, return an empty JSON object {}.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFLICT_PROMPT_ONOS = \"\"\"You are tasked with determining if two ONOS flow configuration JSONs directly conflict with each other. **You MUST base your decision SOLELY on the JSON content provided.** Do **NOT** infer intent, use semantic reasoning, or make assumptions beyond the given JSON structure.\n",
    "\n",
    "---\n",
    "\n",
    "### **Rules for Conflict Detection (STRICT and LITERAL COMPARISON):**\n",
    "\n",
    "A **direct conflict** exists **ONLY IF** all the following conditions are met:\n",
    "\n",
    "#### **1. Matching Traffic Characteristics (Exact or Overlapping Match Criteria)**\n",
    "Both flows must match **overlapping traffic characteristics** for all the specified fields, meaning they could apply to the **exact same packets**. The following fields are checked:\n",
    "\n",
    "**EtherType (`ETH_TYPE`)**  \n",
    "   - Must be present in **both** flows and have **identical** values (e.g., `\"0x800\"` for IPv4, `\"0x86DD\"` for IPv6).\n",
    "   - If missing in either flow, there is **no match**.\n",
    "\n",
    "**Source and Destination IP (`IPV4_SRC` and `IPV4_DST`)**  \n",
    "   - If both flows **specify** a source or destination, they must overlap (e.g., `\"10.0.0.1/32\"` and `\"10.0.0.0/24\"` overlap).\n",
    "   - If **either** flow **omits** source or destination, it applies to **all** sources or destinations respectively.\n",
    "\n",
    "**Protocol (`IP_PROTO`)**  \n",
    "   - Must be present in **both** flows and have **identical** values (e.g., `6` for TCP, `17` for UDP).\n",
    "   - If missing in either flow, there is **no match**.\n",
    "\n",
    "**Transport Layer Ports (`TCP_SRC`, `TCP_DST`, `UDP_SRC`, `UDP_DST`)**  \n",
    "   - Must be **identical** in both flows if present.\n",
    "   - If one flow includes a port filter and the other does not, there is **no match**.\n",
    "\n",
    "**Incoming Port (`IN_PORT`)**  \n",
    "   - If both flows specify `IN_PORT`, they must be identical.\n",
    "   - If missing in either flow, there is **no match**.\n",
    "\n",
    "**Wildcard Matching (Implicit Behavior for Missing Fields)**  \n",
    "   - If a flow **specifies a field** (e.g., `IPV4_SRC`), it applies **only** to that source.\n",
    "   - If a flow **does not specify a field** (e.g., `IPV4_SRC`), it applies to **all sources**.\n",
    "   - General vs. specific distinctions are not classified, but missing fields imply generality (i.e., match all). Conflicts are determined based on whether the two match sets could overlap.\n",
    "---\n",
    "\n",
    "#### **2. Contradictory Actions**\n",
    "Flows that **match the same traffic** only conflict if their actions contradict in one of the following ways:\n",
    "\n",
    "**Different Output Ports (`OUTPUT` instruction)**  \n",
    "   - If one flow **forwards** traffic to port `X` and another to port `Y`, it is a **conflict**.\n",
    "\n",
    "**One Flow Drops, One Flow Forwards**  \n",
    "   - If one flow **omits `\"treatment\"`** (implying a drop) and another **forwards traffic**, it is a **conflict**.\n",
    "\n",
    "**Different Queue Assignments (`QUEUE` instruction)**  \n",
    "   - If the flows **assign different `queueId` values**, it is a **conflict**.\n",
    "\n",
    "**Note on Additional Match Fields:**  \n",
    "   - If one flow includes additional match fields, a conflict may still exist if the effective match space overlaps. Extra fields do not automatically prevent a conflict.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Priority is Irrelevant for Conflict Detection**\n",
    "- `priority` **does not** determine a conflict.\n",
    "- Even if one rule **overrides** another, they **do not conflict** unless their actions contradict.\n",
    "\n",
    "---\n",
    "\n",
    "### **Input Format**\n",
    "You will be provided with **two ONOS JSON flow rules** in the following format:\n",
    "\n",
    "**Flow 1:**\n",
    "```json\n",
    "<JSON for Flow 1>\n",
    "\n",
    "**Flow 2:**\n",
    "<JSON for Flow 2>\n",
    "\n",
    "### **Expected Output Format**\n",
    "Respond strictly in valid JSON format, using the schema below:\n",
    "\n",
    "{\n",
    "    \"conflict_status\": <integer>,\n",
    "    \"conflict_explanation\": \"<conflict explanation, if any>\"\n",
    "}\n",
    "\n",
    "Field Descriptions:\n",
    "   - conflict_status should be 1 if a direct conflict exists, 0 otherwise.\n",
    "   - conflict_explanation → A brief explanation if a conflict exists, otherwise an empty string \"\".\n",
    "\n",
    "NO EXTRA TEXT, COMMENTS, OR EXPLANATIONS OUTSIDE JSON.\n",
    "DO NOT return 1 unless you are certain of a direct conflict.\n",
    "Follow strict field-by-field comparison rules—NO inference beyond given data.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLICING_PROMPT = \"\"\"You are tasked with analyzing a natural language intent to determine if it contains a command to create or use a queue/slice in an OpenFlow switch. You should respond in JSON format.\n",
    "\n",
    "### Rules for Interpretation:\n",
    "1. **Queue/Slice Detection:**  \n",
    "   - The intent is considered related to queue/slice if it contains commands such as:\n",
    "     - \"create queue\", \"create slices\", \"slice the network\", \"implement slicing\", \"slice the flow\", \"make flowspace slicing\", \"do slicing\", \"slice\", \"implement queue\", \"do queuing\", \"assign queue\", \"assign slice\", or any similar phrasing.\n",
    "   - If the intent does not mention creating or using a queue/slice, set the field `\"use_queue\"` to `0`.\n",
    "\n",
    "2. **Switch, Queue, and Port Identification (Data-plane port/interface):**  \n",
    "   - If the intent specifies a **switch ID** (e.g., \"switch 4\" or \"openflow:4\" or \"node 4\" or \"openflow 4\"), populate the `\"switch_id\"` field with its value.  \n",
    "   - If the intent specifies a **Queue ID or slice ID** (e.g., \"queue 4\" or \"4th queue\" or \"fourth queue\" or \"slice 1\" or \"first slice\"), populate the `\"queue_id\"` field with its value.  \n",
    "   - If the intent specifies a **port ID** referring to the device interface/output (e.g., \"port 2\" or \"interface 2\" or \"ethernet 2\" or \"output node connector 2\" or \"second port\" or \"second interface\"), populate the `\"port_id\"` field with its value. If there are multiple instances of \"port_id\" present, take the one which indicates the **output port or outgoing interface**.\n",
    "   - If the intent does not specify a switch ID or queue ID or port ID, set the respective field to an empty string (`\"\"`).\n",
    "\n",
    "3. **Traffic Type and L4 Destination Port Extraction (Protocol/Service):**\n",
    "   - Detect the **Layer-4 protocol** if mentioned: `\"tcp\"` or `\"udp\"`. Populate this in `\"traffic_type\"`. If not specified, set `\"traffic_type\"` to `\"\"`.\n",
    "   - Detect the **destination application port number** (Layer-4 port), if specified as a number (e.g., \"port 80\", \"UDP port 53\") or implied via a service reference such as \"HTTP (TCP port 80)\". Populate this number (as a string) in `\"l4_port\"`.  \n",
    "   - Do **not** confuse the L4 port (e.g., 80/53) with the device/interface port (e.g., switch port 2). The former goes to `\"l4_port\"`, the latter to `\"port_id\"`.\n",
    "   - If multiple L4 ports are mentioned, prefer the **destination/service port** used by the traffic selector (e.g., \"traffic destined for port 80\"). If still ambiguous, choose the first explicit destination/service port mentioned.\n",
    "   - If the L4 destination port is not specified, set `\"l4_port\"` to `\"\"`.\n",
    "\n",
    "4. **Output Format:**  \n",
    "   - Respond strictly in valid JSON format adhering to the following schema:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"use_queue\": <integer>,\n",
    "  \"switch_id\": \"<string>\",\n",
    "  \"queue_id\": \"<string>\",\n",
    "  \"port_id\": \"<string>\",\n",
    "  \"traffic_type\": \"<string>\",\n",
    "  \"l4_port\": \"<string>\"\n",
    "}\n",
    "\n",
    "Field Description:\n",
    "use_queue: 1 if the intent commands to create or use a queue/slice, 0 otherwise.\n",
    "switch_id: Switch ID if specified in the intent, otherwise \"\".\n",
    "queue_id: Queue/Slice ID if specified in the intent, otherwise \"\".\n",
    "port_id: Device/interface port if specified (output/outgoing preferred), otherwise \"\".\n",
    "traffic_type: \"tcp\" or \"udp\" if specified, otherwise \"\".\n",
    "l4_port: Destination application port number (e.g., \"80\", \"53\") if specified, otherwise \"\".\n",
    "\n",
    "No Additional Text:\n",
    "Do not include any comments, explanations, or outputs outside the JSON format.\n",
    "\n",
    "Example Inputs and Outputs:\n",
    "\n",
    "Input Intent:\n",
    "\"Create a queue in switch 4 on port 3 for slicing the flow.\"\n",
    "Output:\n",
    "{\n",
    "\"use_queue\": 1,\n",
    "\"switch_id\": \"switch 4\",\n",
    "\"queue_id\": \"\",\n",
    "\"port_id\": \"port 3\",\n",
    "\"traffic_type\": \"\",\n",
    "\"l4_port\": \"\"\n",
    "}\n",
    "\n",
    "Input Intent:\n",
    "\"Send all video traffic through queue 0 of openflow:2.\"\n",
    "Output:\n",
    "{\n",
    "\"use_queue\": 1,\n",
    "\"switch_id\": \"openflow 2\",\n",
    "\"queue_id\": \"0\",\n",
    "\"port_id\": \"\",\n",
    "\"traffic_type\": \"\",\n",
    "\"l4_port\": \"\"\n",
    "}\n",
    "\n",
    "Input Intent:\n",
    "\"Configure switch 5 for traffic management.\"\n",
    "Output:\n",
    "{\n",
    "\"use_queue\": 0,\n",
    "\"switch_id\": \"switch 5\",\n",
    "\"queue_id\": \"\",\n",
    "\"port_id\": \"\",\n",
    "\"traffic_type\": \"\",\n",
    "\"l4_port\": \"\"\n",
    "}\n",
    "\n",
    "Input Intent:\n",
    "\"Monitor traffic flow on port 1.\"\n",
    "Output:\n",
    "{\n",
    "\"use_queue\": 0,\n",
    "\"switch_id\": \"\",\n",
    "\"queue_id\": \"\",\n",
    "\"port_id\": \"port 1\",\n",
    "\"traffic_type\": \"\",\n",
    "\"l4_port\": \"\"\n",
    "}\n",
    "\n",
    "Input Intent:\n",
    "\"In switch 3, if the incoming traffic in port 1 is TCP traffic destined for port 80, then pass it via interface 2, assigning it to queue 0 for prioritized handling.\"\n",
    "Output:\n",
    "{\n",
    "\"use_queue\": 1,\n",
    "\"switch_id\": \"switch 3\",\n",
    "\"queue_id\": \"0\",\n",
    "\"port_id\": \"interface 2\",\n",
    "\"traffic_type\": \"tcp\",\n",
    "\"l4_port\": \"80\"\n",
    "}\n",
    "\n",
    "Input Intent:\n",
    "\"For node 1, route HTTP (TCP port 80) traffic targeting 10.0.0.3/32 through port 2 with traffic assigned to queue 0.\"\n",
    "Output:\n",
    "{\n",
    "\"use_queue\": 1,\n",
    "\"switch_id\": \"node 1\",\n",
    "\"queue_id\": \"0\",\n",
    "\"port_id\": \"port 2\",\n",
    "\"traffic_type\": \"tcp\",\n",
    "\"l4_port\": \"80\"\n",
    "}\n",
    "\n",
    "Input Intent:\n",
    "\"Forward UDP traffic on port 53 destined for 10.0.0.9 via interface 5 of switch 2, assigning it to queue 3.\"\n",
    "Output:\n",
    "{\n",
    "\"use_queue\": 1,\n",
    "\"switch_id\": \"switch 2\",\n",
    "\"queue_id\": \"3\",\n",
    "\"port_id\": \"interface 5\",\n",
    "\"traffic_type\": \"udp\",\n",
    "\"l4_port\": \"53\"\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_models_translate_real = [\n",
    "\"codestral\",\n",
    "\"command-r\",\n",
    "\"huihui_ai/qwq-abliterated\"\n",
    "]\n",
    "\n",
    "my_models_conflict_real = [\n",
    "\"huihui_ai/qwq-fusion\",\n",
    "\"qwq\"\n",
    "]\n",
    "\n",
    "context_examples = [3, 6]\n",
    "\n",
    "default_model = \"llama2\"\n",
    "\n",
    "ollama_embedding_url = \"http://10.23.7.63:11434\"\n",
    "ollama_server_url = \"http://10.23.7.63:11435\"  \n",
    "\n",
    "ollama_emb = OllamaEmbeddings(\n",
    "    model=default_model,\n",
    "    base_url=ollama_embedding_url,\n",
    ")\n",
    "\n",
    "client = Client(host=ollama_server_url , timeout=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load custom dataset from CSV\n",
    "custom_dataset = pd.read_csv('ONOS_intent_translation_dataset_for_LLM_Evaluation.csv')\n",
    "\n",
    "# Ensure proper column names and format\n",
    "if not {'instruction', 'output'}.issubset(custom_dataset.columns):\n",
    "    raise ValueError(\"The dataset must have 'instruction' and 'output' columns.\")\n",
    "\n",
    "# Split into train and test (50/50 split for example)\n",
    "#trainset, testset = train_test_split(custom_dataset, test_size=0.5, random_state=42, shuffle=True)\n",
    "trainset = custom_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_intent_to_store(\n",
    "    file_path,\n",
    "    nl_intent,\n",
    "    json_flow_rule,\n",
    "    device_id,\n",
    "    flow_id,\n",
    "    intent_type,\n",
    "    intent_specificity\n",
    "):\n",
    "    \"\"\"\n",
    "    Appends an intent record to the IntentStore file in JSONL format.\n",
    "    \"\"\"\n",
    "    record = {\n",
    "        \"nl_intent\": nl_intent,\n",
    "        \"json_flow_rule\": json_flow_rule,\n",
    "        \"device_id\": device_id,\n",
    "        \"flow_id\": flow_id,\n",
    "        \"intent_type\": intent_type,\n",
    "        \"intent_specificity\": intent_specificity\n",
    "    }\n",
    "    with open(file_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(record) + \"\\n\")\n",
    "\n",
    "def read_intents_from_store(file_path):\n",
    "    \"\"\"\n",
    "    Yields each intent record from the IntentStore file.\n",
    "    \"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            intent = json.loads(line)\n",
    "            yield intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_LLM_conflict(existing_intent_flow_json, new_intent_flow_json):\n",
    "    system_prompt = CONFLICT_PROMPT_ONOS\n",
    "\n",
    "    for model in my_models_conflict_real:\n",
    "        count = 0\n",
    "        while True:\n",
    "            count+=1\n",
    "            try:\n",
    "                time.sleep(0.1)\n",
    "\n",
    "                response = client.generate(model=model,\n",
    "                    options={'temperature': 0.3, 'num_ctx': 8192, 'top_p': 0.5, 'num_predict': 1024, 'num_gpu': 99},\n",
    "                    stream=False,\n",
    "                    system=system_prompt,\n",
    "                    prompt=f\"Flow 1:\\n{json.dumps(existing_intent_flow_json, indent=2)}\\n\\nFlow 2:\\n{json.dumps(new_intent_flow_json, indent=2)}\",\n",
    "                    format='json'\n",
    "                )\n",
    "\n",
    "                output = response['response'].strip()\n",
    "\n",
    "                response_json = json.loads(output)\n",
    "\n",
    "                if 'conflict_status' not in response_json:\n",
    "                    #print(\"\\nWarning: 'conflict_status' key is missing in the response.\\n\")\n",
    "                    break\n",
    "                else:\n",
    "                    valid_conflict_response = True\n",
    "                    conflict_status = response_json.get('conflict_status', 0)\n",
    "                    # Ensure conflict_status is an integer\n",
    "                    if isinstance(conflict_status, str):\n",
    "                        conflict_status = int(conflict_status)\n",
    "\n",
    "                    return valid_conflict_response, conflict_status, response_json['conflict_explanation']             \n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"Exception found: \", e)\n",
    "                sys.stdout.flush()\n",
    "                if(count<15):\n",
    "                    continue\n",
    "                else:\n",
    "                    print(\"\\n\",model, \" failed to produce valid JSON for conflict info after 15 tries. Going to next model\\n\")\n",
    "                    break               \n",
    "    \n",
    "    return False, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conflict(device_id, new_intent_flow_json):\n",
    "    \n",
    "    existing_flows = get_flows_for_device_ONOS(device_id)\n",
    "    #existing_flows = manual_flows_by_device.get(device_id, {}).get(\"flows\", [])\n",
    "\n",
    "    for existing_flow in existing_flows:\n",
    "        valid_conflict_response, conflict_status, conflict_details = run_LLM_conflict(existing_flow, new_intent_flow_json)\n",
    "\n",
    "        if (valid_conflict_response == False):\n",
    "            return 2, None, None   #2 means here that LLM could not generate valid JSON for conflict reporting\n",
    "        elif (conflict_status == 1):\n",
    "            return conflict_status, conflict_details, existing_flow\n",
    "        \n",
    "    return 0, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_LLM_IBN(intent, device_id):\n",
    "\n",
    "    for num_examples in context_examples:\n",
    "        for model in my_models_translate_real:\n",
    "            \n",
    "            example_selector = MaxMarginalRelevanceExampleSelector.from_examples(\n",
    "                [{\"instruction\": trainset.iloc[0][\"instruction\"], \"output\": trainset.iloc[0][\"output\"]}],\n",
    "                ollama_emb,\n",
    "                Chroma,\n",
    "                input_keys=[\"instruction\"],\n",
    "                k=num_examples,\n",
    "                vectorstore_kwargs={\"fetch_k\": min(num_examples, len(trainset))}\n",
    "                )\n",
    "            # Clear and add all remaining examples from the trainset\n",
    "            example_selector.vectorstore.reset_collection()\n",
    "            \n",
    "            for _, row in trainset.iterrows():\n",
    "                example_selector.add_example({\n",
    "                    \"instruction\": row[\"instruction\"],\n",
    "                    \"output\": row[\"output\"]\n",
    "                })\n",
    "            \n",
    "            system_prompt = TRANSLATION_PROMPT_ONOS\n",
    "            count = 0\n",
    "\n",
    "            while True:\n",
    "                count+=1\n",
    "                try:\n",
    "                    time.sleep(0.1)\n",
    "                    if num_examples > 0:\n",
    "                        examples = example_selector.select_examples({\"instruction\": intent})\n",
    "                        example_str = \"\\n\\n\\n\".join(map(lambda x: \"Input: \" + x[\"instruction\"] + \"\\n\\nOutput: \" + x[\"output\"], examples))\n",
    "                        system_prompt += example_str + \"\\n\\n\\n\"  \n",
    "                    \n",
    "                    response = client.generate(model=model,\n",
    "                        options={'temperature': 0.6, 'num_ctx': 8192, 'top_p': 0.3, 'num_predict': 1024, 'num_gpu': 99},\n",
    "                        #options={'device': 'cpu'},\n",
    "                        stream=False,\n",
    "                        system=system_prompt,\n",
    "                        prompt=intent,\n",
    "                        format='json'\n",
    "                    )\n",
    "                    actual_output = response['response']\n",
    "                    #print(\"\\nTranslated by: \", model)\n",
    "                    break\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(\"Exception on Input: \", e)\n",
    "                    print(\"\\nCheck example_str same or not: \\n\",example_str)\n",
    "                    sys.stdout.flush()\n",
    "                    if(count<15):\n",
    "                        continue\n",
    "                    else:\n",
    "                        print(\"\\n\",model, \" failed to produce valid JSON for translation info after 15 tries. Going to next model\\n\")\n",
    "                        break \n",
    "            try:\n",
    "                \n",
    "                flow_json = json.loads(actual_output)\n",
    "                \n",
    "                for flow in flow_json.get(\"flows\", []):  # Iterate over all flows\n",
    "                    flow[\"deviceId\"] = device_id  # Replace the device ID\n",
    "\n",
    "                #print(json.dumps(flow_json))\n",
    "\n",
    "                return flow_json\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(\"Exception found: \", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_LLM_Slice(intent):\n",
    "\n",
    "    system_prompt = SLICING_PROMPT\n",
    "    \n",
    "    for model in my_models_translate_real:     \n",
    "        try:\n",
    "            time.sleep(0.1)             \n",
    "            response = client.generate(model=model,\n",
    "                options={'temperature': 0.3, 'num_ctx': 8192, 'top_p': 0.5, 'num_predict': 1024, 'num_gpu': 99},\n",
    "                #options={'device': 'cpu'},\n",
    "                stream=False,\n",
    "                system=system_prompt,\n",
    "                prompt=intent,\n",
    "                format='json'\n",
    "            )\n",
    "            \n",
    "            output = response['response'].strip()\n",
    "            response_json = json.loads(output)\n",
    "            \n",
    "            #print(\"\\nCheckpoint*******Exiting LLM Slicing detection\\n\\n******\")\n",
    "            return response_json            \n",
    "        \n",
    "        except Exception as e:\n",
    "            print(\"Exception found: \", e)\n",
    "            sys.stdout.flush()\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_onos_flow_rule(flow_rule):\n",
    "    \"\"\"\n",
    "    Classify ONOS flow rule into a type and compute its specificity.\n",
    "    Works for both wrapped and standalone flow rule formats.\n",
    "    Returns: (rule_type: str, specificity: float)\n",
    "    \"\"\"\n",
    "\n",
    "    # Support both: wrapped in \"flows\" list OR flat dict\n",
    "    if \"flows\" in flow_rule:\n",
    "        flows = flow_rule.get(\"flows\", [])\n",
    "        if not flows:\n",
    "            return \"unknown\", 0.0\n",
    "        rule = flows[0]\n",
    "    else:\n",
    "        rule = flow_rule\n",
    "\n",
    "    treatment = rule.get(\"treatment\")\n",
    "    selector = rule.get(\"selector\", {})\n",
    "    criteria = selector.get(\"criteria\", [])\n",
    "\n",
    "    # --- Rule Type Detection ---\n",
    "    if treatment is None:\n",
    "        rule_type = \"security\"\n",
    "    else:\n",
    "        instructions = treatment.get(\"instructions\", [])\n",
    "        if not instructions:\n",
    "            rule_type = \"security\"\n",
    "        else:\n",
    "            instr_types = {instr.get(\"type\", \"\").upper() for instr in instructions}\n",
    "            if instr_types == {\"NOACTION\"}:\n",
    "                rule_type = \"security\"\n",
    "            elif \"QUEUE\" in instr_types:\n",
    "                rule_type = \"qos\"\n",
    "            elif \"OUTPUT\" in instr_types:\n",
    "                rule_type = \"forwarding\"\n",
    "            else:\n",
    "                rule_type = \"unknown\"\n",
    "\n",
    "    # --- Specificity Computation ---\n",
    "    specificity = 0.0\n",
    "    for crit in criteria:\n",
    "        specificity += 1\n",
    "        if \"ip\" in crit:\n",
    "            ip = crit[\"ip\"]\n",
    "            try:\n",
    "                ip_net = ipaddress.ip_network(ip, strict=False)\n",
    "                specificity += ip_net.prefixlen / 32.0\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    return rule_type, specificity\n",
    "\n",
    "def resolve_onos_conflict(rule1, rule2):\n",
    "    \"\"\"\n",
    "    Resolve conflict between two ONOS rules using type > specificity > priority.\n",
    "    Handles both LLM-generated-style and ONOS-style rule formats.\n",
    "    Returns: winner_rule, loser_rule\n",
    "    \"\"\"\n",
    "    type_priority = {\"security\": 3, \"qos\": 2, \"forwarding\": 1}\n",
    "\n",
    "    # Normalize both rules into wrapped format for consistency\n",
    "    if \"flows\" not in rule1:\n",
    "        rule1 = {\"flows\": [rule1]}\n",
    "    if \"flows\" not in rule2:\n",
    "        rule2 = {\"flows\": [rule2]}\n",
    "\n",
    "    type1, spec1 = classify_onos_flow_rule(rule1)\n",
    "    type2, spec2 = classify_onos_flow_rule(rule2)\n",
    "\n",
    "    p1 = rule1[\"flows\"][0].get(\"priority\", 0)\n",
    "    p2 = rule2[\"flows\"][0].get(\"priority\", 0)\n",
    "\n",
    "    # Type-based resolution\n",
    "    if type_priority.get(type1, 0) > type_priority.get(type2, 0):\n",
    "        return rule1, rule2\n",
    "    elif type_priority.get(type2, 0) > type_priority.get(type1, 0):\n",
    "        return rule2, rule1\n",
    "\n",
    "    # Specificity-based resolution\n",
    "    if spec1 > spec2:\n",
    "        return rule1, rule2\n",
    "    elif spec2 > spec1:\n",
    "        return rule2, rule1\n",
    "\n",
    "    # Priority-based resolution\n",
    "    if p1 > p2:\n",
    "        return rule1, rule2\n",
    "    elif p2 > p1:\n",
    "        return rule2, rule1\n",
    "\n",
    "    # All equal\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def adjust_priority_onos(winner_rule: dict, loser_rule: dict, step: int = 10) -> dict:\n",
    "    \"\"\"\n",
    "    Adjusts the priority of the winning ONOS flow rule so it overrides the losing one.\n",
    "    Supports both wrapped (\"flows\": [rule]) and flat rule dicts.\n",
    "\n",
    "    Args:\n",
    "        winner_rule (dict): The winning ONOS rule (either format).\n",
    "        loser_rule (dict): The losing ONOS rule (either format).\n",
    "        step (int): Minimum priority margin. Default is 10.\n",
    "\n",
    "    Returns:\n",
    "        dict: Updated winner_rule with modified priority (in-place).\n",
    "    \"\"\"\n",
    "\n",
    "    # Support wrapped and unwrapped formats\n",
    "    if \"flows\" in winner_rule:\n",
    "        winner_flow = winner_rule[\"flows\"][0]\n",
    "    else:\n",
    "        winner_flow = winner_rule\n",
    "\n",
    "    if \"flows\" in loser_rule:\n",
    "        loser_flow = loser_rule[\"flows\"][0]\n",
    "    else:\n",
    "        loser_flow = loser_rule\n",
    "\n",
    "    loser_priority = loser_flow.get(\"priority\", 0)\n",
    "    winner_priority = winner_flow.get(\"priority\", 0)\n",
    "\n",
    "    new_priority = max(winner_priority, loser_priority + step)\n",
    "    winner_flow[\"priority\"] = new_priority\n",
    "\n",
    "    return winner_rule\n",
    "\n",
    "\n",
    "def extract_inner_flow(rule):\n",
    "    return rule[\"flows\"][0] if \"flows\" in rule else rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def end_to_end_IBN(intent):\n",
    "\n",
    "    #current_time = time.time()\n",
    "    device_id = extract_switch_id_ONOS(intent)\n",
    "    global switch_id_for_llm_assurance \n",
    "    switch_id_for_llm_assurance = device_id\n",
    "\n",
    "    intent_JSON = run_LLM_IBN(intent, device_id)\n",
    "\n",
    "    conflict_status, conflict_details, which_flow_conflict = conflict(device_id, intent_JSON)\n",
    "\n",
    "    if((conflict_status != 1) and (conflict_status != 0)):\n",
    "        print(\"\\nCheck Conflict Detection Module, LLM did not produce a valid JSON for conflict detection.\\n\")\n",
    "        return False, None, None, None, None\n",
    "\n",
    "    elif (conflict_status == 1):\n",
    "\n",
    "        winner, non_winner = resolve_onos_conflict(intent_JSON, which_flow_conflict)\n",
    "\n",
    "        winner_rule_inner = extract_inner_flow(winner)\n",
    "        existing_rule_inner = extract_inner_flow(which_flow_conflict)\n",
    "\n",
    "        if winner is None:\n",
    "            print(\"\\nConflict resolution resulted in a tie. The new rule and an existing rule has same type, specificity and priority\\n\")\n",
    "            print(\"\\nThe New flow rule:\\n\", intent_JSON, \"\\nThe existing flow rule: \\n\", which_flow_conflict)\n",
    "            print(\"\\nExisting Flow Rule Location: In switch: \",device_id, \"\\nConflict Details : \\n\",  conflict_details)\n",
    "            return False, \"Tie\", None, None, None\n",
    "        elif (winner_rule_inner == existing_rule_inner):\n",
    "            print(\"\\nExisting Flow Rule that Conflicts: \\n\", winner)\n",
    "            print(\"\\nThe New Flow Rule Attempted to Install based on the Given Intent: \\n\", non_winner)\n",
    "            return False, \"existing_rule_win\", None, None, None\n",
    "        else:\n",
    "            print(\"Conflict Resolved. Winner Flow Rule: \\n\", winner)\n",
    "            print(\"\\nShadowed Flow Rule: \\n\", non_winner)\n",
    "            print(\"\\nShadowed Flow Rule Location: In switch: \",device_id, \"\\nConflict Details : \\n\",  conflict_details)\n",
    "            # After resolving conflict and deciding rule1 is the winner:\n",
    "            updated_flow_json = adjust_priority_onos(winner, non_winner) #argument order important; winner first.\n",
    "            intent_JSON = updated_flow_json   \n",
    "\n",
    "    try:\n",
    "        flow_id = push_flow_rule(device_id, intent_JSON)\n",
    "    except Exception as e:\n",
    "            print(\"Exception found while installing flow rule: \", e)\n",
    "            sys.stdout.flush()\n",
    "            return False, None, None, None, None\n",
    "    try:\n",
    "        verification_status, operational_flow_rule = verify_flow_rule(device_id, flow_id)\n",
    "        if(verification_status == True):\n",
    "            return True, flow_id, device_id, intent_JSON, operational_flow_rule\n",
    "    except Exception as e:\n",
    "            print(\"Exception found while verifying flow rule: \", e)\n",
    "            sys.stdout.flush()\n",
    "            return False, None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_switch_id(intent: str):\n",
    "    \"\"\"\n",
    "    Extract the switch ID from a natural language intent.\n",
    "    \n",
    "    Parameters:\n",
    "        intent (str): The natural language intent.\n",
    "    \n",
    "    Returns:\n",
    "        str: Extracted switch ID (e.g., 'openflow:1') or None if not found.\n",
    "    \"\"\"\n",
    "    # Mapping of ordinal words to numeric values\n",
    "    ordinals = {\n",
    "        \"first\": 1,\n",
    "        \"second\": 2,\n",
    "        \"third\": 3,\n",
    "        \"fourth\": 4,\n",
    "        \"fifth\": 5,\n",
    "        \"sixth\": 6,\n",
    "        \"seventh\": 7,\n",
    "        \"eighth\": 8,\n",
    "        \"ninth\": 9,\n",
    "        \"tenth\": 10\n",
    "    }\n",
    "\n",
    "    # Match patterns like 'openflow:1'\n",
    "    match = re.search(r'openflow[:\\s](\\d+)', intent, re.IGNORECASE)\n",
    "    if match:\n",
    "        return f\"openflow:{match.group(1)}\"\n",
    "\n",
    "    # Match patterns like 'switch 1', 'router 2', 'node 3'\n",
    "    match = re.search(r'\\b(?:switch|router|node|device)(?:\\s*number)?\\s*(\\d+)', intent, re.IGNORECASE)\n",
    "    if match:\n",
    "        return f\"openflow:{match.group(1)}\"\n",
    "\n",
    "    # Match ordinal words (e.g., 'fourth switch', 'second router')\n",
    "    match = re.search(r'\\b(?:switch|router|node|device)\\s*(\\w+)', intent, re.IGNORECASE)\n",
    "    if match:\n",
    "        ordinal_word = match.group(1).lower()\n",
    "        if ordinal_word in ordinals:\n",
    "            return f\"openflow:{ordinals[ordinal_word]}\"\n",
    "\n",
    "    # Match standalone ordinal words (e.g., 'fourth' without 'switch')\n",
    "    for word, number in ordinals.items():\n",
    "        if word in intent.lower():\n",
    "            return f\"openflow:{number}\"\n",
    "\n",
    "    return None\n",
    "\n",
    "def execute_command(command):\n",
    "    \"\"\"\n",
    "    Runs a command with sudo password automation.\n",
    "    \"\"\"\n",
    "    full_command = f\"echo {sudo_password} | sudo -S {command}\"\n",
    "    try:\n",
    "        result = subprocess.run(full_command, shell=True, capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            return result.stdout.strip()\n",
    "        else:\n",
    "            raise Exception(f\"Error executing command: {result.stderr.strip()}\")\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "def get_switch_port_mapping():\n",
    "    try:\n",
    "        # Commands to list port and QoS configurations\n",
    "        list_ports_command = \"sudo -S ovs-vsctl list port\"\n",
    "        list_qos_command = \"sudo -S ovs-vsctl list qos\"\n",
    "        # Fetch port and QoS data\n",
    "        ports_output = execute_command(list_ports_command)\n",
    "        qos_output = execute_command(list_qos_command)\n",
    "\n",
    "        # Parse QoS data into a dictionary\n",
    "        qos_mapping = {}\n",
    "        current_qos = None\n",
    "        for line in qos_output.splitlines():\n",
    "            if line.startswith(\"_uuid\"):\n",
    "                current_qos = line.split(\":\")[1].strip()\n",
    "            elif line.startswith(\"queues\") and current_qos:\n",
    "                qos_mapping[current_qos] = line.split(\":\")[1].strip()\n",
    "\n",
    "        # Create a dictionary to store switch-to-port mapping\n",
    "        switch_port_dict = {}\n",
    "\n",
    "        # Parse ports data and check for QoS\n",
    "        current_port = None\n",
    "        for line in ports_output.splitlines():\n",
    "            if line.startswith(\"name\"):\n",
    "                current_port = line.split(\":\")[1].strip()\n",
    "            elif line.startswith(\"qos\") and \"[]\" not in line and current_port:\n",
    "                qos_uuid = line.split(\":\")[1].strip()\n",
    "\n",
    "                # Extract the OpenFlow switch ID and port number\n",
    "                if \"-\" in current_port:\n",
    "                    switch, port = current_port.split(\"-\")\n",
    "                    switch_id = f\"openflow:{switch[1:]}\"  # e.g., \"s1\" -> \"openflow:1\"\n",
    "                    port_number = port[3:]  # e.g., \"eth2\" -> \"2\"\n",
    "\n",
    "                    # Add to dictionary\n",
    "                    if switch_id not in switch_port_dict:\n",
    "                        switch_port_dict[switch_id] = []\n",
    "                    switch_port_dict[switch_id].append(port_number)\n",
    "\n",
    "                current_port = None\n",
    "\n",
    "        return switch_port_dict\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return {}\n",
    "    \n",
    "def extract_port_number(text: str):\n",
    "    \"\"\"\n",
    "    Extract the Ethernet port number from a natural language text.\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): The input text containing the port reference.\n",
    "    \n",
    "    Returns:\n",
    "        int: Extracted port number or None if not found.\n",
    "    \"\"\"\n",
    "    # Mapping of ordinal words to numeric values\n",
    "    ordinals = {\n",
    "        \"first\": 1,\n",
    "        \"second\": 2,\n",
    "        \"third\": 3,\n",
    "        \"fourth\": 4,\n",
    "        \"fifth\": 5,\n",
    "        \"sixth\": 6,\n",
    "        \"seventh\": 7,\n",
    "        \"eighth\": 8,\n",
    "        \"ninth\": 9,\n",
    "        \"tenth\": 10\n",
    "    }\n",
    "\n",
    "    # Match explicit numbers after keywords\n",
    "    match = re.search(r'\\b(?:port|interface|output\\s+node\\s+connector|ethernet)\\s*(\\d+)', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "\n",
    "    # Match ordinal words (e.g., 'second port', 'third interface')\n",
    "    match = re.search(r'\\b(?:port|interface|output\\s+node\\s+connector|ethernet)\\s*(\\w+)', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        ordinal_word = match.group(1).lower()\n",
    "        if ordinal_word in ordinals:\n",
    "            return ordinals[ordinal_word]\n",
    "\n",
    "    # Match standalone ordinal words (e.g., 'second')\n",
    "    for word, number in ordinals.items():\n",
    "        if word in text.lower():\n",
    "            return number\n",
    "\n",
    "    return None\n",
    "\n",
    "def ovs_port_exists(switch_name, port_name, sudo_password=sudo_password):\n",
    "    import subprocess\n",
    "    cmd = f\"sudo -S ovs-vsctl list-ports {switch_name}\"\n",
    "    result = subprocess.run(cmd, shell=True, capture_output=True, text=True, input=sudo_password + \"\\n\")\n",
    "    ports = result.stdout.split()\n",
    "    return port_name in ports\n",
    "\n",
    "\n",
    "def get_switch_name_from_device_id(device_id):\n",
    "    # device_id is like 'openflow:2'\n",
    "    idx = int(device_id.split(':')[1])\n",
    "    return f\"s{idx}onos\"\n",
    "\n",
    "\n",
    "def create_two_queue_for_switch(device_id, port, max_rate=10000000, queue_configs=None):\n",
    "    \"\"\"\n",
    "    Creates queues dynamically for a specific switch and port.\n",
    "    \n",
    "    Parameters:\n",
    "        switch (str): The name of the switch in 'openflow:X' format (e.g., 'openflow:4').\n",
    "        port (int): The port number on the switch (e.g., 2).\n",
    "        max_rate (int): Maximum rate for the QoS (default is 10000000).\n",
    "        queue_configs (list): List of tuples specifying min-rate and max-rate for each queue (default is 2 queues).\n",
    "    \"\"\"\n",
    "    if queue_configs is None:\n",
    "        # Default to 2 queues with these configurations\n",
    "        queue_configs = [\n",
    "            (6000000, 6000000),  # Queue 0: min-rate and max-rate\n",
    "            (4000000, 4000000)   # Queue 1: min-rate and max-rate\n",
    "        ]\n",
    "\n",
    "    # Construct the port name from the input\n",
    "    #port_name = f\"{switch.replace('openflow:', 's')}-eth{port}\"\n",
    "    switch_name = get_switch_name_from_device_id(device_id)\n",
    "    port_name = f\"{switch_name}-eth{port}\"\n",
    "\n",
    "    if not ovs_port_exists(switch_name, port_name):\n",
    "        print(f\"Port {port_name} does not exist on bridge {switch_name}!\")\n",
    "        return\n",
    "\n",
    "\n",
    "    # Construct the QoS command for the specific switch and port\n",
    "    qos_command = f\"sudo -S ovs-vsctl -- set port {port_name} qos=@newqos -- --id=@newqos create qos type=linux-htb other-config:max-rate={max_rate}\"\n",
    "    for i, (min_rate, max_rate) in enumerate(queue_configs):\n",
    "        qos_command += f\" queues:{i}=@q{i}\"\n",
    "    for i, (min_rate, max_rate) in enumerate(queue_configs):\n",
    "        qos_command += f\" -- --id=@q{i} create queue other-config:min-rate={min_rate} other-config:max-rate={max_rate}\"\n",
    "\n",
    "    # Execute the command\n",
    "    print(f\"Running: {qos_command}\")\n",
    "    process = subprocess.Popen(qos_command, shell=True, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "    stdout, stderr = process.communicate(input=f\"{sudo_password}\\n\")\n",
    "    if process.returncode == 0:\n",
    "        print(f\"Success:\\n{stdout}\")\n",
    "    else:\n",
    "        print(f\"Error:\\n{stderr}\")\n",
    "\n",
    "\n",
    "def create_two_queue_for_switch_handler(slicing_info):\n",
    "\n",
    "    if 'use_queue' in slicing_info:         \n",
    "            slicing_status = slicing_info['use_queue']\n",
    "            slicing_switch_id = slicing_info['switch_id']\n",
    "            slicing_queue_id = slicing_info['queue_id']\n",
    "            slicing_port_id = slicing_info['port_id']\n",
    "\n",
    "            if(slicing_status == 1):\n",
    "                openflow_id = extract_switch_id(slicing_switch_id)\n",
    "                switch_port_mapping = get_switch_port_mapping()\n",
    "                print(\"\\nCheckpoint*******Entering Slice/Queue Management\\n\\n******\")\n",
    "\n",
    "                port_number = extract_port_number(slicing_port_id)\n",
    "                \n",
    "                if openflow_id not in switch_port_mapping :\n",
    "                    \n",
    "                        print(\"\\n\\nQueue was not installed in \",openflow_id, \"\\nInstalling now on interface: \", port_number,\"\\n\")\n",
    "                        print(\"\\nCheckpoint*******Entering queue creation\\n\\n******\")\n",
    "\n",
    "                        create_two_queue_for_switch(\n",
    "                            device_id=openflow_id,  port=port_number,\n",
    "                            queue_configs=[\n",
    "                                (6000000, 6000000),  # Queue 0\n",
    "                                (4000000, 4000000)   # Queue 1\n",
    "                            ]\n",
    "                            )   \n",
    "                else:\n",
    "                    if str(port_number) not in switch_port_mapping[openflow_id]:\n",
    "\n",
    "                        print(\"\\n\\nQueue was not installed in \",openflow_id, \" interface: \", port_number, \"\\nInstalling now...\\n\")\n",
    "                        print(\"\\nCheckpoint*******Entering queue creation\\n\\n******\")\n",
    "\n",
    "                        create_two_queue_for_switch(\n",
    "                            device_id=openflow_id,  port=port_number,\n",
    "                            queue_configs=[\n",
    "                                (6000000, 6000000),  # Queue 0\n",
    "                                (4000000, 4000000)   # Queue 1\n",
    "                            ]\n",
    "                            )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_corrective_action_prompt(intent_nl, operational_flow_rule, device_id, ping_count,\n",
    "                                      candidate_src_ip, candidate_dst_ip, ping_output):\n",
    "    \n",
    "    existing_flows = get_flows_for_device_ONOS(device_id)\n",
    "\n",
    "    prompt_sections = []\n",
    "\n",
    "    # General instruction\n",
    "    prompt_sections.append(\n",
    "        \"You are an SDN network assistant. Your task is to recommend a ranked list of corrective actions \"\n",
    "        \"to enforce a **security intent** that failed during assurance testing.\"\n",
    "    )\n",
    "\n",
    "    # Intent\n",
    "    prompt_sections.append(f\"1. **Security Intent (in Natural Language)**:\\n{intent_nl}\")\n",
    "\n",
    "    # Translated flow rule\n",
    "    prompt_sections.append(\"2. **ONOS Flow Rule for the Security Intent**:\")\n",
    "    prompt_sections.append(json.dumps(operational_flow_rule, indent=2))\n",
    "\n",
    "    # Existing flows\n",
    "    prompt_sections.append(\"3. **Existing Flow Rules in the Same Switch**:\")\n",
    "    prompt_sections.append(json.dumps(existing_flows, separators=(\",\", \":\")))\n",
    "\n",
    "    # Assurance test result\n",
    "    prompt_sections.append(\n",
    "        f\"\"\"4. **Assurance Test Result**:\n",
    "        - Ping Source IP: {candidate_src_ip}\n",
    "        - Ping Destination IP: {candidate_dst_ip}\n",
    "        - Ping Count: {ping_count}\n",
    "        - Ping Output:\n",
    "        {ping_output}\"\"\"\n",
    "    )\n",
    "\n",
    "    # Instruction and output format\n",
    "    prompt_sections.append(\n",
    "        \"---\\nNow, based on the above data, generate a ranked list of corrective actions \"\n",
    "        \"that can help enforce the security intent more effectively. \"\n",
    "        \"You must use only the following predefined corrective actions (and use each only if relevant):\\n\"\n",
    "        \"1. Correct Match Fields\\n\"\n",
    "        \"2. Increase Priority\\n\"\n",
    "        \"3. Fix Action Field\\n\\n\"\n",
    "        \"For each corrective action you suggest:\\n\"\n",
    "        \"- **For 'Correct Match Fields'**: Specify *exactly* which match fields and values should be set in the flow rule's 'selector.criteria' list (e.g., type: 'IPV4_SRC', ip: '10.0.1.1/32'), and which fields (if any) should be removed or changed in the candidate flow rule.\\n\"\n",
    "        \"- **For 'Increase Priority'**: Indicate which existing rule(s) are overshadowing the candidate rule, their current priority value(s), and the exact priority value the candidate rule should be set to (must be greater than the overshadowing rule(s)).\\n\"\n",
    "        \"- **For 'Fix Action Field'**: Only include this suggestion if the candidate rule's 'treatment.instructions' field does not contain only type 'NOACTION'.\\n\\n\"\n",
    "        \"Rank the actions according to what you believe to be the root cause, and explain your reasoning in the 'reasoning' field for each suggestion.\\n\"\n",
    "        \"Return your answer ONLY in the following strict JSON format (do not add extra explanations or commentary):\\n\"\n",
    "        \"{\\n\"\n",
    "        \"  \\\"recommended_actions\\\": [\\n\"\n",
    "        \"    {\\n\"\n",
    "        \"      \\\"rank\\\": 1,\\n\"\n",
    "        \"      \\\"action\\\": \\\"Correct Match Fields\\\",\\n\"\n",
    "        \"      \\\"suggestion\\\": {\\n\"\n",
    "        \"        \\\"set_fields\\\": {\\\"IPV4_SRC\\\": \\\"10.0.0.1\\\", \\\"IPV4_DST\\\": \\\"10.0.0.2\\\"},\\n\"\n",
    "        \"        \\\"remove_fields\\\": [\\\"TCP_SRC\\\"],\\n\"\n",
    "        \"        \\\"reasoning\\\": \\\"The match fields do not match the intended source and destination; correcting them should enforce the intent.\\\"\\n\"\n",
    "        \"      }\\n\"\n",
    "        \"    },\\n\"\n",
    "        \"    {\\n\"\n",
    "        \"      \\\"rank\\\": 2,\\n\"\n",
    "        \"      \\\"action\\\": \\\"Increase Priority\\\",\\n\"\n",
    "        \"      \\\"suggestion\\\": {\\n\"\n",
    "        \"        \\\"conflicting_rules\\\": [ {\\\"flow_id\\\": \\\"123\\\", \\\"priority\\\": 40000} ],\\n\"\n",
    "        \"        \\\"recommended_priority\\\": 40001,\\n\"\n",
    "        \"        \\\"reasoning\\\": \\\"The candidate rule is overshadowed by a rule with higher priority; increasing priority will resolve this.\\\"\\n\"\n",
    "        \"      }\\n\"\n",
    "        \"    },\\n\"\n",
    "        \"    ...\\n\"\n",
    "        \"  ]\\n\"\n",
    "        \"}\\n\"\n",
    "        \"Omit any action that is not relevant to the current deviation.\"\n",
    "    )\n",
    "\n",
    "    return \"\\n\\n\".join(prompt_sections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Run_assurance_LLM (assurance_prompt):\n",
    "    \n",
    "    for model in my_models_conflict_real:    \n",
    "        try:\n",
    "            time.sleep(0.1)             \n",
    "            response = client.generate(model=model,\n",
    "                options={'temperature': 0.3, 'num_ctx': 8192, 'top_p': 0.5, 'num_predict': 1024, 'num_gpu': 99},\n",
    "                #options={'device': 'cpu'},\n",
    "                stream=False,\n",
    "                system=\"\",\n",
    "                prompt=assurance_prompt,\n",
    "                format='json'\n",
    "            )\n",
    "            \n",
    "            output = response['response'].strip()\n",
    "            response_json = json.loads(output)\n",
    "            return response_json            \n",
    "        \n",
    "        except Exception as e:\n",
    "            print(\"Exception found at assurance LLM for corrective action generation: \", e)\n",
    "            sys.stdout.flush()\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_host_and_ip_onos(flow_data):\n",
    "    \"\"\"\n",
    "    Extract source and destination host names and IPs from ONOS flow rule.\n",
    "    Supports both wrapped (with 'flows') and flat formats.\n",
    "    \n",
    "    Returns: (src_host, dst_host, src_ip, dst_ip)\n",
    "    \"\"\"\n",
    "    # Handle both wrapped and flat formats\n",
    "    flow = flow_data[\"flows\"][0] if \"flows\" in flow_data else flow_data\n",
    "\n",
    "    # Default values\n",
    "    src_ip = dst_ip = None\n",
    "\n",
    " # Extract criteria from selector\n",
    "    criteria = flow.get(\"selector\", {}).get(\"criteria\", [])\n",
    "    for criterion in criteria:\n",
    "        if criterion.get(\"type\") == \"IPV4_SRC\":\n",
    "            src_ip = criterion[\"ip\"].split(\"/\")[0]\n",
    "        elif criterion.get(\"type\") == \"IPV4_DST\":\n",
    "            dst_ip = criterion[\"ip\"].split(\"/\")[0]\n",
    "\n",
    "    src_host = ip_to_host.get(src_ip, \"Unknown\") if src_ip else None\n",
    "    dst_host = ip_to_host.get(dst_ip, \"Unknown\") if dst_ip else None\n",
    "\n",
    "    return src_host, dst_host, src_ip, dst_ip\n",
    "\n",
    "def execute_command_full(command, timeout):\n",
    "    \"\"\"Execute a command and capture full output, waiting for all responses.\"\"\"\n",
    "    try:\n",
    "        process = subprocess.Popen(\n",
    "            command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True\n",
    "        )\n",
    "\n",
    "        output_lines = []\n",
    "        start_time = time.time()\n",
    "\n",
    "        while True:\n",
    "            line = process.stdout.readline()\n",
    "            if line:\n",
    "                output_lines.append(line.strip())  # Store the output line\n",
    "                #print(line.strip())  # Print live output (optional)\n",
    "\n",
    "            # Check if process has completed\n",
    "            if process.poll() is not None:\n",
    "                break\n",
    "\n",
    "            # Timeout check\n",
    "            if time.time() - start_time > timeout:\n",
    "                process.terminate()  # Stop process if timeout occurs\n",
    "                raise TimeoutError(f\"Command timed out after {timeout} seconds\")\n",
    "\n",
    "        # Capture remaining output\n",
    "        remaining_output, _ = process.communicate()\n",
    "        if remaining_output:\n",
    "            output_lines.append(remaining_output.strip())\n",
    "\n",
    "        return \"\\n\".join(output_lines)\n",
    "\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "    \n",
    "def get_mininet_host_pid(src_host):\n",
    "    \"\"\"\n",
    "    Robustly get the PID of a Mininet host process (e.g., 'h1' or 'h1onos') regardless of user.\n",
    "    Looks for a process with command containing 'mininet:<src_host>'.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ps_output = subprocess.check_output([\"ps\", \"-eo\", \"pid,args\"], text=True).strip().splitlines()\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        raise RuntimeError(\"Failed to run 'ps -eo pid,args'\") from e\n",
    "\n",
    "    for line in ps_output:\n",
    "        if f\"mininet:{src_host}\" in line and \"grep\" not in line:\n",
    "            parts = line.strip().split(None, 1)\n",
    "            if len(parts) == 2:\n",
    "                pid_str, cmd = parts\n",
    "                try:\n",
    "                    pid = int(pid_str)\n",
    "                    #print(f\"[DEBUG] Matched host '{src_host}' → PID {pid}\")\n",
    "                    return pid\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "    raise RuntimeError(f\"No Mininet host process found for '{src_host}'.\")\n",
    "\n",
    "def ONOS_assurance_for_security_intent(src_ip, dst_ip, ping_count=2):\n",
    "    \n",
    "    all_ips = [\"10.0.1.1\", \"10.0.1.2\", \"10.0.1.3\", \"10.0.1.4\"]  # Customize this list as per your topology\n",
    "    global llm_caller_flag\n",
    "    llm_caller_flag = 0\n",
    "\n",
    "    def perform_ping(source_ip, target_ip):\n",
    "\n",
    "        source_host = ip_to_host.get(source_ip)\n",
    "        if not source_host:\n",
    "            print(f\"[WARNING] Unknown source host for IP: {source_ip}\")\n",
    "            return None\n",
    "        try:\n",
    "            host_pid = get_mininet_host_pid(source_host)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Cannot get PID for host {source_host}: {e}\")\n",
    "            return None\n",
    "        ping_cmd = f\"echo {sudo_password} | sudo -S mnexec -a {host_pid} ping -c {ping_count} {target_ip}\"\n",
    "        return execute_command_full(ping_cmd, timeout=15)\n",
    "\n",
    "    # Case 1: src and dst IP both present\n",
    "    if src_ip and dst_ip:\n",
    "        print(f\"[INFO] Testing {src_ip} to {dst_ip}\")\n",
    "        output = perform_ping(src_ip, dst_ip)\n",
    "        if output and \"100% packet loss\" in output:\n",
    "            print(f\"[PASS] Intent effective. Traffic from {src_ip} to {dst_ip} is blocked.\")\n",
    "        elif output and \"0% packet loss\" in output:\n",
    "            print(f\"[FAIL] Intent NOT effective. Traffic from {src_ip} to {dst_ip} is NOT blocked.\")\n",
    "            llm_caller_flag = 1\n",
    "        else:\n",
    "            print(\"[WARN] Inconclusive result. Ping output:\\n\", output)\n",
    "            llm_caller_flag = 1\n",
    "        return ping_count, src_ip, dst_ip, output\n",
    "\n",
    "    # Case 2: src_ip is None → test all src IPs → dst_ip\n",
    "    elif src_ip is None and dst_ip:\n",
    "        print(f\"[INFO] Testing multiple sources to {dst_ip}\")\n",
    "        for candidate_src in all_ips:\n",
    "            if candidate_src == dst_ip:\n",
    "                continue\n",
    "            output = perform_ping(candidate_src, dst_ip)\n",
    "            if output and \"100% packet loss\" in output:\n",
    "                continue  # this one is blocked, good\n",
    "            elif output and \"0% packet loss\" in output:\n",
    "                print(f\"[FAIL] Intent NOT effective. {candidate_src} → {dst_ip} was NOT blocked.\")\n",
    "                llm_caller_flag = 1\n",
    "                return ping_count, candidate_src, dst_ip, output\n",
    "            else:\n",
    "                print(f\"[WARN] Inconclusive result from {candidate_src} → {dst_ip}:\\n{output}\")\n",
    "                llm_caller_flag = 1\n",
    "                return ping_count, candidate_src, dst_ip, output\n",
    "        print(f\"[PASS] Intent effective. All sources blocked from reaching {dst_ip}.\")\n",
    "        return ping_count, candidate_src, dst_ip, output\n",
    "\n",
    "    # Case 3: dst_ip is None → test src_ip → all destinations\n",
    "    elif dst_ip is None and src_ip:\n",
    "        print(f\"[INFO] Testing {src_ip} for multiple destinations\")\n",
    "        for candidate_dst in all_ips:\n",
    "            if candidate_dst == src_ip:\n",
    "                continue\n",
    "            output = perform_ping(src_ip, candidate_dst)\n",
    "            if output and \"100% packet loss\" in output:\n",
    "                continue  # this one is blocked, good\n",
    "            elif output and \"0% packet loss\" in output:\n",
    "                print(f\"[FAIL] Intent NOT effective. {src_ip} → {candidate_dst} was NOT blocked.\")\n",
    "                llm_caller_flag = 1\n",
    "                return ping_count, src_ip, candidate_dst, output\n",
    "            else:\n",
    "                print(f\"[WARN] Inconclusive result from {src_ip} → {candidate_dst}:\\n{output}\")\n",
    "                llm_caller_flag = 1\n",
    "                return ping_count, src_ip, candidate_dst, output\n",
    "        print(f\"[PASS] Intent effective. {src_ip} blocked from reaching all destinations.\")\n",
    "        return ping_count, src_ip, candidate_dst, output\n",
    "\n",
    "    else:\n",
    "        print(\"[ERROR] Both source and destination IPs are missing. Cannot evaluate intent.\")\n",
    "        llm_caller_flag = 2\n",
    "\n",
    "def ONOS_assurance_for_qos_intent(src_host, dst_host, src_ip, dst_ip, ping_count=2):\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "def ONOS_assurance_for_forwarding_intent(src_host, dst_host, src_ip, dst_ip, ping_count=2):\n",
    "\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_match_fields(candidate_flow, set_fields, remove_fields):\n",
    "    \"\"\"\n",
    "    Update candidate_flow's match fields: set specified, remove specified.\n",
    "    set_fields: dict, e.g. {'IPV4_SRC': '10.0.2.2/32'}\n",
    "    remove_fields: list of type strings\n",
    "    \"\"\"\n",
    "    selector = candidate_flow['selector']\n",
    "    # Remove fields\n",
    "    selector['criteria'] = [\n",
    "        crit for crit in selector['criteria'] if crit['type'] not in remove_fields\n",
    "    ]\n",
    "    # Set/update fields\n",
    "    for k, v in set_fields.items():\n",
    "        # Remove any existing\n",
    "        selector['criteria'] = [crit for crit in selector['criteria'] if crit['type'] != k]\n",
    "        # Correct value key based on ONOS spec\n",
    "        if k in [\"IPV4_SRC\", \"IPV4_DST\"]:\n",
    "            selector['criteria'].append({'type': k, 'ip': v})\n",
    "        elif k == \"ETH_TYPE\":\n",
    "            selector['criteria'].append({'type': k, 'ethType': v})\n",
    "        else:\n",
    "            selector['criteria'].append({'type': k, 'value': v})\n",
    "    candidate_flow['selector'] = selector\n",
    "    return candidate_flow\n",
    "\n",
    "def increase_priority(candidate_flow, recommended_priority):\n",
    "    candidate_flow['priority'] = recommended_priority\n",
    "    return candidate_flow\n",
    "\n",
    "def fix_action_field(candidate_flow):\n",
    "    \"\"\"\n",
    "    Make sure treatment.instructions is only [{'type': 'NOACTION'}]\n",
    "    \"\"\"\n",
    "    candidate_flow['treatment'] = {\n",
    "        \"instructions\": [{\"type\": \"NOACTION\"}]\n",
    "    }\n",
    "    return candidate_flow\n",
    "\n",
    "def parse_and_execute_corrective_actions(candidate_flow, llm_response, device_id, flow_id, src_ip, dst_ip):\n",
    "    \"\"\"\n",
    "    candidate_flow: dict, the ONOS flow rule you want to fix\n",
    "    existing_flows: list of dicts, flows on the same device\n",
    "    llm_response: dict, output from LLM with 'recommended_actions'\n",
    "    intent_drift_fn: function that checks for intent drift, returns True if drift still exists, False if resolved\n",
    "    push_flow_fn: function to push the modified flow to ONOS\n",
    "    \"\"\"\n",
    "    actions = sorted(llm_response[\"recommended_actions\"], key=lambda x: x[\"rank\"])\n",
    "    for action_item in actions:\n",
    "        action = action_item[\"action\"]\n",
    "        suggestion = action_item[\"suggestion\"]\n",
    "        print(f\"Triggering action: {action} (rank {action_item['rank']})\")\n",
    "\n",
    "        if action == \"Correct Match Fields\":\n",
    "            set_fields = suggestion.get(\"set_fields\", {})\n",
    "            remove_fields = suggestion.get(\"remove_fields\", [])\n",
    "            candidate_flow = correct_match_fields(candidate_flow, set_fields, remove_fields)\n",
    "        elif action == \"Increase Priority\":\n",
    "            recommended_priority = suggestion.get(\"recommended_priority\")\n",
    "            candidate_flow = increase_priority(candidate_flow, recommended_priority)\n",
    "        elif action == \"Fix Action Field\":\n",
    "            candidate_flow = fix_action_field(candidate_flow)\n",
    "        else:\n",
    "            print(f\"Unknown action: {action}\")\n",
    "\n",
    "        # Push the flow to ONOS\n",
    "        # First remove the old one\n",
    "        delete_flow_rule_ONOS(device_id, flow_id)\n",
    "\n",
    "        try:\n",
    "            flow_id = push_flow_rule(device_id, candidate_flow)\n",
    "        except Exception as e:\n",
    "                print(\"Exception found while installing flow rule: \", e)\n",
    "                sys.stdout.flush()\n",
    "        try:\n",
    "            verification_status, operational_flow_rule = verify_flow_rule(device_id, flow_id)\n",
    "            if(verification_status == True):\n",
    "                print(\"\\nCorrected Flow Rules Installed Successfully\\n\")\n",
    "        except Exception as e:\n",
    "                print(\"Corrected Flow Rules Failed to be Installed Successfully. Exception found while verifying flow rule: \", e)\n",
    "                sys.stdout.flush()\n",
    "\n",
    "        global llm_caller_flag\n",
    "\n",
    "        ONOS_assurance_for_security_intent(src_ip, dst_ip)\n",
    "\n",
    "        # Check intent drift (assurance) after each action\n",
    "        \n",
    "        if llm_caller_flag == 0:\n",
    "            print(f\"Intent deviation resolved after action: {action}\")\n",
    "            return True  # Deviation fixed\n",
    "\n",
    "        print(f\"Deviation not fixed after action: {action}, proceeding to next action...\")\n",
    "\n",
    "    print(\"\\n\\nAll suggested corrective actions exhausted, but deviation remains. Escalate the issue to the Operator.\\n\")\n",
    "    return False  # Deviation not fixed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QoS verification helper functions\n",
    "\n",
    "_UNITS_BYTES = {\"KBytes\":1024, \"MBytes\":1024**2, \"GBytes\":1024**3, \"TBytes\":1024**4, \"Bytes\":1}\n",
    "_UNITS_BITS  = {\"Kbits/sec\":1e3, \"Mbits/sec\":1e6, \"Gbits/sec\":1e9, \"bits/sec\":1.0}\n",
    "\n",
    "def build_pin_selector_forward(src_ip: str, dst_ip: str, dport: int, proto: str = \"tcp\"):\n",
    "    proto = proto.lower()\n",
    "    criteria = [\n",
    "        {\"type\": \"ETH_TYPE\", \"ethType\": \"0x800\"},\n",
    "        {\"type\": \"IP_PROTO\", \"protocol\": 6 if proto == \"tcp\" else 17},\n",
    "        {\"type\": \"IPV4_SRC\", \"ip\": f\"{src_ip}/32\"},\n",
    "        {\"type\": \"IPV4_DST\", \"ip\": f\"{dst_ip}/32\"},\n",
    "    ]\n",
    "    if proto == \"tcp\":\n",
    "        criteria.append({\"type\": \"TCP_DST\", \"tcpPort\": dport})\n",
    "    else:\n",
    "        criteria.append({\"type\": \"UDP_DST\", \"udpPort\": dport})\n",
    "    return {\"criteria\": criteria}\n",
    "\n",
    "def build_pin_selector_reverse(src_ip: str, dst_ip: str, sport: int, proto: str = \"tcp\"):\n",
    "    # reverse direction (dst->src); for TCP we match TCP_SRC=port, for UDP we match UDP_SRC=port\n",
    "    proto = proto.lower()\n",
    "    criteria = [\n",
    "        {\"type\": \"ETH_TYPE\", \"ethType\": \"0x800\"},\n",
    "        {\"type\": \"IP_PROTO\", \"protocol\": 6 if proto == \"tcp\" else 17},\n",
    "        {\"type\": \"IPV4_SRC\", \"ip\": f\"{dst_ip}/32\"},\n",
    "        {\"type\": \"IPV4_DST\", \"ip\": f\"{src_ip}/32\"},\n",
    "    ]\n",
    "    if proto == \"tcp\":\n",
    "        criteria.append({\"type\": \"TCP_SRC\", \"tcpPort\": sport})\n",
    "    else:\n",
    "        criteria.append({\"type\": \"UDP_SRC\", \"udpPort\": sport})\n",
    "    return {\"criteria\": criteria}\n",
    "\n",
    "def build_output_only_treatment(out_port: int | str):\n",
    "    return {\"instructions\": [{\"type\": \"OUTPUT\", \"port\": str(out_port)}]}\n",
    "\n",
    "def build_queue_and_output_treatment(queue_id: int, out_port: int | str):\n",
    "    return {\"instructions\": [{\"type\": \"QUEUE\", \"queueId\": int(queue_id)}, {\"type\": \"OUTPUT\", \"port\": str(out_port)}]}\n",
    "\n",
    "def build_pin_flow_body(device_id: str, selector: dict, treatment: dict, priority: int = 65000):\n",
    "    # ONOS expects an array under \"flows\"\n",
    "    return {\n",
    "        \"flows\": [{\n",
    "            \"deviceId\": device_id,\n",
    "            \"isPermanent\": True,\n",
    "            \"priority\": priority,\n",
    "            \"selector\": selector,\n",
    "            \"treatment\": treatment\n",
    "        }]\n",
    "    }\n",
    "\n",
    "# def delete_flow_rule(device_id: str, flow_id: str):\n",
    "#     url = f\"{ONOS_BASE_URL}/{device_id}/{flow_id}\"\n",
    "#     HEADERS = {\"Accept\": \"application/json\"}\n",
    "#     r = requests.delete(url, headers=HEADERS, auth=(USERNAME, PASSWORD), timeout=15)\n",
    "#     # 204/200/202 = fine; 404 -> already gone is OK\n",
    "#     if r.status_code not in (200, 202, 204, 404):\n",
    "#         print(f\"[WARN] DELETE {device_id}/{flow_id} failed {r.status_code}: {r.text}\")\n",
    "\n",
    "# ---------- PIN PATH VIA S3 (place below the helpers) ----------\n",
    "def pin_path_via_s3(src_ip=\"10.0.1.1\", dst_ip=\"10.0.1.3\", dst_port=80, proto=\"tcp\",\n",
    "                    include_s4_forward_qos=False, s4_queue_id=1):\n",
    "    \"\"\"\n",
    "    Installs high-priority OUTPUT-only pins on s1 and s3 for forward,\n",
    "    OUTPUT-only pins on s4,s3,s1 for reverse ACK path.\n",
    "    Optionally installs the s4 forward QoS rule (QUEUE+OUTPUT) if needed.\n",
    "    Returns dict of {label: (deviceId, flowId)} for cleanup.\n",
    "    \"\"\"\n",
    "    S1, S3, S4 = \"of:0000000000000001\", \"of:0000000000000003\", \"of:0000000000000004\"\n",
    "    pins = {}\n",
    "\n",
    "    # Selectors\n",
    "    sel_fwd = build_pin_selector_forward(src_ip, dst_ip, dport=dst_port, proto=proto)\n",
    "    sel_rev = build_pin_selector_reverse(src_ip, dst_ip, sport=dst_port, proto=proto)\n",
    "\n",
    "    # ---- Forward pins (s1->s3->s4). s4 forward QoS rule optional. ----\n",
    "    # s1 out to s3 (port 2)\n",
    "    body = build_pin_flow_body(S1, sel_fwd, build_output_only_treatment(2), priority=65000)\n",
    "    fid = push_flow_rule(S1, body); pins[\"s1_fwd\"] = (S1, fid)\n",
    "\n",
    "    # s3 out to s4 (port 2)\n",
    "    body = build_pin_flow_body(S3, sel_fwd, build_output_only_treatment(2), priority=65000)\n",
    "    fid = push_flow_rule(S3, body); pins[\"s3_fwd\"] = (S3, fid)\n",
    "\n",
    "    if include_s4_forward_qos:\n",
    "        # s4 set-queue then out to h3 (port 3)\n",
    "        body = build_pin_flow_body(S4, sel_fwd, build_queue_and_output_treatment(s4_queue_id, 3), priority=65000)\n",
    "        fid = push_flow_rule(S4, body); pins[\"s4_qos_fwd\"] = (S4, fid)\n",
    "\n",
    "    # ---- Reverse (ACK) pins (h3->h1) along s4->s3->s1 ----\n",
    "    # s4 out to s3 (port 2)\n",
    "    body = build_pin_flow_body(S4, sel_rev, build_output_only_treatment(2), priority=65000)\n",
    "    fid = push_flow_rule(S4, body); pins[\"s4_rev\"] = (S4, fid)\n",
    "\n",
    "    # s3 out to s1 (port 1)\n",
    "    body = build_pin_flow_body(S3, sel_rev, build_output_only_treatment(1), priority=65000)\n",
    "    fid = push_flow_rule(S3, body); pins[\"s3_rev\"] = (S3, fid)\n",
    "\n",
    "    # s1 out to h1 (port 3)\n",
    "    body = build_pin_flow_body(S1, sel_rev, build_output_only_treatment(3), priority=65000)\n",
    "    fid = push_flow_rule(S1, body); pins[\"s1_rev\"] = (S1, fid)\n",
    "\n",
    "    return pins\n",
    "\n",
    "# def unpin_path(pins: dict):\n",
    "#     \"\"\"Remove all pinned rules by device/flow ID (safe if already deleted).\"\"\"\n",
    "#     for label, (dev, fid) in pins.items():\n",
    "#         if fid:\n",
    "#             delete_flow_rule(dev, fid)\n",
    "\n",
    "def run_in_host(host_pid: int, cmd: str, timeout: int = 30, require_sudo: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Run a command inside a Mininet host namespace using mnexec -a <PID>.\n",
    "    Always uses sudo here to avoid 'Permission denied' when entering namespaces.\n",
    "    \"\"\"\n",
    "    prefix = f\"echo {shlex.quote(sudo_password)} | sudo -S \"\n",
    "    full_cmd = f\"{prefix}mnexec -a {host_pid} {cmd}\"\n",
    "    return execute_command_full(full_cmd, timeout=timeout)\n",
    "\n",
    "def ensure_no_iperf_server(host_pid: int, port: int) -> None:\n",
    "    \"\"\"\n",
    "    Attempt to kill any existing iperf3 server on that port in the host namespace.\n",
    "    \"\"\"\n",
    "    # Try pkill first, then kill by pgrep if needed.\n",
    "    run_in_host(host_pid, f\"pkill -f {shlex.quote(f'iperf3 -s -p {port}')} || true\", timeout=5, require_sudo=True)\n",
    "    run_in_host(host_pid, f\"bash -lc \\\"pgrep -af 'iperf3.*-s.*-p {port}' | awk '{{print $1}}' | xargs -r kill -9\\\"\", timeout=5, require_sudo=True)\n",
    "\n",
    "def start_iperf_server(host_pid: int, port: int, extra_args: str = \"\") -> None:\n",
    "    \"\"\"\n",
    "    Start iperf3 server (-s) on port (may require sudo for <1024). Run in background.\n",
    "    Use --one-off to auto-exit after one test.\n",
    "    \"\"\"\n",
    "    ensure_no_iperf_server(host_pid, port)\n",
    "    cmd = f\"bash -lc 'nohup iperf3 -s -p {int(port)} --one-off {extra_args} >/tmp/iperf3_s_{port}.log 2>&1 & echo $!'\"\n",
    "    out = run_in_host(host_pid, cmd, timeout=5, require_sudo=True)\n",
    "    # Best-effort small delay for readiness\n",
    "    time.sleep(0.6)\n",
    "\n",
    "def stop_iperf_server(host_pid: int, port: int) -> None:\n",
    "    ensure_no_iperf_server(host_pid, port)\n",
    "\n",
    "def sudo_sh(cmd, timeout=20):\n",
    "    return execute_command_full(f\"echo {shlex.quote(sudo_password)} | sudo -S bash -lc {shlex.quote(cmd)}\", timeout=timeout)\n",
    "\n",
    "def find_bridge_for_device(device_id: str) -> str:\n",
    "    js = sudo_sh(\"ovs-vsctl -f json list Bridge\", timeout=10)\n",
    "    data = json.loads(js)\n",
    "    dpid_hex = device_id.replace(\"of:\",\"\").lower()\n",
    "    head = data[\"headings\"]\n",
    "    for row in data[\"data\"]:\n",
    "        obj = dict(zip(head, row))\n",
    "        oc = dict(obj[\"other_config\"][1]) if isinstance(obj.get(\"other_config\"), list) else {}\n",
    "        oc_dpid = (oc.get(\"datapath-id\") or oc.get(\"datapath_id\") or \"\").lower().replace(\":\",\"\")\n",
    "        if oc_dpid == dpid_hex:\n",
    "            name = obj[\"name\"]\n",
    "            return name[-1] if isinstance(name, list) else name\n",
    "    raise RuntimeError(\"Bridge not found\")\n",
    "\n",
    "def parse_qos_show(iface: str):\n",
    "    \"\"\"\n",
    "    Parse `ovs-appctl -t ovs-vswitchd qos/show IFACE` that looks like:\n",
    "\n",
    "      QoS: s2onos-eth2 linux-htb\n",
    "      max-rate: 10000000\n",
    "\n",
    "      Default:\n",
    "        burst: 12512\n",
    "        min-rate: 6000000\n",
    "        tx_packets: 1868919\n",
    "        tx_bytes: 267187192\n",
    "        tx_errors: 0\n",
    "\n",
    "      Queue 1:\n",
    "        burst: 12512\n",
    "        min-rate: 4000000\n",
    "        tx_packets: 3429\n",
    "        tx_bytes: 5078775\n",
    "        tx_errors: 0\n",
    "\n",
    "    Returns: {\"queues\": {\"default\": {...}, \"1\": {...}}, \"raw\": <text>, \"_qos\": {\"max-rate\": ...}}\n",
    "    \"\"\"\n",
    "    txt = sudo_sh(f\"ovs-appctl -t ovs-vswitchd qos/show {shlex.quote(iface)} 2>&1\", timeout=8)\n",
    "\n",
    "    queues = {}\n",
    "    current = None\n",
    "    qos_meta = {}\n",
    "\n",
    "    for raw in txt.splitlines():\n",
    "        line = raw.strip()\n",
    "\n",
    "        # Top-level QoS meta (e.g., max-rate)\n",
    "        m_qos_max = re.search(r'\\bmax-rate:\\s*(\\d+)', line, re.IGNORECASE)\n",
    "        if m_qos_max and current is None:\n",
    "            qos_meta[\"max-rate\"] = int(m_qos_max.group(1))\n",
    "\n",
    "        # Block headers\n",
    "        if re.match(r'^(Default)\\s*:\\s*$', line, re.IGNORECASE):\n",
    "            current = \"default\"\n",
    "            queues.setdefault(current, {})\n",
    "            continue\n",
    "        m_q = re.match(r'^(?:Queue|queue)\\s+(\\d+)\\s*:\\s*$', line)\n",
    "        if m_q:\n",
    "            current = m_q.group(1)\n",
    "            queues.setdefault(current, {})\n",
    "            continue\n",
    "\n",
    "        # Inside a block, pick out key:value lines we care about\n",
    "        if current:\n",
    "            for key, pat in [\n",
    "                (\"min-rate\",   r'\\bmin-rate:\\s*(\\d+)'),\n",
    "                (\"max-rate\",   r'\\bmax-rate:\\s*(\\d+)'),\n",
    "                (\"tx_bytes\",   r'\\btx_bytes:\\s*(\\d+)'),\n",
    "                (\"tx_packets\", r'\\btx_packets:\\s*(\\d+)'),\n",
    "            ]:\n",
    "                m = re.search(pat, line, re.IGNORECASE)\n",
    "                if m:\n",
    "                    queues[current][key] = int(m.group(1))\n",
    "\n",
    "    return {\"queues\": queues, \"raw\": txt, \"_qos\": qos_meta}\n",
    "\n",
    "# # keep snapshot_queue using the patched parser\n",
    "def snapshot_queue(iface: str, queue_id: int | str):\n",
    "    parsed = parse_qos_show(iface)\n",
    "    q = parsed[\"queues\"].get(str(queue_id)) or parsed[\"queues\"].get(\"default\") or {}\n",
    "    return {\n",
    "        \"min_rate\": q.get(\"min-rate\"),\n",
    "        \"max_rate\": q.get(\"max-rate\"),\n",
    "        \"tx_bytes\": q.get(\"tx_bytes\"),\n",
    "        \"tx_packets\": q.get(\"tx_packets\"),\n",
    "        \"_raw\": parsed[\"raw\"][:1200]\n",
    "    }\n",
    "\n",
    "# def onos_get(path):\n",
    "#     url = f\"{ONOS_API_ROOT}/{path.lstrip('/')}\"\n",
    "#     r = requests.get(url, auth=(USERNAME, PASSWORD), headers={\"Accept\":\"application/json\"}, timeout=15)\n",
    "#     r.raise_for_status()\n",
    "#     return r.json()\n",
    "\n",
    "def onos_get(path):\n",
    "    r = requests.get(f\"{ONOS_API_ROOT}/{path.lstrip('/')}\", auth=(USERNAME,PASSWORD), headers={\"Accept\":\"application/json\"}, timeout=15)\n",
    "    r.raise_for_status(); return r.json()\n",
    "\n",
    "def get_iface_for_port(device_id: str, port_no: int | str) -> str:\n",
    "    \"\"\"\n",
    "    Ask ONOS for port annotations to get iface name (e.g., s2-eth2).\n",
    "    Handles responses shaped like {\"ports\":[...]} or just a list.\n",
    "    Falls back to <bridge>-eth<port> if no annotation is found.\n",
    "    \"\"\"\n",
    "    data = onos_get(f\"devices/{device_id}/ports\")\n",
    "    # Normalize to a list of port dicts\n",
    "    if isinstance(data, dict) and \"ports\" in data:\n",
    "        ports_list = data[\"ports\"]\n",
    "    elif isinstance(data, list):\n",
    "        ports_list = data\n",
    "    else:\n",
    "        print(\"[DEBUG] Unexpected /devices/.../ports payload:\")\n",
    "        try:\n",
    "            print(json.dumps(data, indent=2)[:1200])\n",
    "        except Exception:\n",
    "            print(str(data)[:1200])\n",
    "        raise RuntimeError(\"Unexpected ONOS /ports response shape (see DEBUG).\")\n",
    "\n",
    "    target = int(port_no)\n",
    "    for p in ports_list:\n",
    "        # p.get(\"port\") is often a string \"2\" or an int 2\n",
    "        try:\n",
    "            p_no = int(p.get(\"port\"))\n",
    "        except Exception:\n",
    "            continue\n",
    "        if p_no == target:\n",
    "            ann = p.get(\"annotations\") or {}\n",
    "            name = ann.get(\"portName\") or ann.get(\"name\") or ann.get(\"port-name\")\n",
    "            if name:\n",
    "                return name\n",
    "\n",
    "    # If annotation missing, fall back to bridge-eth<port>\n",
    "    print(f\"[WARN] No iface annotation for {device_id} port {port_no}; falling back to bridge-eth{port_no}\")\n",
    "    br = find_bridge_for_device(device_id)\n",
    "    return f\"{br}-eth{port_no}\"\n",
    "\n",
    "def get_a_flow_rule_ONOS(device_id, flow_id):\n",
    "    \"\"\"\n",
    "    Fetch a single flow rule from ONOS by device_id and flow_id,\n",
    "    and display it in JSON format.\n",
    "    \"\"\"\n",
    "    if not device_id or not flow_id:\n",
    "        print(\"\\nBoth device_id and flow_id are required.\\n\")\n",
    "        return None\n",
    "\n",
    "    # Direct endpoint for a single flow rule\n",
    "    url = f\"{ONOS_BASE_URL}/{device_id}/{flow_id}\"\n",
    "    HEADERS = {\"Accept\": \"application/json\"}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS, auth=(USERNAME, PASSWORD))\n",
    "        if response.status_code == 200:\n",
    "            flow = response.json()\n",
    "            #print(json.dumps(flow, indent=4))  # Pretty-print JSON\n",
    "            return flow\n",
    "        elif response.status_code == 404:\n",
    "            print(f\"\\nFlow rule NOT found (Device: {device_id}, Flow ID: {flow_id})\\n\")\n",
    "            return None\n",
    "        else:\n",
    "            print(f\"\\nFailed to query ONOS. Status Code: {response.status_code}, Response: {response.text}\\n\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"\\nException occurred while fetching flow rule: {e}\\n\")\n",
    "        return None\n",
    "\n",
    "def _sudo(cmd, timeout=30):\n",
    "    return execute_command_full(f\"echo {shlex.quote(sudo_password)} | sudo -S bash -lc {shlex.quote(cmd)}\",\n",
    "                                timeout=timeout)\n",
    "\n",
    "def _ns(pid, cmd, timeout=90):\n",
    "    return execute_command_full(f\"echo {shlex.quote(sudo_password)} | sudo -S mnexec -a {pid} bash -lc {shlex.quote(cmd)}\",\n",
    "                                timeout=timeout)\n",
    "\n",
    "def _parse_iperf_sender(line: str):\n",
    "    m = re.search(\n",
    "        r'\\s(\\d+(?:\\.\\d+)?)\\s*(KBytes|MBytes|GBytes|TBytes|Bytes)\\s+'\n",
    "        r'(\\d+(?:\\.\\d+)?)\\s*(Kbits/sec|Mbits/sec|Gbits/sec|bits/sec)\\s+.*sender', line)\n",
    "    if not m:\n",
    "        raise RuntimeError(\"iperf sender parse failed: \" + line)\n",
    "    bytes_val = float(m.group(1)) * _UNITS_BYTES[m.group(2)]\n",
    "    bps_val   = float(m.group(3)) * _UNITS_BITS[m.group(4)]\n",
    "    return bps_val/1e6, int(bytes_val)\n",
    "\n",
    "def _iperf_text_summary(client_pid, dst_ip, dst_port, duration, extra_args=\"\"):\n",
    "    out = _ns(client_pid, f\"iperf3 -c {shlex.quote(dst_ip)} -p {int(dst_port)} -t {int(duration)} -f m {extra_args}\", \n",
    "              timeout=duration+60)\n",
    "    # prefer final [SUM] sender line; fallback to last 'sender'\n",
    "    lines = out.strip().splitlines()\n",
    "    target = None\n",
    "    for ln in lines:\n",
    "        if \"[SUM]\" in ln and \"sender\" in ln:\n",
    "            target = ln\n",
    "    if not target:\n",
    "        for ln in reversed(lines):\n",
    "            if \"sender\" in ln:\n",
    "                target = ln; break\n",
    "    # after failing to find 'sender', fallback to last line with 'sec' and 'bits/sec'\n",
    "    if not target:\n",
    "        for ln in reversed(lines):\n",
    "            if \"sec\" in ln and \"bits/sec\" in ln:\n",
    "                target = ln; break\n",
    "    if not target:\n",
    "        raise RuntimeError(\"Could not find iperf sender summary line.\")\n",
    "    mbps, bytes_sent = _parse_iperf_sender(target)\n",
    "    return {\"sender_mbps\": mbps, \"bytes_sent\": bytes_sent, \"sender_line\": target}\n",
    "\n",
    "# ---- ONOS flow counters helper (expects your get_a_flow_rule_ONOS) ----\n",
    "def _flow_counters(flow_json):\n",
    "    try:\n",
    "        f = flow_json[\"flows\"][0]\n",
    "        return int(f.get(\"packets\", 0)), int(f.get(\"bytes\", 0))\n",
    "    except Exception:\n",
    "        return None, None\n",
    "\n",
    "def verify_qos_flow_with_iperf(\n",
    "    flow_device_id: str, flow_id: str,\n",
    "    queue_device_id: str, queue_port_no: int, queue_id: int,\n",
    "    src_ip: str, dst_ip: str, dst_port: int,\n",
    "    target_mbps: float,\n",
    "    duration_sec: int = 8, parallel: int = 8, tcp_mss: int = 1200,\n",
    "    tolerance_pct: float = 10.0,\n",
    "    pin_path_flows: list | None = None,   # optional: list of (deviceId, out_port, direction) dicts you push via your push_flow_rule\n",
    "    protocol: str = \"tcp\",                # <-- NEW\n",
    "    udp_bw_mbps: float = 50.0,            # <-- NEW (target send rate for UDP)\n",
    "    udp_len_bytes: int = 1200,            # <-- NEW (datagram size)\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns a dict result and prints a human summary.\n",
    "    \"\"\"\n",
    "    # Resolve actors\n",
    "    iface = get_iface_for_port(queue_device_id, queue_port_no)\n",
    "    client_pid = get_mininet_host_pid(ip_to_host[src_ip])\n",
    "    server_pid = get_mininet_host_pid(ip_to_host[dst_ip])\n",
    "\n",
    "    proto = protocol.lower()\n",
    "    if proto == \"tcp\":\n",
    "        extra_args = f\"-P {parallel} -M {tcp_mss}\"\n",
    "    else:\n",
    "        # For UDP you must specify a target rate with -b (pick higher than your cap so the shaper clamps it)\n",
    "        extra_args = f\"-u -b {udp_bw_mbps}M -l {udp_len_bytes} -P {max(1, parallel)}\"\n",
    "\n",
    "    # Optional: push pinning flows if provided (expects caller to craft correct selectors)\n",
    "    pushed_ids = []\n",
    "    if pin_path_flows:\n",
    "        for item in pin_path_flows:\n",
    "            dev, outp, direction = item[\"deviceId\"], item[\"out_port\"], item[\"direction\"]\n",
    "            if direction == \"forward\":\n",
    "                sel = build_pin_selector_forward(src_ip, dst_ip, dst_port, proto=proto)\n",
    "            else:\n",
    "                sel = build_pin_selector_reverse(src_ip, dst_ip, dst_port, proto=proto)\n",
    "            flow_body = {\n",
    "                \"flows\": [{\n",
    "                    \"priority\": 65000,\n",
    "                    \"isPermanent\": True,\n",
    "                    \"deviceId\": dev,\n",
    "                    \"treatment\": {\"instructions\":[ {\"type\":\"OUTPUT\",\"port\": str(outp)} ]},\n",
    "                    \"selector\": sel\n",
    "                }]}\n",
    "            fid = push_flow_rule(dev, flow_body)\n",
    "            pushed_ids.append((dev, fid))\n",
    "\n",
    "    # Best-effort offload guard at egress\n",
    "    try: _sudo(f\"ethtool -K {shlex.quote(iface)} gro off gso off tso off\", timeout=6)\n",
    "    except Exception: pass\n",
    "\n",
    "    # 1) Snapshots before\n",
    "    #print(\"\\nSnapshot 1: before\\n\")\n",
    "    flow_before = get_a_flow_rule_ONOS(flow_device_id, flow_id) or {}\n",
    "    f_pkts0, f_bytes0 = _flow_counters(flow_before)\n",
    "    q0 = snapshot_queue(iface, queue_id)\n",
    "\n",
    "    # 2) Run iperf\n",
    "    start_iperf_server(server_pid, dst_port)\n",
    "    time.sleep(0.6)\n",
    "    t0 = time.time()\n",
    "    iptxt = _iperf_text_summary(client_pid, dst_ip, dst_port, duration_sec, extra_args=extra_args)\n",
    "    t1 = time.time()\n",
    "    stop_iperf_server(server_pid, dst_port)\n",
    "    time.sleep(0.8)\n",
    "\n",
    "    # 3) Snapshots after\n",
    "    #print(\"\\nSnapshot 1: before\\n\")\n",
    "    flow_after = get_a_flow_rule_ONOS(flow_device_id, flow_id) or {}\n",
    "    f_pkts1, f_bytes1 = _flow_counters(flow_after)\n",
    "    q1 = snapshot_queue(iface, queue_id)\n",
    "\n",
    "    # 4) Deltas\n",
    "    elapsed = max(0.001, t1 - t0)\n",
    "    q_bytes = None if (q0[\"tx_bytes\"] is None or q1[\"tx_bytes\"] is None) else (q1[\"tx_bytes\"] - q0[\"tx_bytes\"])\n",
    "    q_mbps  = (q_bytes * 8 / elapsed / 1e6) if q_bytes is not None else None\n",
    "    f_pkts_delta = (f_pkts1 - f_pkts0) if (f_pkts0 is not None and f_pkts1 is not None) else None\n",
    "    f_bytes_delta = (f_bytes1 - f_bytes0) if (f_bytes0 is not None and f_bytes1 is not None) else None\n",
    "    f_mbps = (f_bytes_delta * 8 / elapsed / 1e6) if (f_bytes_delta is not None) else None\n",
    "\n",
    "    # 5) Decision\n",
    "    rate_ok   = (q_mbps is not None) and (abs(q_mbps - target_mbps) <= (tolerance_pct/100.0)*target_mbps)\n",
    "    packets_ok= (f_pkts_delta or 0) > 0\n",
    "    verdict   = \"PASS\" if (rate_ok and packets_ok) else \"FAIL\"\n",
    "\n",
    "    # Print summary\n",
    "    print(\"\\n=== QoS FLOW VERIFICATION ===\")\n",
    "    print(f\"Flow {flow_id} @ {flow_device_id}  → selector should match {protocol} dst {dst_port} to {dst_ip}\")\n",
    "    print(f\"Egress iface={iface} queue={queue_id}  target≈{target_mbps:.3f} Mbps  tol=±{tolerance_pct:.0f}%\")\n",
    "    print(f\"iperf sender: {iptxt['sender_mbps']:.3f} Mbps  bytes≈{iptxt['bytes_sent']}\")\n",
    "    print(f\"Queue Δbytes={q_bytes} over {elapsed:.3f}s  → queue_measured≈{(q_mbps or 0):.3f} Mbps\")\n",
    "    print(f\"Flow Δ: packets={f_pkts_delta} bytes={f_bytes_delta}  (flow_measured≈{(f_mbps or 0):.3f} Mbps)\")\n",
    "    print(f\"Queue caps (min/max): {q0['min_rate']} / {q0['max_rate']}  →  {q1['min_rate']} / {q1['max_rate']}\")\n",
    "    print(\"VERDICT:\", verdict)\n",
    "\n",
    "    return {\n",
    "        \"elapsed_sec\": elapsed,\n",
    "        \"iperf_sender_mbps\": iptxt[\"sender_mbps\"],\n",
    "        \"queue_measured_mbps\": q_mbps,\n",
    "        \"queue_delta_bytes\": q_bytes,\n",
    "        \"flow_delta_packets\": f_pkts_delta,\n",
    "        \"flow_delta_bytes\": f_bytes_delta,\n",
    "        \"flow_measured_mbps\": f_mbps,\n",
    "        \"verdict\": verdict\n",
    "    }\n",
    "\n",
    "def ensure_qos_cap(device_id: str, port_no: int, qid: int, min_bps: int, max_bps: int, port_cap_bps: int = 100_000_000):\n",
    "    iface = get_iface_for_port(device_id, port_no)\n",
    "    print(f\"[INFO] Setting QoS on {iface}: q{qid} min={min_bps} max={max_bps}, root max-rate={port_cap_bps}bps\")\n",
    "    sudo_sh(f\"ovs-vsctl --if-exists clear Port {shlex.quote(iface)} qos\")\n",
    "    cmd = (\n",
    "        \"ovs-vsctl \"\n",
    "        f\"-- --id=@q create Queue other-config:min-rate={min_bps} other-config:max-rate={max_bps} \"\n",
    "        f\"-- --id=@qos create QoS type=linux-htb other-config:max-rate={port_cap_bps} queues:{qid}=@q \"\n",
    "        f\"-- set Port {shlex.quote(iface)} qos=@qos\"\n",
    "    )\n",
    "    print(sudo_sh(cmd))\n",
    "    print(sudo_sh(f\"ovs-appctl -t ovs-vswitchd qos/show {shlex.quote(iface)}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Diamond topology wiring helpers (drop-in) ---\n",
    "\n",
    "SW_OF = {\n",
    "    \"1\": \"of:0000000000000001\",  # s1\n",
    "    \"2\": \"of:0000000000000002\",  # s2\n",
    "    \"3\": \"of:0000000000000003\",  # s3\n",
    "    \"4\": \"of:0000000000000004\",  # s4\n",
    "}\n",
    "\n",
    "HOSTS = {\n",
    "    \"h1\": \"10.0.1.1\",\n",
    "    \"h2\": \"10.0.1.2\",\n",
    "    \"h3\": \"10.0.1.3\",\n",
    "    \"h4\": \"10.0.1.4\",\n",
    "}\n",
    "\n",
    "# Host attachment (edge switch, access port) from your Mininet build\n",
    "HOST_ATTACH = {\n",
    "    HOSTS[\"h1\"]: (SW_OF[\"1\"], 3),  # h1 -> s1:3\n",
    "    HOSTS[\"h2\"]: (SW_OF[\"1\"], 4),  # h2 -> s1:4\n",
    "    HOSTS[\"h3\"]: (SW_OF[\"4\"], 3),  # h3 -> s4:3\n",
    "    HOSTS[\"h4\"]: (SW_OF[\"4\"], 4),  # h4 -> s4:4\n",
    "}\n",
    "\n",
    "# --- New helpers to satisfy the “missing src/dst” rules ---\n",
    "\n",
    "def choose_dst_for_port(device_id: str, port_no: int) -> str:\n",
    "    \"\"\"\n",
    "    Pick a destination IP that makes forward traffic EXIT on (device_id, port_no).\n",
    "    Uses your diamond wiring.\n",
    "    \"\"\"\n",
    "    # Final-hop host ports first\n",
    "    if device_id == SW_OF[\"1\"] and port_no == 3:  # s1 -> h1\n",
    "        return HOSTS[\"h1\"]\n",
    "    if device_id == SW_OF[\"1\"] and port_no == 4:  # s1 -> h2\n",
    "        return HOSTS[\"h2\"]\n",
    "    if device_id == SW_OF[\"4\"] and port_no == 3:  # s4 -> h3\n",
    "        return HOSTS[\"h3\"]\n",
    "    if device_id == SW_OF[\"4\"] and port_no == 4:  # s4 -> h4\n",
    "        return HOSTS[\"h4\"]\n",
    "\n",
    "    # Inter-switch egress: choose a host \"behind\" the far side so packets must traverse this link\n",
    "    # s1:1->s2 (right), s1:2->s3 (right) → pick a right-side host (h3 default)\n",
    "    if device_id == SW_OF[\"1\"] and port_no in (1, 2):\n",
    "        return HOSTS[\"h3\"]\n",
    "    # s2:2->s4 (right) → pick right-side host; s2:1->s1 (left) → pick left-side host\n",
    "    if device_id == SW_OF[\"2\"] and port_no == 2:\n",
    "        return HOSTS[\"h3\"]\n",
    "    if device_id == SW_OF[\"2\"] and port_no == 1:\n",
    "        return HOSTS[\"h1\"]\n",
    "    # s3:2->s4 (right) → right host; s3:1->s1 (left) → left host\n",
    "    if device_id == SW_OF[\"3\"] and port_no == 2:\n",
    "        return HOSTS[\"h3\"]\n",
    "    if device_id == SW_OF[\"3\"] and port_no == 1:\n",
    "        return HOSTS[\"h1\"]\n",
    "    # s4 inter-switch (rare in your tests): port1->s2 (left) pick left host; port2->s3 (left) pick left host\n",
    "    if device_id == SW_OF[\"4\"] and port_no in (1, 2):\n",
    "        return HOSTS[\"h1\"]\n",
    "\n",
    "    # Fallback\n",
    "    return HOSTS[\"h3\"]\n",
    "\n",
    "def fill_missing_endpoints(plan: dict, device_id: str, port_no: int) -> tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Apply your policy:\n",
    "      - If only dst is present → choose src that forces egress at (device,port)\n",
    "      - If only src is present → choose dst that forces egress at (device,port)\n",
    "      - If both missing → pick both to force egress at (device,port)\n",
    "      - Ensure src != dst\n",
    "    \"\"\"\n",
    "    src = plan.get(\"src_ip\")\n",
    "    dst = plan.get(\"dst_ip\")\n",
    "\n",
    "    # Normalize empty strings to None\n",
    "    src = src or None\n",
    "    dst = dst or None\n",
    "\n",
    "    if dst is None:\n",
    "        dst = choose_dst_for_port(device_id, port_no)\n",
    "    if src is None:\n",
    "        src = choose_src_for_port(device_id, port_no)\n",
    "\n",
    "    # If they accidentally collide, flip src to the opposite side\n",
    "    if src == dst:\n",
    "        # If dst is on right side, move src to left; else move to right\n",
    "        try:\n",
    "            dst_edge, _ = _edge_for_ip(dst)\n",
    "        except Exception:\n",
    "            dst_edge = SW_OF[\"4\"]  # assume right if unknown\n",
    "        src = HOSTS[\"h1\"] if dst_edge in (SW_OF[\"3\"], SW_OF[\"4\"]) else HOSTS[\"h3\"]\n",
    "\n",
    "    return src, dst\n",
    "\n",
    "def _strip32(ip: str) -> str:\n",
    "    return ip.split(\"/\", 1)[0]\n",
    "\n",
    "def find_edge_for_ip(dst_ip: str):\n",
    "    \"\"\"Return (deviceId, portNo) for the host that owns dst_ip.\n",
    "       Prefer static map; fall back to ONOS /hosts if needed.\"\"\"\n",
    "    ip = _strip32(dst_ip)\n",
    "    if ip in HOST_ATTACH:\n",
    "        return HOST_ATTACH[ip]\n",
    "    # Optional fallback via ONOS:\n",
    "    try:\n",
    "        js = onos_get(f\"hosts?ip={ip}\")\n",
    "        lst = js.get(\"hosts\", js if isinstance(js, list) else [])\n",
    "        if lst:\n",
    "            locs = lst[0].get(\"locations\") or lst[0].get(\"location\") or []\n",
    "            if locs:\n",
    "                dev = locs[0].get(\"elementId\") or locs[0].get(\"device\") or locs[0].get(\"element\")\n",
    "                port = int(locs[0].get(\"port\"))\n",
    "                return dev, port\n",
    "    except Exception:\n",
    "        pass\n",
    "    raise RuntimeError(f\"Could not infer edge device/port for dst_ip={dst_ip}\")\n",
    "\n",
    "def infer_enforcement_point(plan):\n",
    "    \"\"\"\n",
    "    Decide where to enforce if device/port not fully specified.\n",
    "    Preference:\n",
    "      1) If plan.device_id & plan.port_no given → use those\n",
    "      2) Else enforce at the final hop to the destination host (works for h1..h4).\n",
    "    \"\"\"\n",
    "    device_id, port_no = plan.get(\"device_id\"), plan.get(\"port_no\")\n",
    "    if device_id and port_no:\n",
    "        return device_id, port_no\n",
    "    return find_edge_for_ip(plan[\"dst_ip\"])\n",
    "\n",
    "def _edge_for_ip(ip: str):\n",
    "    ip = ip.split(\"/\", 1)[0]\n",
    "    if ip in HOST_ATTACH:\n",
    "        return HOST_ATTACH[ip]\n",
    "    # Optional: try ONOS if not in static map (kept simple)\n",
    "    try:\n",
    "        js = onos_get(f\"hosts?ip={ip}\")\n",
    "        lst = js.get(\"hosts\", js if isinstance(js, list) else [])\n",
    "        if lst:\n",
    "            loc = (lst[0].get(\"locations\") or lst[0].get(\"location\") or [])[0]\n",
    "            return loc[\"elementId\"], int(loc[\"port\"])\n",
    "    except Exception:\n",
    "        pass\n",
    "    raise RuntimeError(f\"No edge mapping for IP {ip}\")\n",
    "\n",
    "def _is(dev: str, n: str) -> bool:\n",
    "    \"\"\"dev == SW_OF[n]?\"\"\"\n",
    "    return dev == SW_OF[n]\n",
    "\n",
    "def choose_src_for_port(device_id: str, port_no: int) -> str:\n",
    "    \"\"\"\n",
    "    Pick a source IP that will make *forward* traffic egress on (device_id, port_no).\n",
    "    This aligns the traffic direction with your enforcement point so your queue is actually exercised.\n",
    "    \"\"\"\n",
    "    # s1: final-host ports 3/4 → pick a source on the right (h3)\n",
    "    if _is(device_id, \"1\"):\n",
    "        if port_no in (3, 4):        # s1 -> h1/h2\n",
    "            return HOSTS[\"h3\"]\n",
    "        elif port_no in (1, 2):      # s1 -> s2/s3 (inter-switch)\n",
    "            return HOSTS[\"h1\"]       # left host causes egress at s1\n",
    "    # s2: port2 to s4 → src on left; port1 to s1 → src on right\n",
    "    if _is(device_id, \"2\"):\n",
    "        return HOSTS[\"h1\"] if port_no == 2 else HOSTS[\"h3\"]\n",
    "    # s3: port2 to s4 → src on left; port1 to s1 → src on right\n",
    "    if _is(device_id, \"3\"):\n",
    "        return HOSTS[\"h1\"] if port_no == 2 else HOSTS[\"h3\"]\n",
    "    # s4: final-host ports 3/4 → src on left; inter-switch (1/2) → src on right\n",
    "    if _is(device_id, \"4\"):\n",
    "        if port_no in (3, 4):        # s4 -> h3/h4\n",
    "            return HOSTS[\"h1\"]\n",
    "        elif port_no in (1, 2):      # s4 -> s2/s3\n",
    "            return HOSTS[\"h3\"]\n",
    "    # Fallback\n",
    "    return HOSTS[\"h1\"]\n",
    "\n",
    "def make_pin_path_flows(device_id: str, port_no: int,\n",
    "                        src_ip: str, dst_ip: str, dst_port: int,\n",
    "                        protocol: str = \"tcp\"):\n",
    "    \"\"\"\n",
    "    Build a pinning plan so src_ip -> dst_ip forward traffic *must* traverse (device_id, port_no).\n",
    "\n",
    "    Returns a list of dicts: [{\"deviceId\":..., \"out_port\":..., \"direction\":\"forward|reverse\"}, ...]\n",
    "    - For TCP: includes reverse pins (ACK path) to reduce variability.\n",
    "    - For UDP: forward-only pins (reverse is optional, skipped here).\n",
    "    \"\"\"\n",
    "    proto = protocol.lower()\n",
    "    is_udp = (proto == \"udp\")\n",
    "\n",
    "    pins = []\n",
    "    src_edge_dev, src_edge_port = _edge_for_ip(src_ip)\n",
    "    dst_edge_dev, dst_edge_port = _edge_for_ip(dst_ip)\n",
    "\n",
    "    def add(dev, outp, direction):\n",
    "        pins.append({\"deviceId\": dev, \"out_port\": int(outp), \"direction\": direction})\n",
    "\n",
    "    # ----- cases by enforcement point -----\n",
    "\n",
    "    # s4 final hop to host (port 3 or 4: h3/h4)\n",
    "    if _is(device_id, \"4\") and port_no in (3, 4):\n",
    "        # Forward: steer from the left toward s4 via s1->s3->s4\n",
    "        # If source is already on the right (h3/h4), nothing to pin on the way in.\n",
    "        if _is(src_edge_dev, \"1\"):\n",
    "            add(SW_OF[\"1\"], 2, \"forward\")   # s1 -> s3\n",
    "            add(SW_OF[\"3\"], 2, \"forward\")   # s3 -> s4\n",
    "        elif _is(src_edge_dev, \"4\"):\n",
    "            pass  # already on s4 side\n",
    "        elif _is(src_edge_dev, \"2\"):\n",
    "            add(SW_OF[\"2\"], 2, \"forward\")   # s2 -> s4\n",
    "        elif _is(src_edge_dev, \"3\"):\n",
    "            add(SW_OF[\"3\"], 2, \"forward\")   # s3 -> s4\n",
    "\n",
    "        # Reverse (TCP): s4 -> s3 -> s1 -> host(src)\n",
    "        if not is_udp:\n",
    "            if _is(src_edge_dev, \"1\"):\n",
    "                add(SW_OF[\"4\"], 2, \"reverse\")   # s4 -> s3\n",
    "                add(SW_OF[\"3\"], 1, \"reverse\")   # s3 -> s1\n",
    "                add(SW_OF[\"1\"], src_edge_port, \"reverse\")  # s1 -> h1/h2\n",
    "            elif _is(src_edge_dev, \"4\"):\n",
    "                add(SW_OF[\"4\"], src_edge_port, \"reverse\")  # local s4 -> h3/h4\n",
    "\n",
    "    # s1 final hop to host (port 3 or 4: h1/h2)\n",
    "    elif _is(device_id, \"1\") and port_no in (3, 4):\n",
    "        # Forward: steer from the right toward s1 via s4->s3->s1\n",
    "        if _is(src_edge_dev, \"4\"):\n",
    "            add(SW_OF[\"4\"], 2, \"forward\")   # s4 -> s3\n",
    "            add(SW_OF[\"3\"], 1, \"forward\")   # s3 -> s1\n",
    "        elif _is(src_edge_dev, \"1\"):\n",
    "            pass  # already on s1 side\n",
    "\n",
    "        # Reverse (TCP): s1 -> s3 -> s4 -> host(src)\n",
    "        if not is_udp:\n",
    "            if _is(src_edge_dev, \"4\"):\n",
    "                add(SW_OF[\"1\"], 2, \"reverse\")   # s1 -> s3\n",
    "                add(SW_OF[\"3\"], 2, \"reverse\")   # s3 -> s4\n",
    "                add(SW_OF[\"4\"], src_edge_port, \"reverse\")  # s4 -> h3/h4\n",
    "            elif _is(src_edge_dev, \"1\"):\n",
    "                add(SW_OF[\"1\"], src_edge_port, \"reverse\")  # local s1 -> h1/h2\n",
    "\n",
    "    # s1 inter-switch egress\n",
    "    elif _is(device_id, \"1\") and port_no == 2:\n",
    "        # Forward: use s1->s3->s4 path\n",
    "        add(SW_OF[\"1\"], 2, \"forward\")\n",
    "        add(SW_OF[\"3\"], 2, \"forward\")\n",
    "        # Reverse (TCP): s4 -> s3 -> s1 -> host(src)\n",
    "        if not is_udp:\n",
    "            add(SW_OF[\"4\"], 2, \"reverse\")\n",
    "            add(SW_OF[\"3\"], 1, \"reverse\")\n",
    "            add(SW_OF[\"1\"], src_edge_port, \"reverse\")\n",
    "    elif _is(device_id, \"1\") and port_no == 1:\n",
    "        # Forward: use s1->s2->s4 path\n",
    "        add(SW_OF[\"1\"], 1, \"forward\")\n",
    "        add(SW_OF[\"2\"], 2, \"forward\")\n",
    "        # Reverse (TCP): s4 -> s2 -> s1 -> host(src)\n",
    "        if not is_udp:\n",
    "            add(SW_OF[\"4\"], 1, \"reverse\")\n",
    "            add(SW_OF[\"2\"], 1, \"reverse\")\n",
    "            add(SW_OF[\"1\"], src_edge_port, \"reverse\")\n",
    "\n",
    "    # s2 inter-switch egress\n",
    "    elif _is(device_id, \"2\") and port_no == 2:\n",
    "        # Forward: s1 -> s2 -> s4\n",
    "        add(SW_OF[\"1\"], 1, \"forward\")\n",
    "        add(SW_OF[\"2\"], 2, \"forward\")\n",
    "        if not is_udp:\n",
    "            add(SW_OF[\"4\"], 1, \"reverse\")\n",
    "            add(SW_OF[\"2\"], 1, \"reverse\")\n",
    "            add(SW_OF[\"1\"], src_edge_port, \"reverse\")\n",
    "    elif _is(device_id, \"2\") and port_no == 1:\n",
    "        # Forward: s4 -> s2 -> s1\n",
    "        add(SW_OF[\"4\"], 1, \"forward\")\n",
    "        add(SW_OF[\"2\"], 1, \"forward\")\n",
    "        if not is_udp:\n",
    "            add(SW_OF[\"1\"], 1, \"reverse\")\n",
    "            add(SW_OF[\"2\"], 2, \"reverse\")\n",
    "            add(SW_OF[\"4\"], src_edge_port, \"reverse\")\n",
    "\n",
    "    # s3 inter-switch egress\n",
    "    elif _is(device_id, \"3\") and port_no == 2:\n",
    "        # Forward: s1 -> s3 -> s4\n",
    "        add(SW_OF[\"1\"], 2, \"forward\")\n",
    "        add(SW_OF[\"3\"], 2, \"forward\")\n",
    "        if not is_udp:\n",
    "            add(SW_OF[\"4\"], 2, \"reverse\")\n",
    "            add(SW_OF[\"3\"], 1, \"reverse\")\n",
    "            add(SW_OF[\"1\"], src_edge_port, \"reverse\")\n",
    "    elif _is(device_id, \"3\") and port_no == 1:\n",
    "        # Forward: s4 -> s3 -> s1\n",
    "        add(SW_OF[\"4\"], 2, \"forward\")\n",
    "        add(SW_OF[\"3\"], 1, \"forward\")\n",
    "        if not is_udp:\n",
    "            add(SW_OF[\"1\"], 2, \"reverse\")\n",
    "            add(SW_OF[\"3\"], 2, \"reverse\")\n",
    "            add(SW_OF[\"4\"], src_edge_port, \"reverse\")\n",
    "\n",
    "    # s4 inter-switch egress (rare in your tests but supported)\n",
    "    elif _is(device_id, \"4\") and port_no in (1, 2):\n",
    "        # To use s4->(2?3?) link in *forward* direction, src should be on the right.\n",
    "        # Forward: none if src is already on s4; else steer toward s4 via right path\n",
    "        if _is(src_edge_dev, \"1\"):\n",
    "            add(SW_OF[\"1\"], 2, \"forward\")  # prefer via s3\n",
    "            add(SW_OF[\"3\"], 2, \"forward\")\n",
    "        # Reverse (TCP): symmetric back to src\n",
    "        if not is_udp:\n",
    "            if port_no == 1:\n",
    "                add(SW_OF[\"4\"], 1, \"reverse\"); add(SW_OF[\"2\"], 1, \"reverse\")\n",
    "                add(SW_OF[\"1\"], src_edge_port, \"reverse\")\n",
    "            else:\n",
    "                add(SW_OF[\"4\"], 2, \"reverse\"); add(SW_OF[\"3\"], 1, \"reverse\")\n",
    "                add(SW_OF[\"1\"], src_edge_port, \"reverse\")\n",
    "\n",
    "    else:\n",
    "        # Fallback: route via s1->s3->s4 with TCP reverse symmetry\n",
    "        add(SW_OF[\"1\"], 2, \"forward\")\n",
    "        add(SW_OF[\"3\"], 2, \"forward\")\n",
    "        if not is_udp:\n",
    "            add(SW_OF[\"4\"], 2, \"reverse\")\n",
    "            add(SW_OF[\"3\"], 1, \"reverse\")\n",
    "            add(SW_OF[\"1\"], src_edge_port, \"reverse\")\n",
    "\n",
    "    # For UDP, we intentionally omit reverse pins (ACK-less).\n",
    "    # if is_udp:\n",
    "    #     pins = [p for p in pins if p[\"direction\"] == \"forward\"]\n",
    "\n",
    "    # --- Never overshadow the QoS rule on the enforcement port ---\n",
    "    # Drop any FORWARD pin that sits on the enforcement device+port.\n",
    "    pins = [p for p in pins\n",
    "            if not (p[\"direction\"] == \"forward\"\n",
    "                    and p[\"deviceId\"] == device_id\n",
    "                    and int(p[\"out_port\"]) == int(port_no))]\n",
    "\n",
    "    # For UDP, keep forward-only (already done above)\n",
    "    if is_udp:\n",
    "        pins = [p for p in pins if p[\"direction\"] == \"forward\"]\n",
    "\n",
    "    # De-duplicate [(dev,port,direction)] triples, keep first\n",
    "    seen, uniq = set(), []\n",
    "    for p in pins:\n",
    "        key = (p[\"deviceId\"], int(p[\"out_port\"]), p[\"direction\"])\n",
    "        if key in seen: \n",
    "            continue\n",
    "        seen.add(key); uniq.append(p)\n",
    "    return uniq\n",
    "    #return pins\n",
    "\n",
    "def normalize_device_id(dev: str | None) -> str | None:\n",
    "    if not dev:\n",
    "        return dev\n",
    "    dev = dev.strip()\n",
    "\n",
    "    # openflow:<decimal>\n",
    "    m = re.fullmatch(r'openflow:(\\d+)', dev, flags=re.I)\n",
    "    if m:\n",
    "        return f\"of:{int(m.group(1)):016x}\"\n",
    "\n",
    "    # openflow:<hex> or openflow:0x<hex>\n",
    "    m = re.fullmatch(r'openflow:(?:0x)?([0-9a-fA-F]+)', dev, flags=re.I)\n",
    "    if m:\n",
    "        return f\"of:{int(m.group(1), 16):016x}\"\n",
    "\n",
    "    # of:<decimal>\n",
    "    m = re.fullmatch(r'of:(\\d+)', dev, flags=re.I)\n",
    "    if m:\n",
    "        return f\"of:{int(m.group(1)):016x}\"\n",
    "\n",
    "    # of:<hex already>\n",
    "    if dev.lower().startswith(\"of:\"):\n",
    "        return \"of:\" + dev[3:].lower()\n",
    "\n",
    "    return dev\n",
    "\n",
    "def parse_intent_text(slicing_info, src_ip, dst_ip):\n",
    "\n",
    "                slicing_queue_id = slicing_info['queue_id'] if (slicing_info['queue_id']) != \"\" else 1\n",
    "                proto = slicing_info['traffic_type'] if \"udp\" in slicing_info['traffic_type'] else (\"tcp\" if \"tcp\" in slicing_info['traffic_type'] or \"http\" in slicing_info['traffic_type'] else \"tcp\")\n",
    "                slicing_l4_port = slicing_info['l4_port'] if slicing_info['l4_port'] != \"\" else 80\n",
    "                port_no = extract_port_number(slicing_info['port_id'])\n",
    "                device_id = extract_switch_id(slicing_info['switch_id'])\n",
    "                device_id = normalize_device_id (device_id)\n",
    "\n",
    "                return {\n",
    "                    \"protocol\": proto,\n",
    "                    \"dst_port\": slicing_l4_port,\n",
    "                    \"device_id\": device_id,   # may be None\n",
    "                    \"port_no\": port_no,       # may be None, it means output interface number\n",
    "                    \"queue_id\": slicing_queue_id,\n",
    "                    \"src_ip\": src_ip,         # may be None\n",
    "                    \"dst_ip\": dst_ip,         # may be None\n",
    "                }\n",
    "\n",
    "def intent_to_verifier_args(slicing_info, old_src_ip, old_dst_ip, target_mbps: float = 4.0):\n",
    "    \n",
    "    plan = parse_intent_text(slicing_info, old_src_ip, old_dst_ip)\n",
    "\n",
    "    # 1) Decide enforcement point:\n",
    "    #    - If device/port specified → use them\n",
    "    #    - Else → final hop to dst (and if dst missing, we’ll still pick a consistent dst next)\n",
    "    device_id, port_no = infer_enforcement_point(plan)\n",
    "    plan[\"device_id\"], plan[\"port_no\"] = device_id, port_no\n",
    "\n",
    "    # 2) Fill missing src/dst according to your policy (and ensure src != dst)\n",
    "    src_ip, dst_ip = fill_missing_endpoints(plan, device_id, port_no)\n",
    "    plan[\"src_ip\"], plan[\"dst_ip\"] = src_ip, dst_ip\n",
    "\n",
    "    # 3) Build verifier args\n",
    "    args = {\n",
    "        \"flow_device_id\":  device_id,\n",
    "        \"queue_device_id\": device_id,\n",
    "        \"queue_port_no\":   port_no,\n",
    "        \"queue_id\":        plan[\"queue_id\"],\n",
    "        \"src_ip\":          src_ip,\n",
    "        \"dst_ip\":          dst_ip,\n",
    "        \"dst_port\":    plan[\"dst_port\"],   # if your verifier expects dst_port, duplicate the key:\n",
    "        \"dst_port\":        plan[\"dst_port\"],\n",
    "        \"target_mbps\":     target_mbps,\n",
    "    }\n",
    "\n",
    "    # 4) Pin plan (TCP includes reverse, UDP forward-only)\n",
    "    pins = make_pin_path_flows(device_id, port_no, src_ip, dst_ip, plan[\"dst_port\"], plan[\"protocol\"])\n",
    "    return args, pins, plan\n",
    "\n",
    "def delete_flow_rule(device_id: str, flow_id: str):\n",
    "    url = f\"{ONOS_BASE_URL}/{device_id}/{flow_id}\"\n",
    "    r = requests.delete(url, auth=(USERNAME, PASSWORD), headers={\"Accept\":\"application/json\"}, timeout=15)\n",
    "    if r.status_code not in (200,202,204):\n",
    "        print(f\"[WARN] Delete failed for {device_id}/{flow_id}: {r.status_code} {r.text}\")\n",
    "\n",
    "def _pin_selector(direction: str, protocol: str, src_ip: str, dst_ip: str, dst_port: int):\n",
    "    \"\"\"Build protocol-aware 5-tuple for forward/reverse.\"\"\"\n",
    "    is_udp = protocol.lower() == \"udp\"\n",
    "    crit = [\n",
    "        {\"type\":\"ETH_TYPE\",\"ethType\":\"0x800\"},\n",
    "        {\"type\":\"IP_PROTO\",\"protocol\": 17 if is_udp else 6},\n",
    "    ]\n",
    "    if direction == \"forward\":\n",
    "        crit += [\n",
    "            {\"type\":\"IPV4_SRC\",\"ip\": f\"{src_ip}/32\"},\n",
    "            {\"type\":\"IPV4_DST\",\"ip\": f\"{dst_ip}/32\"},\n",
    "            ({\"type\":\"UDP_DST\",\"udpPort\": dst_port} if is_udp else {\"type\":\"TCP_DST\",\"tcpPort\": dst_port}),\n",
    "        ]\n",
    "    else:  # reverse\n",
    "        crit += [\n",
    "            {\"type\":\"IPV4_SRC\",\"ip\": f\"{dst_ip}/32\"},\n",
    "            {\"type\":\"IPV4_DST\",\"ip\": f\"{src_ip}/32\"},\n",
    "            ({\"type\":\"UDP_SRC\",\"udpPort\": dst_port} if is_udp else {\"type\":\"TCP_SRC\",\"tcpPort\": dst_port}),\n",
    "        ]\n",
    "    return {\"criteria\": crit}\n",
    "\n",
    "def install_pins_from_plan(pins: list, src_ip: str, dst_ip: str, dst_port: int, protocol: str) -> list:\n",
    "    \"\"\"Install the pin flows returned by make_pin_path_flows(...).\n",
    "       Returns [(deviceId, flowId), ...] for cleanup.\"\"\"\n",
    "    pushed = []\n",
    "    for p in pins:\n",
    "        dev = p[\"deviceId\"]; outp = str(p[\"out_port\"]); direction = p[\"direction\"]\n",
    "        flow_body = {\n",
    "            \"flows\": [{\n",
    "                \"deviceId\": dev,\n",
    "                \"isPermanent\": True,\n",
    "                \"priority\": 65000,\n",
    "                \"selector\": _pin_selector(direction, protocol, src_ip, dst_ip, dst_port),\n",
    "                \"treatment\": {\"instructions\": [ {\"type\":\"OUTPUT\",\"port\": outp} ]}\n",
    "            }]}\n",
    "        fid = push_flow_rule(dev, flow_body)\n",
    "        if fid:\n",
    "            pushed.append((dev, fid))\n",
    "    return pushed\n",
    "\n",
    "def unpin_path(pushed: list):\n",
    "    for dev, fid in pushed:\n",
    "        delete_flow_rule(dev, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent = \"Forward TCP traffic on port 80 destined for 10.0.1.3 via interface 2, assigning it to queue 1 for prioritized handling in switch 2.\"\n",
    "#intent = \"In switch 4, block all IPv4 traffic from 10.0.1.1 to 10.0.1.4 with a high priority, ensuring the switch operates as a firewall.\"\n",
    "#intent = \"In switch 4, traffic destined for 10.0.1.4 should use port 4.\"\n",
    "\n",
    "current_time = time.time()\n",
    "\n",
    "slicing_info = run_LLM_Slice(intent)\n",
    "\n",
    "#create_two_queue_for_switch_handler(slicing_info)\n",
    "\n",
    "deployment_status, flow_id, device_id, translated_flow_rule, operational_flow_rule = end_to_end_IBN(intent)\n",
    "\n",
    "if 'use_queue' in slicing_info and slicing_info['use_queue'] == 1:\n",
    "    #Creating one queue\n",
    "    expected_queue_rate_mbps = 4.0\n",
    "    port_max = 100_000_000  # 100 Mbps cap for the port QoS root\n",
    "    min_rate = max_rate = int(expected_queue_rate_mbps * 1_000_000)\n",
    "    slicing_queue_id = slicing_info['queue_id'] if (slicing_info['queue_id']) != \"\" else 1\n",
    "    proto = slicing_info['traffic_type'] if \"udp\" in slicing_info['traffic_type'] else (\"tcp\" if \"tcp\" in slicing_info['traffic_type'] or \"http\" in slicing_info['traffic_type'] else \"tcp\")\n",
    "    slicing_l4_port = slicing_info['l4_port'] if slicing_info['l4_port'] != \"\" else 80\n",
    "    port_no = extract_port_number(slicing_info['port_id'])\n",
    "    \n",
    "    ensure_qos_cap(device_id, port_no, slicing_queue_id, min_bps=min_rate, max_bps=max_rate, port_cap_bps=100_000_000)\n",
    "\n",
    "global llm_caller_flag\n",
    "\n",
    "if (deployment_status == True):\n",
    "        proc_time_s = (time.time() - current_time)\n",
    "        print(\"\\n\\nSuccessfully translated and installed the rule in ODL SDN Controller. Time taken: \", proc_time_s)\n",
    "        src_host, dst_host, src_ip, dst_ip = extract_host_and_ip_onos(translated_flow_rule)\n",
    "        flow_rule_type, flow_rule_specificity = classify_onos_flow_rule(translated_flow_rule)\n",
    "        \n",
    "        # Example of appending an intent to IntentStore\n",
    "        append_intent_to_store(\n",
    "            \"IntentStore_ONOS.jsonl\",\n",
    "            nl_intent=intent,\n",
    "            json_flow_rule=translated_flow_rule,\n",
    "            device_id=device_id,\n",
    "            flow_id=flow_id,\n",
    "            intent_type=flow_rule_type,\n",
    "            intent_specificity=flow_rule_specificity\n",
    "            )\n",
    "        \n",
    "        if (flow_rule_type== \"security\"):\n",
    "            ping_count, candidate_src_ip, candidate_dst_ip, ping_output = ONOS_assurance_for_security_intent(src_ip, dst_ip)\n",
    "            if (llm_caller_flag == 1):\n",
    "                print(\"\\nAsking LLM to generate corrective actions...\")\n",
    "                assurance_LLM_prompt = generate_corrective_action_prompt(intent, operational_flow_rule, device_id, ping_count,\n",
    "                                    candidate_src_ip, candidate_dst_ip, ping_output)\n",
    "                llm_response = Run_assurance_LLM (assurance_LLM_prompt)\n",
    "                print(llm_response)\n",
    "                parse_and_execute_corrective_actions(operational_flow_rule, llm_response, device_id, flow_id, src_ip, dst_ip)\n",
    "                 \n",
    "        elif (flow_rule_type== \"qos\"):\n",
    "\n",
    "            target_mbps = 1\n",
    "\n",
    "            # 1) Resolve intent → concrete args + pin plan\n",
    "            args, pins_plan, plan = intent_to_verifier_args(slicing_info, src_ip, dst_ip, target_mbps)\n",
    "            protocol = plan[\"protocol\"]             # \"tcp\" or \"udp\"\n",
    "            dst_port = args[\"dst_port\"] if \"dst_tcp_port\" in args else args.get(\"dst_port\", 80)\n",
    "\n",
    "            # 2) Ensure we have a flow_id (find an existing QoS flow on that device/port/queue/L4)\n",
    "\n",
    "            if not flow_id:\n",
    "                print(\"[WARN] Could not find an existing QoS flow matching the intent on the enforcement device.\")\n",
    "                print(\"If we want this caller to auto-push the QoS flow, we can add a tiny helper for that.\")\n",
    "                # We can still run the verifier; flow deltas will be None but queue counters are sufficient.\n",
    "            else:\n",
    "                args[\"flow_id\"] = flow_id\n",
    "\n",
    "            # 3) Install pin flows so the traffic must traverse the enforcement port\n",
    "            pushed_pins = install_pins_from_plan(\n",
    "                pins=pins_plan,\n",
    "                src_ip=args[\"src_ip\"], dst_ip=args[\"dst_ip\"],\n",
    "                dst_port=dst_port, protocol=protocol\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                # 4) Call the verifier\n",
    "                if protocol == \"udp\":\n",
    "                    # UDP: send at high rate so shaping is visible (edit the args if your verifier signature differs)\n",
    "                    verify_qos_flow_with_iperf(\n",
    "                        flow_device_id=args[\"flow_device_id\"],\n",
    "                        flow_id=args.get(\"flow_id\"),\n",
    "                        queue_device_id=args[\"queue_device_id\"],\n",
    "                        queue_port_no=args[\"queue_port_no\"],\n",
    "                        queue_id=args[\"queue_id\"],\n",
    "                        src_ip=args[\"src_ip\"],\n",
    "                        dst_ip=args[\"dst_ip\"],\n",
    "                        dst_port=dst_port,          # reuse field name; your function may still call it dst_tcp_port internally\n",
    "                        target_mbps=args[\"target_mbps\"],\n",
    "                        duration_sec=8,\n",
    "                        parallel=1,\n",
    "                        tolerance_pct=10.0,\n",
    "                        protocol=\"udp\",\n",
    "                        udp_bw_mbps=50.0,\n",
    "                        udp_len_bytes=1200\n",
    "                    )\n",
    "                else:\n",
    "                    # TCP\n",
    "                    verify_qos_flow_with_iperf(\n",
    "                        flow_device_id=args[\"flow_device_id\"],\n",
    "                        flow_id=args.get(\"flow_id\"),\n",
    "                        queue_device_id=args[\"queue_device_id\"],\n",
    "                        queue_port_no=args[\"queue_port_no\"],\n",
    "                        queue_id=args[\"queue_id\"],\n",
    "                        src_ip=args[\"src_ip\"],\n",
    "                        dst_ip=args[\"dst_ip\"],\n",
    "                        dst_port=dst_port,          # if your function uses dst_tcp_port, rename this argument accordingly\n",
    "                        target_mbps=args[\"target_mbps\"],\n",
    "                        duration_sec=8,\n",
    "                        parallel=8,\n",
    "                        tcp_mss=1200,\n",
    "                        tolerance_pct=10.0,\n",
    "                        protocol=\"tcp\"\n",
    "                    )\n",
    "            finally:\n",
    "                # 5) Always clean up pin flows after the test\n",
    "                unpin_path(pushed_pins)       \n",
    "             \n",
    "        elif (flow_rule_type== \"forwarding\"):\n",
    "             ONOS_assurance_for_forwarding_intent(src_host, dst_host, src_ip, dst_ip)\n",
    "\n",
    "        elapsed_time = (time.time() - current_time)\n",
    "        print(\"\\nTime taken for end-to-end IBN: \",  round(elapsed_time,2))\n",
    "\n",
    "elif (translated_flow_rule == \"Tie\"):\n",
    "    print(\"\\n\\nReport to the operator about this conflict resolution issue. Need adjustment to conflict resolution policy.\\n\")\n",
    "\n",
    "elif (translated_flow_rule == \"existing_rule_win\"):\n",
    "    print(\"\\n\\nThe new intent conflicts with an existing one having a higher priority according to current policy, hence the new intent was not installed. See the existing flow rule that conflicts.\\n\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n\\nLLM failed to produce meaningful response. Either update context example or model.\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onos_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
