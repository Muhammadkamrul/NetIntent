{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import re\n",
    "import pysqlite3\n",
    "import sys\n",
    "sys.modules[\"sqlite3\"] = sys.modules.pop(\"pysqlite3\")\n",
    "import time\n",
    "import jsondiff\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.example_selectors import MaxMarginalRelevanceExampleSelector\n",
    "#from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from ollama import Client\n",
    "#from openai import OpenAI\n",
    "from secret import OPENAI_API_KEY\n",
    "import json, jsondiff\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ODL Controller Details\n",
    "ODL_BASE_URL = \"http://10.23.7.63:8181/restconf\"\n",
    "USERNAME = \"admin\"\n",
    "PASSWORD = \"admin\"  # Replace with your ODL credentials\n",
    "\n",
    "# Headers for REST API\n",
    "HEADERS = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Accept\": \"application/json\"\n",
    "}\n",
    "\n",
    "\n",
    "# Define sudo password\n",
    "sudo_password = \"your_password\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flows_from_all_nodes_config():\n",
    "    url = f\"{ODL_BASE_URL}/config/opendaylight-inventory:nodes/\"\n",
    "    headers = {\"Accept\": \"application/json\"}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, auth=(USERNAME, PASSWORD), headers=headers)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        data = response.json()\n",
    "        node_flow_map = {}\n",
    "\n",
    "        for node in data.get(\"nodes\", {}).get(\"node\", []):\n",
    "            node_id = node.get(\"id\", \"unknown\")\n",
    "            node_flows = []\n",
    "\n",
    "            for table in node.get(\"flow-node-inventory:table\", []):\n",
    "                for flow in table.get(\"flow\", []):\n",
    "                    node_flows.append(flow.get(\"id\"))\n",
    "            \n",
    "            node_flow_map[node_id] = node_flows\n",
    "\n",
    "        #for node_id, flow_ids in node_flow_map.items():\n",
    "            #print(f\"Node: {node_id}, Flows: {flow_ids}\")\n",
    "\n",
    "        return node_flow_map\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(\"Error fetching flows from all nodes in configuration datastore:\", e)\n",
    "        return {}\n",
    "\n",
    "\n",
    "def get_next_available_flow_id_for_switch(flow_map, node_id):\n",
    "    \"\"\"\n",
    "    Get the next available flow ID for a specific switch (node_id).\n",
    "    \n",
    "    Parameters:\n",
    "        flow_map (dict): Mapping of node IDs to their flow IDs.\n",
    "        node_id (str): The ID of the target switch.\n",
    "        \n",
    "    Returns:\n",
    "        int: The next available flow ID for the given switch.\n",
    "    \"\"\"\n",
    "    used_ids = set()\n",
    "    flows = flow_map.get(node_id, [])\n",
    "    \n",
    "    for flow in flows:\n",
    "        try:\n",
    "            used_ids.add(int(flow))\n",
    "        except ValueError:\n",
    "            pass  # Ignore non-integer flow IDs\n",
    "\n",
    "    return max(used_ids) + 1 if used_ids else 1\n",
    "\n",
    "\n",
    "def get_flow_details(node_id, flow_id):\n",
    "    \"\"\"\n",
    "    Retrieve details of a specific flow rule by node ID and flow ID from the configuration datastore.\n",
    "    \n",
    "    Parameters:\n",
    "        node_id (str): The ID of the OpenFlow node (e.g., \"openflow:1\").\n",
    "        flow_id (str): The ID of the flow rule.\n",
    "    \n",
    "    Returns:\n",
    "        dict: JSON details of the specific flow rule.\n",
    "    \"\"\"\n",
    "    url = f\"{ODL_BASE_URL}/config/opendaylight-inventory:nodes/node/{node_id}/table/0/flow/{flow_id}\"\n",
    "    headers = {\"Accept\": \"application/json\"}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, auth=(USERNAME, PASSWORD), headers=headers)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        flow_data = response.json()\n",
    "        return flow_data\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching flow {flow_id} from node {node_id}: {e}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "def retrieve_all_flow_details():\n",
    "    \"\"\"\n",
    "    Retrieve all flow rule details from all OpenFlow nodes and save them in a structured format.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Mapping of node IDs to a dictionary of flow IDs and their JSON details.\n",
    "    \"\"\"\n",
    "    flow_details_map = {}\n",
    "    node_flow_map = get_flows_from_all_nodes_config()\n",
    "\n",
    "    for node_id, flow_ids in node_flow_map.items():\n",
    "        flow_details_map[node_id] = {}\n",
    "        for flow_id in flow_ids:\n",
    "            flow_details = get_flow_details(node_id, flow_id)\n",
    "            flow_details_map[node_id][flow_id] = flow_details\n",
    "\n",
    "    return flow_details_map\n",
    "\n",
    "\n",
    "def extract_switch_id(intent: str):\n",
    "    \"\"\"\n",
    "    Extract the switch ID from a natural language intent.\n",
    "    \n",
    "    Parameters:\n",
    "        intent (str): The natural language intent.\n",
    "    \n",
    "    Returns:\n",
    "        str: Extracted switch ID (e.g., 'openflow:1') or None if not found.\n",
    "    \"\"\"\n",
    "    # Mapping of ordinal words to numeric values\n",
    "    ordinals = {\n",
    "        \"first\": 1,\n",
    "        \"second\": 2,\n",
    "        \"third\": 3,\n",
    "        \"fourth\": 4,\n",
    "        \"fifth\": 5,\n",
    "        \"sixth\": 6,\n",
    "        \"seventh\": 7,\n",
    "        \"eighth\": 8,\n",
    "        \"ninth\": 9,\n",
    "        \"tenth\": 10\n",
    "    }\n",
    "\n",
    "    # Match patterns like 'openflow:1'\n",
    "    match = re.search(r'openflow[:\\s](\\d+)', intent, re.IGNORECASE)\n",
    "    if match:\n",
    "        return f\"openflow:{match.group(1)}\"\n",
    "\n",
    "    # Match patterns like 'switch 1', 'router 2', 'node 3'\n",
    "    match = re.search(r'\\b(?:switch|router|node|device)(?:\\s*number)?\\s*(\\d+)', intent, re.IGNORECASE)\n",
    "    if match:\n",
    "        return f\"openflow:{match.group(1)}\"\n",
    "\n",
    "    # Match ordinal words (e.g., 'fourth switch', 'second router')\n",
    "    match = re.search(r'\\b(?:switch|router|node|device)\\s*(\\w+)', intent, re.IGNORECASE)\n",
    "    if match:\n",
    "        ordinal_word = match.group(1).lower()\n",
    "        if ordinal_word in ordinals:\n",
    "            return f\"openflow:{ordinals[ordinal_word]}\"\n",
    "\n",
    "    # Match standalone ordinal words (e.g., 'fourth' without 'switch')\n",
    "    for word, number in ordinals.items():\n",
    "        if word in intent.lower():\n",
    "            return f\"openflow:{number}\"\n",
    "\n",
    "    return None\n",
    "\n",
    "def extract_port_number(text: str):\n",
    "    \"\"\"\n",
    "    Extract the Ethernet port number from a natural language text.\n",
    "    \n",
    "    Parameters:\n",
    "        text (str): The input text containing the port reference.\n",
    "    \n",
    "    Returns:\n",
    "        int: Extracted port number or None if not found.\n",
    "    \"\"\"\n",
    "    # Mapping of ordinal words to numeric values\n",
    "    ordinals = {\n",
    "        \"first\": 1,\n",
    "        \"second\": 2,\n",
    "        \"third\": 3,\n",
    "        \"fourth\": 4,\n",
    "        \"fifth\": 5,\n",
    "        \"sixth\": 6,\n",
    "        \"seventh\": 7,\n",
    "        \"eighth\": 8,\n",
    "        \"ninth\": 9,\n",
    "        \"tenth\": 10\n",
    "    }\n",
    "\n",
    "    # Match explicit numbers after keywords\n",
    "    match = re.search(r'\\b(?:port|interface|output\\s+node\\s+connector|ethernet)\\s*(\\d+)', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "\n",
    "    # Match ordinal words (e.g., 'second port', 'third interface')\n",
    "    match = re.search(r'\\b(?:port|interface|output\\s+node\\s+connector|ethernet)\\s*(\\w+)', text, re.IGNORECASE)\n",
    "    if match:\n",
    "        ordinal_word = match.group(1).lower()\n",
    "        if ordinal_word in ordinals:\n",
    "            return ordinals[ordinal_word]\n",
    "\n",
    "    # Match standalone ordinal words (e.g., 'second')\n",
    "    for word, number in ordinals.items():\n",
    "        if word in text.lower():\n",
    "            return number\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def push_flow_rule(node, table_id, flow_id, flow_json):\n",
    "    \"\"\"\n",
    "    Push a flow rule to ODL config datastore.\n",
    "    \"\"\"\n",
    "    url = f\"{ODL_BASE_URL}/config/opendaylight-inventory:nodes/node/{node}/table/{table_id}/flow/{flow_id}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.put(url, headers=HEADERS, auth=(USERNAME, PASSWORD), data=json.dumps(flow_json))\n",
    "        if response.status_code in [200, 201, 204]:\n",
    "            print(f\"Successfully pushed flow rule to Config Datastore (Switch ID: {node}, Flow ID: {flow_id})\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Failed to push flow rule to Config Datastore. Status Code: {response.status_code}, Response: {response.text}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred while pushing flow rule: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def verify_flow_rule(node, table_id, flow_id):\n",
    "    \"\"\"\n",
    "    Verify if the flow rule exists in ODL operational datastore.\n",
    "    \"\"\"\n",
    "    url = f\"{ODL_BASE_URL}/operational/opendaylight-inventory:nodes/node/{node}/table/{table_id}/flow/{flow_id}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS, auth=(USERNAME, PASSWORD))\n",
    "        if response.status_code == 200:\n",
    "            print(f\"Flow rule exists in Operational Datastore (Flow ID: {flow_id})\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Flow rule NOT found in Operational Datastore. Status Code: {response.status_code}, Response: {response.text}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occurred while verifying flow rule: {e}\")\n",
    "        return False\n",
    "\n",
    "# Function to update flow_id and table_id\n",
    "def update_flow_fields(flow_json, new_flow_id, new_table_id):\n",
    "    \"\"\"\n",
    "    Update flow_id and table_id in OpenDaylight flow JSON.\n",
    "\n",
    "    Parameters:\n",
    "        flow_json (dict): JSON object representing the flow.\n",
    "        new_flow_id (str): New flow ID to replace the current one.\n",
    "        new_table_id (int): New table ID to replace the current one.\n",
    "\n",
    "    Returns:\n",
    "        dict: Updated JSON object.\n",
    "    \"\"\"\n",
    "    for flow in flow_json.get(\"flow-node-inventory:flow\", []):\n",
    "        flow[\"id\"] = str(new_flow_id)  # Ensure flow_id is a string\n",
    "        flow[\"table_id\"] = new_table_id  # Ensure table_id is an integer\n",
    "    \n",
    "    return flow_json\n",
    "\n",
    "def execute_command(command):\n",
    "    process = subprocess.Popen(command, shell=True, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "    stdout, stderr = process.communicate(input=f\"{sudo_password}\\n\")\n",
    "    if process.returncode == 0:\n",
    "        return stdout.strip()\n",
    "    else:\n",
    "        raise Exception(f\"Error executing command: {stderr.strip()}\")\n",
    "\n",
    "def get_switch_port_mapping():\n",
    "    try:\n",
    "        # Commands to list port and QoS configurations\n",
    "        list_ports_command = \"sudo -S ovs-vsctl list port\"\n",
    "        list_qos_command = \"sudo -S ovs-vsctl list qos\"\n",
    "        # Fetch port and QoS data\n",
    "        ports_output = execute_command(list_ports_command)\n",
    "        qos_output = execute_command(list_qos_command)\n",
    "\n",
    "        # Parse QoS data into a dictionary\n",
    "        qos_mapping = {}\n",
    "        current_qos = None\n",
    "        for line in qos_output.splitlines():\n",
    "            if line.startswith(\"_uuid\"):\n",
    "                current_qos = line.split(\":\")[1].strip()\n",
    "            elif line.startswith(\"queues\") and current_qos:\n",
    "                qos_mapping[current_qos] = line.split(\":\")[1].strip()\n",
    "\n",
    "        # Create a dictionary to store switch-to-port mapping\n",
    "        switch_port_dict = {}\n",
    "\n",
    "        # Parse ports data and check for QoS\n",
    "        current_port = None\n",
    "        for line in ports_output.splitlines():\n",
    "            if line.startswith(\"name\"):\n",
    "                current_port = line.split(\":\")[1].strip()\n",
    "            elif line.startswith(\"qos\") and \"[]\" not in line and current_port:\n",
    "                qos_uuid = line.split(\":\")[1].strip()\n",
    "\n",
    "                # Extract the OpenFlow switch ID and port number\n",
    "                if \"-\" in current_port:\n",
    "                    switch, port = current_port.split(\"-\")\n",
    "                    switch_id = f\"openflow:{switch[1:]}\"  # e.g., \"s1\" -> \"openflow:1\"\n",
    "                    port_number = port[3:]  # e.g., \"eth2\" -> \"2\"\n",
    "\n",
    "                    # Add to dictionary\n",
    "                    if switch_id not in switch_port_dict:\n",
    "                        switch_port_dict[switch_id] = []\n",
    "                    switch_port_dict[switch_id].append(port_number)\n",
    "\n",
    "                current_port = None\n",
    "\n",
    "        return switch_port_dict\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "def create_two_queue_for_switch(switch, port, max_rate=10000000, queue_configs=None):\n",
    "    \"\"\"\n",
    "    Creates queues dynamically for a specific switch and port.\n",
    "    \n",
    "    Parameters:\n",
    "        switch (str): The name of the switch in 'openflow:X' format (e.g., 'openflow:4').\n",
    "        port (int): The port number on the switch (e.g., 2).\n",
    "        max_rate (int): Maximum rate for the QoS (default is 10000000).\n",
    "        queue_configs (list): List of tuples specifying min-rate and max-rate for each queue (default is 2 queues).\n",
    "    \"\"\"\n",
    "    if queue_configs is None:\n",
    "        # Default to 2 queues with these configurations\n",
    "        queue_configs = [\n",
    "            (6000000, 6000000),  # Queue 0: min-rate and max-rate\n",
    "            (4000000, 4000000)   # Queue 1: min-rate and max-rate\n",
    "        ]\n",
    "\n",
    "    # Construct the port name from the input\n",
    "    port_name = f\"{switch.replace('openflow:', 's')}-eth{port}\"\n",
    "\n",
    "    # Construct the QoS command for the specific switch and port\n",
    "    qos_command = f\"sudo -S ovs-vsctl -- set port {port_name} qos=@newqos -- --id=@newqos create qos type=linux-htb other-config:max-rate={max_rate}\"\n",
    "    for i, (min_rate, max_rate) in enumerate(queue_configs):\n",
    "        qos_command += f\" queues:{i}=@q{i}\"\n",
    "    for i, (min_rate, max_rate) in enumerate(queue_configs):\n",
    "        qos_command += f\" -- --id=@q{i} create queue other-config:min-rate={min_rate} other-config:max-rate={max_rate}\"\n",
    "\n",
    "    # Execute the command\n",
    "    print(f\"Running: {qos_command}\")\n",
    "    process = subprocess.Popen(qos_command, shell=True, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "    stdout, stderr = process.communicate(input=f\"{sudo_password}\\n\")\n",
    "    if process.returncode == 0:\n",
    "        print(f\"Success:\\n{stdout}\")\n",
    "    else:\n",
    "        print(f\"Error:\\n{stderr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSLATION_PROMPT = \"\"\"Your task is to transform natural language network intents into JSON-formatted network policies compatible with the OpenDaylight (ODL) SDN controller's configuration datastore.\n",
    "\n",
    "You only reply in JSON, no natural language. The network intents can represent different traffic control behaviors, such as:\n",
    "\n",
    "a. **Traffic Forwarding and Queue-Based Traffic Control Rule:** Define rules for forwarding traffic based on IPv4 destination, TCP/UDP ports, and optionally assign traffic to specific queues for prioritization. \n",
    "b. **Firewall and Blocking:** Define rules to drop traffic based on specific match criteria (e.g., source IP, destination IP).  \n",
    "c. **Port-Based Forwarding:** Redirect traffic entering a specific port to another designated port.\n",
    "\n",
    "### JSON STRUCTURE:\n",
    "\n",
    "1. **Traffic Forwarding and Queue-Based Traffic Control Rule:**  \n",
    "\n",
    "```json\n",
    "{\n",
    "  \"flow-node-inventory:flow\": [\n",
    "    {\n",
    "      \"id\": \"<unique_id>\",\n",
    "      \"priority\": <integer>,\n",
    "      \"table_id\": <integer>,\n",
    "      \"flow-name\": \"<descriptive_name>\",\n",
    "      \"hard-timeout\": <integer>,\n",
    "      \"idle-timeout\": <integer>,\n",
    "      \"match\": {\n",
    "        \"ethernet-match\": {\n",
    "          \"ethernet-type\": {\n",
    "            \"type\": 2048\n",
    "          }\n",
    "        },\n",
    "        \"ipv4-source\": \"<ip_address/mask>\", //**optional**\n",
    "        \"ipv4-destination\": \"<ip_address/mask>\", //**optional**\n",
    "        \"ip-match\": {\n",
    "          \"ip-protocol\": <integer>\n",
    "        },\n",
    "        \"tcp-destination-port\": <integer>,\n",
    "        \"udp-destination-port\": <integer>\n",
    "      },\n",
    "      \"instructions\": {\n",
    "        \"instruction\": [\n",
    "          {\n",
    "            \"order\": 0,\n",
    "            \"apply-actions\": {\n",
    "              \"action\": [\n",
    "                {\n",
    "                  \"order\": 0,\n",
    "                  \"set-queue-action\": {\n",
    "                    \"queue-id\": <queue_id>\n",
    "                  }\n",
    "                },\n",
    "                {\n",
    "                  \"order\": 1,\n",
    "                  \"output-action\": {\n",
    "                    \"output-node-connector\": \"<port_number>\"\n",
    "                  }\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "2. **Blocking or Dropping Rule:**  \n",
    "\n",
    "{\n",
    "  \"flow-node-inventory:flow\": [\n",
    "    {\n",
    "      \"id\": \"<unique_id>\",\n",
    "      \"priority\": <integer>,\n",
    "      \"table_id\": <integer>,\n",
    "      \"flow-name\": \"<descriptive_name>\",\n",
    "      \"hard-timeout\": <integer>,\n",
    "      \"idle-timeout\": <integer>,\n",
    "      \"match\": {\n",
    "        \"ethernet-match\": {\n",
    "          \"ethernet-type\": {\n",
    "            \"type\": <integer>\n",
    "          }\n",
    "        },\n",
    "        \"ipv4-source\": \"<ip_address/mask>\",\n",
    "        \"ipv4-destination\": \"<ip_address/mask>\"\n",
    "      },\n",
    "      \"instructions\": {\n",
    "        \"instruction\": [\n",
    "          {\n",
    "            \"order\": 0,\n",
    "            \"apply-actions\": {\n",
    "              \"action\": [\n",
    "                {\n",
    "                  \"order\": 0,\n",
    "                  \"drop-action\": {}\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "3. **Port-Based Forwarding Rule:**  \n",
    "\n",
    "{\n",
    "  \"flow-node-inventory:flow\": [\n",
    "    {\n",
    "      \"id\": \"<unique_id>\",\n",
    "      \"priority\": <integer>,\n",
    "      \"table_id\": <integer>,\n",
    "      \"flow-name\": \"<descriptive_name_summerizing_the_intent>\",\n",
    "      \"hard-timeout\": <integer>,\n",
    "      \"idle-timeout\": <integer>,\n",
    "      \"match\": {\n",
    "        \"in-port\": <port_number>\n",
    "      },\n",
    "      \"instructions\": {\n",
    "        \"instruction\": [\n",
    "          {\n",
    "            \"order\": 0,\n",
    "            \"apply-actions\": {\n",
    "              \"action\": [\n",
    "                {\n",
    "                  \"order\": 0,\n",
    "                  \"output-action\": {\n",
    "                    \"output-node-connector\": \"<port_number>\"\n",
    "                  }\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "Field Descriptions: \n",
    "id: A number representing a unique identifier for the flow (0 for default).\n",
    "priority: Priority level (higher numbers indicate higher priority). For dropping or blocking or firewall rule, assign priority greater than 300.\n",
    "table_id: An integer representing the flow table identifier (0 for default).\n",
    "flow-name: A short, descriptive flow name that summerizes the intent.\n",
    "hard-timeout: Timeout in seconds after which the flow is removed (0 for default).\n",
    "idle-timeout: Timeout in seconds after which the flow is removed if there's no activity (0 for default).\n",
    "ethernet-type: Ethernet protocol type (e.g., 2048 for IPv4).\n",
    "ipv4-destination: IPv4 address in CIDR notation (e.g., 10.0.0.1/32). Note: This field is optional. Don't include it unless IP address (e.g., 10.0.0.1) is explicitly mentioned in the intent.\n",
    "ipv4-source: Source IP address (optional). Note: This field is optional. Don't include it unless IP address (e.g., 10.0.0.1) is explicitly mentioned in the intent.\n",
    "ip-protocol: Use \"ip-match\" and \"ip-protocol\" when specifying specific transport layer protocols (e.g., 6 for TCP, 17 for UDP, 1 for ICMP (optional)).\n",
    "tcp-source-port: The source port for the connection, usually a random high port on the client (rarely fixed) (optional).\n",
    "tcp-destination-port: The destination port for the connection (i.e., the server port, e.g., 80 for HTTP) (optional).\n",
    "udp-source-port: UDP port number (optional).\n",
    "udp-destination-port: UDP port number (optional).\n",
    "in-port: A value representing incoming interface port number (optional).\n",
    "output-action: Use \"output-action\" and \"output-node-connector\" to specify the output port number (optional).\n",
    "set-queue-action: Use \"set-queue-action\" and \"queue-id\" when the intent specifies assigning traffic to a queue (The \"queue-id\" is an integer (0 for default)).\n",
    "drop-action: Use {} to indicate packet dropping.\n",
    "\n",
    "RULES:\n",
    "Each id must be unique.\n",
    "Set priority values appropriately (higher for critical rules, lower for defaults). Set priority very high (e.g., 500) for queue related rules.\n",
    "Don't include any **optional field** unless it is explicitly mentioned in the intent.\n",
    "Use valid match conditions (ipv4-destination, tcp-destination-port, ipv4-source, in-port) depending on the intent type.\n",
    "When translating HTTP, HTTPS, or other protocol traffic by port, always use 'tcp-destination-port' for the protocol's standard server port (e.g., 80 for HTTP, 443 for HTTPS) unless the intent explicitly says 'source port'.\n",
    "Ensure valid ODL-compliant JSON syntax.\n",
    "Avoid duplicate keys and empty fields.\n",
    "Verify JSON structure for correctness before responding.\n",
    "Always respond with valid JSON only, with no additional text, comments, or explanations.\n",
    "If the intent cannot be mapped, return an empty JSON object {}.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLICING_PROMPT = \"\"\"You are tasked with analyzing a natural language intent to determine if it contains a command to create or use a queue/slice in a openflow switch. You should respond in JSON format. \n",
    "\n",
    "### Rules for Interpretation:\n",
    "1. **Queue/Slice Detection:**  \n",
    "   - The intent is considered related to queue/slice if it contains commands such as:\n",
    "     - \"create queue\", \"create slices\", \"slice the network\", \"implement slicing\", \"slice the flow\", \"make flowspace slicing\", \"do slicing\", \"slice\", \"implement queue\", \"do queuing\", \"assign queue\", \"assign slice\", or any similar phrasing.\n",
    "   - If the intent does not mention creating or using a queue/slice, set the field `\"use_queue\"` to `0`. \n",
    "\n",
    "2. **Switch and Port Identification:**  \n",
    "   - If the intent specifies a **switch ID** (e.g., \"switch 4\" or \"openflow:4\" or \"node 4\" or \"openflow 4\"), populate the `\"switch_id\"` field with its value.  \n",
    "   - If the intent specifies a **Queue ID or slice ID** (e.g., \"queue 4\" or \"4th queue\" or \"fourth queue\" or \"slice 1\" or \"first slice\"), populate the `\"queue_id\"` field with its value.  \n",
    "   - If the intent specifies a **port ID** (e.g., \"port 2\" or \"interface 2\" or \"ethernet 2\" or \"output node connector 2\" or \"second port\" or \"second interface\"), populate the `\"port_id\"` field with its value. If there are multiple instances of \"port_id\" present, take the one which indicates output port or outgoing interface.\n",
    "   - If the intent does not specify a switch ID or queue ID or port ID, set the respective field to an empty string (`\"\"`).\n",
    "\n",
    "3. **Output Format:**  \n",
    "   - Respond strictly in valid JSON format adhering to the following schema:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"use_queue\": <integer>,\n",
    "  \"switch_id\": \"<string>\",\n",
    "  \"queue_id\": \"<string>\",\n",
    "  \"port_id\": \"<string>\"\n",
    "}\n",
    "\n",
    "Field Description:\n",
    "-use_queue: 1 if the intent commands to create or use a queue/slice, 0 otherwise.\n",
    "-switch_id: Switch ID if specified in the intent, otherwise \"\".\n",
    "-queue_id: Queue ID if specified in the intent, otherwise \"\".\n",
    "-port_id: Port ID if specified in the intent, otherwise \"\". If there are mutiple instances of \"port_id\" present, take the one which indicates the output port or outgoing interface.\n",
    "\n",
    "4. No Additional Text:\n",
    "Do not include any comments, explanations, or outputs outside the JSON format.\n",
    "\n",
    "Example Inputs and Outputs:\n",
    "    1. Input Intent:\n",
    "    \"Create a queue in switch 4 on port 3 for slicing the flow.\"\n",
    "    Output:\n",
    "    {\n",
    "    \"use_queue\": 1,\n",
    "    \"switch_id\": \"switch 4\",\n",
    "    \"queue_id\": \"\",\n",
    "    \"port_id\": \"port 3\"\n",
    "    }\n",
    "\n",
    "    2. Input Intent:\n",
    "    \"Send all video traffic through queue 0 of openflow:2.\"\n",
    "    Output:\n",
    "    {\n",
    "    \"use_queue\": 1,\n",
    "    \"switch_id\": \"openflow 2\",\n",
    "    \"queue_id\": 0,\n",
    "    \"port_id\": \"\"\n",
    "    }\n",
    "\n",
    "    3. Input Intent:\n",
    "    \"Configure switch 5 for traffic management.\"\n",
    "    Output:\n",
    "    {\n",
    "    \"use_queue\": 0,\n",
    "    \"switch_id\": \"switch 5\",\n",
    "    \"queue_id\": \"\",\n",
    "    \"port_id\": \"\"\n",
    "    }\n",
    "\n",
    "    4. Input Intent:\n",
    "    \"Monitor traffic flow on port 1.\"\n",
    "    Output:\n",
    "    {\n",
    "    \"use_queue\": 0,\n",
    "    \"switch_id\": \"\",\n",
    "    \"queue_id\": \"\",\n",
    "    \"port_id\": \"port 1\"\n",
    "    }\n",
    "\n",
    "   5. Input Intent:\n",
    "    \"In switch 3, if the incoming traffic in port 1 is TCP traffic destined for port 80, then pass it via interface 2, assigning it to queue 0 for prioritized handling.\"\n",
    "    Output:\n",
    "    {\n",
    "    \"use_queue\": 1,\n",
    "    \"switch_id\": switch 3,\n",
    "    \"queue_id\": 0,\n",
    "    \"port_id\": \"interface 2\"\n",
    "    }\n",
    "\n",
    "Respond with the appropriate JSON strictly following these rules and format.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFLICT_PROMPT = \"\"\"You are tasked with determining if two OpenDaylight (ODL) flow configuration JSONs directly conflict with each other. You MUST base your decision SOLELY on the content of the JSON structures provided. Do NOT consider the intent behind the flow rule or try to infer conflicts based on the general idea of blocking or forwarding traffic. Your analysis MUST be a strict, field-by-field comparison of the JSON structures.\n",
    "\n",
    "### **Rules of Conflict Detection (STRICT and LITERAL):\n",
    "\n",
    "\n",
    "A **direct conflict** exists ONLY if *all* of the following conditions are met:\n",
    "\n",
    "1. **Exact Matching Traffic Characteristics (Match Criteria Overlap):** Both flows MUST have *identical* or *overlapping* match criteria for *all specified fields*. This means they could potentially apply to the *exact same* packet. Critically, if a field is present in one flow but *not* in the other, there is *NO MATCH* for that field. Consider the following match fields:\n",
    "    *   `in-port`: Both flows must have the `in-port` field specified and the values must be identical for an overlap. If either flow does not have the `in-port` field, there is NO overlap for this criterion.\n",
    "    *   `ethernet-match.ethernet-type.type`: Both flows must have this field and the values must be identical (e.g., 2048 for IPv4) for an overlap. If either flow does not have this field, there is NO overlap for this criterion.\n",
    "    *   `ipv4-source`: Both flows must have the `ipv4-source` field specified. The source IP addresses/masks must overlap (e.g., 10.0.0.1/32 and 10.0.0.0/24 overlap) for an overlap. If either flow does not have the `ipv4-source` field, there is NO overlap for this criterion.\n",
    "    *   `ipv4-destination`: Both flows must have the `ipv4-destination` field specified. The destination IP addresses/masks must overlap for an overlap. If either flow does not have the `ipv4-destination` field, there is NO overlap for this criterion.\n",
    "    *   `ip-match.ip-protocol`: Both flows must have the `ip-protocol` field specified and the values must be identical (e.g., 6 for TCP, 17 for UDP) for an overlap. If either flow does not have this field, there is NO overlap for this criterion.\n",
    "    *   `tcp-source-port`, `tcp-destination-port`, `udp-source-port`, `udp-destination-port`: Both flows must have the *same* port field (e.g., both `tcp-destination-port`) specified, and the values must be identical for an overlap. If either flow does not have the corresponding port field, there is NO overlap for this criterion.\n",
    "    *    **EXCEPTION** If one flow has additional match fields for ethernet-type or ip-protocol or tcp-destination-port or udp-destination-port, then there is NO overlap for these flows even if the output actions are same and some but not all required fields (such as ethernet-type, ip-protocol, IP address, tcp-destination-port, udp-destination-port) match.\n",
    "\n",
    "2. **Contradictory Actions:** If *and only if* the match criteria overlap as described above, check the actions. Contradictory actions include:\n",
    "    *   Different `output-node-connector` values: If the flows have different output ports, it's a conflict..\n",
    "    *   One flow has `drop-action: {}` and the other has an `output-action`: If one flow drops the packet and the other forwards it, it's a conflict.\n",
    "    *   Different `set-queue-action.queue-id` values: If the flows specify different queue IDs, it's a conflict.\n",
    "    *   **EXCEPTION** If one flow has additional match fields for ethernet-type or ip-protocol or tcp-destination-port or udp-destination-port, then there is NO overlap for these flows even if the output actions are same and some but not all required fields (such as ethernet-type, ip-protocol, IP address, tcp-destination-port, udp-destination-port) match.\n",
    "\n",
    "3. **Priority is Irrelevant for Direct Conflicts:** The `priority` field does *not* determine if a direct conflict exists. Priority only determines which flow rule takes precedence if a conflict is detected by the switch.\n",
    "\n",
    "4. **No General vs. Specific Rule Heuristics**  \n",
    "    Do NOT assume that one rule is “more general” or “more specific.” Only literal match-set overlap matters. Two rules conflict if — and only if — they match the same packet and specify different actions.\n",
    "    \n",
    "5. **Source to Source, Destination to Destination:** You MUST match source to source and destination to destination. Any match between a JSON's source to another JSON's destination is NOT a conflict.\n",
    "\n",
    "6. **Missing Field Handling - EXTREMELY IMPORTANT (LITERAL COMPARISON):**\n",
    "    *   If one JSON omits a field (e.g., ipv4-source), it matches all values for that field. Therefore, if the other JSON specifies a narrower match, and their actions differ, this can be a conflict.\n",
    "    *   **Crucially:** You MUST perform a literal, field-by-field comparison. Do NOT infer any broader meaning or intent.\n",
    "    *   **Example 1 (CONFLICT):**\n",
    "        *   Flow 1: `{\"match\": {\"ipv4-destination\": \"10.0.0.2/32\"}, \"instructions\": { ... \"output-action\": ... }}`\n",
    "        *   Flow 2: `{\"match\": {\"ipv4-source\": \"10.0.0.1/32\", \"ipv4-destination\": \"10.0.0.2/32\"}, \"instructions\": { ... \"drop-action\": {} }}`\n",
    "        *   **Explanation:** Flow 1 matches all sources to 10.0.0.2. Flow 2 matches only packets from 10.0.0.1 to 10.0.0.2. Their match sets may overlap — so if their actions differ, this is a conflict. \n",
    "   *     **Example 2 (NO CONFLICT):**\n",
    "         *  One flow allows traffic to `10.0.0.2/32` \n",
    "         *  Another flow blocks traffic from `10.0.0.2/32` to `10.0.0.4/32`\n",
    "         *   **Explanation:** These do not conflict because source and destination fields do not align.\n",
    "   *   **Example 3 (NO CONFLICT):**\n",
    "        *   Flow 1: `{\"match\": {\"ipv4-source\": \"10.0.0.1/32\", \"ipv4-destination\": \"10.0.0.4/32\"}, \"instructions\": { ... \"drop-action\": {} }}`\n",
    "        *   Flow 2: `{\"match\": {\"ipv4-source\": \"10.0.0.2/32\", \"ipv4-destination\": \"10.0.0.4/32\"}, \"instructions\": { ... \"drop-action\": {} }}`\n",
    "        *   **Explanation:** Although both flows drop traffic to 10.0.0.4, they have *different sources*. Therefore, they do NOT conflict. They apply to different traffic.\n",
    "   *     **Example 4 (NO CONFLICT):**\n",
    "         *  One flow has destination IP `10.0.0.1` \n",
    "         *  Another flow has detination IP `10.0.0.2`\n",
    "         *   **Explanation:** These do not conflict even if the output actions are different because the source and the destination IP are not same, i.e. 10.0.0.1/32 and 10.0.0.2/32 do not overlap as 10.0.0.1 is not within the subnet of 10.0.0.2/32.\n",
    "\n",
    "### **Input Format:**\n",
    "\n",
    "You will be provided with two JSON objects representing ODL flow entries. The input will be formatted as follows:\n",
    "\n",
    "Flow 1:\n",
    "<JSON for Flow 1>\n",
    "\n",
    "Flow 2:\n",
    "<JSON for Flow 2>\n",
    "\n",
    "### **Expected Output Format:**\n",
    "\n",
    "Respond strictly in valid JSON adhering to the following schema:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"conflict_status\": <integer>,\n",
    "  \"conflict_explanation\": \"<conflict explanation, if any>\"\n",
    "}\n",
    "\n",
    "Field Descriptions:\n",
    "\n",
    "conflict_status: An integer value: 1 if a direct conflict exists, 0 if no direct conflict exists. **DO NOT PUT 1 IF YOU ARE NOT CONFIDENT ABOUT A DIRECT CONFLICT**.\n",
    "conflict_explanation: A brief explanation of the detected conflict, if any. This field should be an empty string (\"\") if there is no conflict.\n",
    "Do not include any additional text, comments, or explanations outside of the JSON structure. Only output valid JSON.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_models = [\n",
    "\"qwq\"\n",
    "    ]\n",
    "  \n",
    "context_examples = [3]\n",
    "\n",
    "default_model = \"qwq\"\n",
    "\n",
    "ollama_embedding_url = \"http://localhost:11434\"\n",
    "ollama_server_url = \"http://localhost:11435\"  \n",
    "\n",
    "ollama_emb = OllamaEmbeddings(\n",
    "    model=default_model,\n",
    "    base_url=ollama_embedding_url,\n",
    ")\n",
    "\n",
    "client = Client(host=ollama_server_url , timeout=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load custom dataset from CSV\n",
    "custom_dataset = pd.read_csv('Intent2Flow-ODL.csv')\n",
    "\n",
    "# Ensure proper column names and format\n",
    "if not {'instruction', 'output'}.issubset(custom_dataset.columns):\n",
    "    raise ValueError(\"The dataset must have 'instruction' and 'output' columns.\")\n",
    "\n",
    "trainset = custom_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict_error_count = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_LLM_conflict(existing_intent_flow_json, new_intent_flow_json):\n",
    "\n",
    "    system_prompt = CONFLICT_PROMPT\n",
    "\n",
    "    print(\"\\nCheckpoint*******Entering RUM LLM Conflict\\n\\n******\")\n",
    "    \n",
    "    for model in my_models:     \n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                time.sleep(0.1)             \n",
    "                response = client.generate(model=model,\n",
    "                    options={'temperature': 0.3, 'num_ctx': 8192, 'top_p': 0.5, 'num_predict': 1024, 'num_gpu': 99},\n",
    "                    #options={'device': 'cpu'},\n",
    "                    stream=False,\n",
    "                    system=system_prompt,\n",
    "                    prompt=f\"Flow 1:\\n{json.dumps(existing_intent_flow_json, indent=2)}\\n\\nFlow 2:\\n{json.dumps(new_intent_flow_json, indent=2)}\",\n",
    "                    format='json'\n",
    "                )\n",
    "                \n",
    "                output = response['response'].strip()\n",
    "                response_json = json.loads(output)\n",
    "\n",
    "                if 'conflict_status' not in response_json:\n",
    "                    print(\"\\nWarning: 'conflict_status' key is missing in the response.\\n\")\n",
    "                \n",
    "                conflict_status = response_json.get('conflict_status', 0)\n",
    "                \n",
    "                if not isinstance(conflict_status, int):\n",
    "                    if (type(conflict_status).__name__ == 'str'):\n",
    "                        conflict_status = int(conflict_status)\n",
    "                \n",
    "                if conflict_status == 1:\n",
    "                    return True, response_json['conflict_explanation']\n",
    "                \n",
    "                break\n",
    "                \n",
    "                #result_dict_error_count[model] = result_dict_error_count.get(model, 0) + conflict_status\n",
    "                #print(\"\\n\\nConflict Status by: \", model, \"\\n\\n\", output)               \n",
    "                #break\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(\"Exception found: \", e)\n",
    "                sys.stdout.flush()\n",
    "                continue      \n",
    "    print(\"\\nCheckpoint*******Exiting RUN LLM Conflict\\n\\n******\")\n",
    "    #print(\"\\n\\n============Trying another flow==============\\n\\n\")\n",
    "    return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conflict(node_id, new_intent_flow_json):\n",
    "\n",
    "    all_flow_details = retrieve_all_flow_details()\n",
    "    flows_of_node_id = all_flow_details.get(node_id, {})\n",
    "\n",
    "    print(\"\\nCheckpoint*******Inside Conflict Checking\\n\\n******\")\n",
    "\n",
    "    for flow_id, existing_intent_flow_json in flows_of_node_id.items():\n",
    "        print(\"\\n\",node_id, \" \", flow_id,\"\\n\")\n",
    "        conflict_status, conflict_info = run_LLM_conflict(existing_intent_flow_json, new_intent_flow_json)\n",
    "        if conflict_status == True :\n",
    "            return True, flow_id, conflict_info\n",
    "    \n",
    "    #for model, errors in result_dict_error_count.items():\n",
    "        #print(f\"{model}: {errors}\")\n",
    "    \n",
    "    #return True, None, None\n",
    "    print(\"\\nCheckpoint*******Exiting conflict Checking\\n\\n******\")\n",
    "    return False, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_LLM_Slice(intent):\n",
    "\n",
    "    system_prompt = SLICING_PROMPT\n",
    "    \n",
    "    for model in my_models:     \n",
    "        try:\n",
    "            time.sleep(0.1)             \n",
    "            response = client.generate(model=model,\n",
    "                options={'temperature': 0.3, 'num_ctx': 8192, 'top_p': 0.5, 'num_predict': 1024, 'num_gpu': 99},\n",
    "                #options={'device': 'cpu'},\n",
    "                stream=False,\n",
    "                system=system_prompt,\n",
    "                prompt=intent,\n",
    "                format='json'\n",
    "            )\n",
    "            \n",
    "            output = response['response'].strip()\n",
    "            response_json = json.loads(output)\n",
    "            \n",
    "            print(\"\\nCheckpoint*******Exiting LLM Slicing detection\\n\\n******\")\n",
    "            return response_json            \n",
    "        \n",
    "        except Exception as e:\n",
    "            print(\"Exception found: \", e)\n",
    "            sys.stdout.flush()\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_LLM_IBN(intent, node_id):\n",
    "\n",
    "    for num_examples in context_examples:\n",
    "        for model in my_models:\n",
    "            example_selector = MaxMarginalRelevanceExampleSelector.from_examples(\n",
    "                [{\"instruction\": trainset.iloc[0][\"instruction\"], \"output\": trainset.iloc[0][\"output\"]}],\n",
    "                ollama_emb,\n",
    "                Chroma,\n",
    "                input_keys=[\"instruction\"],\n",
    "                k=num_examples,\n",
    "                vectorstore_kwargs={\"fetch_k\": min(num_examples, len(trainset))}\n",
    "                )\n",
    "\n",
    "            # Clear and add all remaining examples from the trainset\n",
    "            example_selector.vectorstore.reset_collection()\n",
    "            for _, row in trainset.iterrows():\n",
    "                example_selector.add_example({\n",
    "                    \"instruction\": row[\"instruction\"],\n",
    "                    \"output\": row[\"output\"]\n",
    "                })\n",
    "            \n",
    "            system_prompt = TRANSLATION_PROMPT\n",
    "\n",
    "            while True:\n",
    "                try:\n",
    "                    time.sleep(0.1)\n",
    "                    if num_examples > 0:\n",
    "                        examples = example_selector.select_examples({\"instruction\": intent})\n",
    "                        example_str = \"\\n\\n\\n\".join(map(lambda x: \"Input: \" + x[\"instruction\"] + \"\\n\\nOutput: \" + x[\"output\"], examples))\n",
    "                        system_prompt += example_str + \"\\n\\n\\n\"  \n",
    "                    \n",
    "                    response = client.generate(model=model,\n",
    "                        options={'temperature': 0.6, 'num_ctx': 8192, 'top_p': 0.3, 'num_predict': 1024, 'num_gpu': 99},\n",
    "                        #options={'device': 'cpu'},\n",
    "                        stream=False,\n",
    "                        system=system_prompt,\n",
    "                        prompt=intent,\n",
    "                        format='json'\n",
    "                    )\n",
    "                    actual_output = response['response']\n",
    "                    print(\"\\nTranslated by: \", model)\n",
    "                    break\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(\"Exception on Input: \", e)\n",
    "                    sys.stdout.flush()\n",
    "                    continue\n",
    "            \n",
    "            try:\n",
    "                \n",
    "                print(\"\\nCheckpoint*******Entering next flow id checking\\n\\n******\")\n",
    "                new_flow_id = get_next_available_flow_id_for_switch(get_flows_from_all_nodes_config(), node_id)\n",
    "                new_table_id = 0\n",
    "                \n",
    "                flow_json = json.loads(actual_output)\n",
    "                updated_flow_json = update_flow_fields(flow_json, new_flow_id, new_table_id)\n",
    "\n",
    "                print(\"\\n\\n\", intent, \"\\n\", flow_json, \"\\n\\n\")\n",
    "\n",
    "                print(\"\\nCheckpoint*******Entering conflict detection\\n\\n******\")\n",
    "                conflict_status, flow_id, conflict_info = conflict(node_id, updated_flow_json)\n",
    "\n",
    "                print(\"\\nCheckpoint*******Conflict detection done\\n\\n******\")\n",
    "\n",
    "                if(conflict_status == True):\n",
    "                    print(\"\\n\\nThe new intent JSON conflicts with an existing intent JSON\\nCheck switch: \",node_id, \", flow id: \",flow_id, \"\\n\\n\", conflict_info)\n",
    "                    return False\n",
    "                else:\n",
    "                    # Push Flow Rule\n",
    "                    print(\"\\nCheckpoint*******Entering PUSH flow rule of ODL\\n\\n******\")\n",
    "                    if push_flow_rule(node_id, new_table_id, new_flow_id, updated_flow_json):\n",
    "                        print(\"Waiting for the rule to propagate to Operational Datastore...\\n\")\n",
    "                        time.sleep(5)  # Introduce a 5-second delay\n",
    "                        # Verify Flow Rule\n",
    "                        if verify_flow_rule(node_id, new_table_id, new_flow_id):\n",
    "                            print(\"\\n\\n\", intent, \"\\n\", flow_json, \"\\n\\n\")\n",
    "                            return True\n",
    "            \n",
    "            except Exception as e:\n",
    "                print(\"Exception found: \", e)\n",
    "    print(\"\\nCheckpoint*******Exiting IBN LLM\\n\\n******\")\n",
    "    return False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    intent = input().strip()\n",
    "    #intent = \"in switch 4, install a firewall to block traffic from 10.0.0.2 to 10.0.0.4\"\n",
    "    #intent = \"in switch 4, traffic destined for 10.0.0.4 should pass through port 3\"\n",
    "    #intent = \"Using openflow switch number 1, forward UDP traffic on port 80 destined for 10.0.0.3 via interface 2, assigning it to queue 1 for prioritized handling.\"\n",
    "    #intent = \"In switch 3, if the incoming traffic in port 1 is TCP traffic destined for port 80, then pass it via interface 2, assigning it to queue 0 for prioritized handling.\"\n",
    "    #intent = \"In switch 3, if the incoming traffic in interface 1 is UDP traffic destined for port 80, then pass it via port 2, assigning it to queue 1 for prioritized handling.\"\n",
    "    #intent = \"In switch 3, if the incoming traffic in port 2 is TCP traffic destined for port 80, then pass it via interface 1, assigning it to queue 0 for prioritized handling.\"\n",
    "    #intent = \"In switch 3, if the incoming traffic in interface 2 is UDP traffic destined for port 80, then pass it via port 1, assigning it to queue 1 for prioritized handling.\"\n",
    "\n",
    "    current_time = time.time()\n",
    "\n",
    "    openflow_id = extract_switch_id(intent)\n",
    "\n",
    "    print(\"\\nCheckpoint*******Entering LLM Slicing detection\\n\\n******\")\n",
    "    sliceing_info = run_LLM_Slice(intent)\n",
    "\n",
    "    if 'use_queue' in sliceing_info:         \n",
    "        slicing_status = sliceing_info['use_queue']\n",
    "        slicing_switch_id = sliceing_info['switch_id']\n",
    "        slicing_queue_id = sliceing_info['queue_id']\n",
    "        slicing_port_id = sliceing_info['port_id']\n",
    "\n",
    "        if(slicing_status == 1):\n",
    "            openflow_id = extract_switch_id(slicing_switch_id)\n",
    "            switch_port_mapping = get_switch_port_mapping()\n",
    "            print(\"\\nCheckpoint*******Entering Slice/Queue Management\\n\\n******\")\n",
    "\n",
    "            port_number = extract_port_number(slicing_port_id)\n",
    "            \n",
    "            if openflow_id not in switch_port_mapping :\n",
    "                \n",
    "                    print(\"\\n\\nQueue was not installed in \",openflow_id, \"\\nInstalling now on interface: \", port_number,\"\\n\")\n",
    "                    print(\"\\nCheckpoint*******Entering queue creation\\n\\n******\")\n",
    "\n",
    "                    create_two_queue_for_switch(\n",
    "                        switch=openflow_id,  port=port_number,\n",
    "                        queue_configs=[\n",
    "                            (6000000, 6000000),  # Queue 0\n",
    "                            (4000000, 4000000)   # Queue 1\n",
    "                        ]\n",
    "                        )   \n",
    "            else:\n",
    "                if str(port_number) not in switch_port_mapping[openflow_id]:\n",
    "\n",
    "                    print(\"\\n\\nQueue was not installed in \",openflow_id, \" interface: \", port_number, \"\\nInstalling now...\\n\")\n",
    "                    print(\"\\nCheckpoint*******Entering queue creation\\n\\n******\")\n",
    "\n",
    "                    create_two_queue_for_switch(\n",
    "                        switch=openflow_id,  port=port_number,\n",
    "                        queue_configs=[\n",
    "                            (6000000, 6000000),  # Queue 0\n",
    "                            (4000000, 4000000)   # Queue 1\n",
    "                        ]\n",
    "                        )\n",
    "\n",
    "    if run_LLM_IBN(intent, openflow_id):\n",
    "        proc_time_s = (time.time() - current_time)\n",
    "        print(\"\\n\\nSuccessfully translated and installed the rule in ODL SDN Controller. Time taken: \", proc_time_s)\n",
    "    else:\n",
    "        print(\"\\n\\nFailed to install the intent.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
