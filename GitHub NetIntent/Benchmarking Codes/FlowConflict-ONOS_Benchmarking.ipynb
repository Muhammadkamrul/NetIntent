{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from ollama import Client\n",
    "import json\n",
    "import csv\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFLICT_PROMPT_ONOS = \"\"\"You are tasked with determining if two ONOS flow configuration JSONs directly conflict with each other. **You MUST base your decision SOLELY on the JSON content provided.** Do **NOT** infer intent, use semantic reasoning, or make assumptions beyond the given JSON structure.\n",
    "\n",
    "---\n",
    "\n",
    "### **Rules for Conflict Detection (STRICT and LITERAL COMPARISON):**\n",
    "\n",
    "A **direct conflict** exists **ONLY IF** all the following conditions are met:\n",
    "\n",
    "#### **1. Matching Traffic Characteristics (Exact or Overlapping Match Criteria)**\n",
    "Both flows must match **overlapping traffic characteristics** for all the specified fields, meaning they could apply to the **exact same packets**. The following fields are checked:\n",
    "\n",
    "**EtherType (`ETH_TYPE`)**  \n",
    "   - Must be present in **both** flows and have **identical** values (e.g., `\"0x800\"` for IPv4, `\"0x86DD\"` for IPv6).\n",
    "   - If missing in either flow, there is **no match**.\n",
    "\n",
    "**Source and Destination IP (`IPV4_SRC` and `IPV4_DST`)**  \n",
    "   - If both flows **specify** a source or destination, they must overlap (e.g., `\"10.0.0.1/32\"` and `\"10.0.0.0/24\"` overlap).\n",
    "   - If **either** flow **omits** source or destination, it applies to **all** sources or destinations respectively.\n",
    "\n",
    "**Protocol (`IP_PROTO`)**  \n",
    "   - Must be present in **both** flows and have **identical** values (e.g., `6` for TCP, `17` for UDP).\n",
    "   - If missing in either flow, there is **no match**.\n",
    "\n",
    "**Transport Layer Ports (`TCP_SRC`, `TCP_DST`, `UDP_SRC`, `UDP_DST`)**  \n",
    "   - Must be **identical** in both flows if present.\n",
    "   - If one flow includes a port filter and the other does not, there is **no match**.\n",
    "\n",
    "**Incoming Port (`IN_PORT`)**  \n",
    "   - If both flows specify `IN_PORT`, they must be identical.\n",
    "   - If missing in either flow, there is **no match**.\n",
    "\n",
    "**Wildcard Matching (Implicit Behavior for Missing Fields)**  \n",
    "   - If a flow **specifies a field** (e.g., `IPV4_SRC`), it applies **only** to that source.\n",
    "   - If a flow **does not specify a field** (e.g., `IPV4_SRC`), it applies to **all sources**.\n",
    "   - General vs. specific distinctions are not classified, but missing fields imply generality (i.e., match all). Conflicts are determined based on whether the two match sets could overlap.\n",
    "---\n",
    "\n",
    "#### **2. Contradictory Actions**\n",
    "Flows that **match the same traffic** only conflict if their actions contradict in one of the following ways:\n",
    "\n",
    "**Different Output Ports (`OUTPUT` instruction)**  \n",
    "   - If one flow **forwards** traffic to port `X` and another to port `Y`, it is a **conflict**.\n",
    "\n",
    "**One Flow Drops, One Flow Forwards**  \n",
    "   - If one flow **omits `\"treatment\"`** (implying a drop) and another **forwards traffic**, it is a **conflict**.\n",
    "\n",
    "**Different Queue Assignments (`QUEUE` instruction)**  \n",
    "   - If the flows **assign different `queueId` values**, it is a **conflict**.\n",
    "\n",
    "**Note on Additional Match Fields:**  \n",
    "   - If one flow includes additional match fields, a conflict may still exist if the effective match space overlaps. Extra fields do not automatically prevent a conflict.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Priority is Irrelevant for Conflict Detection**\n",
    "- `priority` **does not** determine a conflict.\n",
    "- Even if one rule **overrides** another, they **do not conflict** unless their actions contradict.\n",
    "\n",
    "---\n",
    "\n",
    "### **Input Format**\n",
    "You will be provided with **two ONOS JSON flow rules** in the following format:\n",
    "\n",
    "**Flow 1:**\n",
    "```json\n",
    "<JSON for Flow 1>\n",
    "\n",
    "**Flow 2:**\n",
    "<JSON for Flow 2>\n",
    "\n",
    "### **Expected Output Format**\n",
    "Respond strictly in valid JSON format, using the schema below:\n",
    "\n",
    "{\n",
    "    \"conflict_status\": <integer>,\n",
    "    \"conflict_explanation\": \"<conflict explanation, if any>\"\n",
    "}\n",
    "\n",
    "Field Descriptions:\n",
    "   - conflict_status should be 1 if a direct conflict exists, 0 otherwise.\n",
    "   - conflict_explanation → A brief explanation if a conflict exists, otherwise an empty string \"\".\n",
    "\n",
    "NO EXTRA TEXT, COMMENTS, OR EXPLANATIONS OUTSIDE JSON.\n",
    "DO NOT return 1 unless you are certain of a direct conflict.\n",
    "Follow strict field-by-field comparison rules—NO inference beyond given data.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_models = [\n",
    "\"marco-o1\",\n",
    "\"mistral\",\n",
    "\"mistral-nemo\",\n",
    "\"deepseek-coder\",\n",
    "\"starcoder\", \n",
    "\"codegemma\",\n",
    "\"starcoder2\",\n",
    "\"openchat\",\n",
    "\"phi3\",\n",
    "\"dolphin-mistral\",\n",
    "\"wizardlm2\",\n",
    "\"phi\",\n",
    "\"yi\",\n",
    "\"zephyr\",\n",
    "\"command-r\",\n",
    "\"llava-llama3\",\n",
    "\"codestral\",\n",
    "\"codellama:34b\",\n",
    "\"codellama\",\n",
    "\"llama2\",\n",
    "\"llama3\",\n",
    "\"llama3.1\",\n",
    "\"llama3.2\",\n",
    "\"qwen\",\n",
    "\"qwen2\",\n",
    "\"qwen2.5\",\n",
    "\"gemma2:27b\",\n",
    "\"huihui_ai/qwq-abliterated\",\n",
    "\"huihui_ai/qwq-fusion\",\n",
    "\"qwq\",\n",
    "\"llama3.3\",\n",
    "\"llama2:70b\",\n",
    "\"codellama:70b\"\n",
    "]\n",
    "\n",
    "default_model = \"llama2\"\n",
    "\n",
    "ollama_embedding_url = \"http://10.23.7.63:11434\"\n",
    "ollama_server_url = \"http://10.23.7.63:11435\"  \n",
    "\n",
    "ollama_emb = OllamaEmbeddings(\n",
    "    model=default_model,\n",
    "    base_url=ollama_embedding_url,\n",
    ")\n",
    "\n",
    "client = Client(host=ollama_server_url , timeout=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_LLM_conflict(flow_json_1, flow_json_2, model):\n",
    "    \n",
    "    system_prompt = CONFLICT_PROMPT_ONOS\n",
    "    count = 0\n",
    "    while True:\n",
    "        count+=1\n",
    "        try:\n",
    "            time.sleep(0.1)\n",
    "\n",
    "            response = client.generate(model=model,\n",
    "                options={'temperature': 0.3, 'num_ctx': 8192, 'top_p': 0.5, 'num_predict': 1024, 'num_gpu': 99},\n",
    "                stream=False,\n",
    "                system=system_prompt,\n",
    "                prompt=f\"Flow 1:\\n{json.dumps(flow_json_1, indent=2)}\\n\\nFlow 2:\\n{json.dumps(flow_json_2, indent=2)}\",\n",
    "                format='json'\n",
    "            )\n",
    "\n",
    "            output = response['response'].strip()\n",
    "\n",
    "            response_json = json.loads(output)\n",
    "\n",
    "            if 'conflict_status' not in response_json:\n",
    "                #print(\"\\nWarning: 'conflict_status' key is missing in the response.\\n\")\n",
    "                break\n",
    "            else:\n",
    "                valid_conflict_response = True\n",
    "                conflict_status = response_json.get('conflict_status', 0)\n",
    "                # Ensure conflict_status is an integer\n",
    "                if isinstance(conflict_status, str):\n",
    "                    conflict_status = int(conflict_status)\n",
    "\n",
    "                return valid_conflict_response, conflict_status, response_json['conflict_explanation']             \n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Exception found: \", e)\n",
    "            sys.stdout.flush()\n",
    "            if(count<15):\n",
    "                continue\n",
    "            else:\n",
    "                print(\"\\n\",model, \" failed to produce valid JSON for conflict info after 15 tries. Going to next model\\n\")\n",
    "                break               \n",
    "    \n",
    "    return False, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conflict(flow_json_1, flow_json_2):\n",
    "    \n",
    "    valid_conflict_response, conflict_status, conflict_details = run_LLM_conflict(flow_json_1, flow_json_2)\n",
    "\n",
    "    if (valid_conflict_response == False):\n",
    "        return 2, None  #2 means here that LLM could not generate valid JSON for conflict reporting\n",
    "    elif (conflict_status == 1):\n",
    "        return conflict_status, conflict_details\n",
    "        \n",
    "    return 0, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_load_flow_json(flow_str, index_number):\n",
    "    try:\n",
    "        return ast.literal_eval(flow_str)\n",
    "    except Exception as e:\n",
    "        print(f\"[Index {index_number}] Error parsing flow JSON from excel using ast.literal_eval: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"FlowConflict-ONOS.xlsx\")\n",
    "\n",
    "# ---- Model-level summary collection ----\n",
    "summary_rows = []\n",
    "\n",
    "for model in my_models:\n",
    "    TP = FP = TN = FN = 0\n",
    "    times = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "\n",
    "        index_number = row[\"Sl.\"]\n",
    "        flow_rule_1_json = safe_load_flow_json(row[\"ONOS Flow Rule 1\"], index_number)\n",
    "        flow_rule_2_json = safe_load_flow_json(row[\"ONOS Flow Rule 2\"], index_number)\n",
    "\n",
    "        ground_truth_conflict = row[\"Conflicting\"].strip().lower()  # 'yes' or 'no'\n",
    "        gt_conflict = (ground_truth_conflict == 'yes')\n",
    "\n",
    "        if (flow_rule_1_json is None) or (flow_rule_2_json is None):\n",
    "            continue\n",
    "\n",
    "        start_conflict_time = time.time()\n",
    "        valid_conflict_response, conflict_status, conflict_details = run_LLM_conflict(\n",
    "            flow_rule_1_json, flow_rule_2_json, model=model)\n",
    "        conflict_duration = time.time() - start_conflict_time\n",
    "        times.append(conflict_duration)\n",
    "\n",
    "        # Only score if a valid result was returned\n",
    "        if conflict_status == 2 or not valid_conflict_response:\n",
    "            continue\n",
    "        detected_conflict = (conflict_status == 1)\n",
    "\n",
    "        # Update counts\n",
    "        if detected_conflict and gt_conflict:\n",
    "            TP += 1\n",
    "        elif detected_conflict and not gt_conflict:\n",
    "            FP += 1\n",
    "        elif not detected_conflict and not gt_conflict:\n",
    "            TN += 1\n",
    "        elif not detected_conflict and gt_conflict:\n",
    "            FN += 1\n",
    "\n",
    "    total = TP + TN + FP + FN\n",
    "    accuracy = (TP + TN) / total if total > 0 else 0\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    fpr = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
    "    avg_time = sum(times) / len(times) if times else 0\n",
    "\n",
    "    summary_rows.append([\n",
    "        model, TP, FP, TN, FN, round(accuracy, 4), round(precision, 4),\n",
    "        round(recall, 4), round(f1, 4), round(fpr, 4), round(avg_time, 4)\n",
    "    ])\n",
    "\n",
    "# ---- Write summary CSV ----\n",
    "with open(\"conflict_detection_model_summaries.csv\", 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Model\", \"TP\", \"FP\", \"TN\", \"FN\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"FPR\", \"Avg Time (s)\"])\n",
    "    for row in summary_rows:\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(\"Processing completed. Model summaries saved to CSV.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onos_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
