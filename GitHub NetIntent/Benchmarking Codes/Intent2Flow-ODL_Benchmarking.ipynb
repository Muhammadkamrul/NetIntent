{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.example_selectors import MaxMarginalRelevanceExampleSelector\n",
    "#from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from ollama import Client\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSLATION_PROMPT = \"\"\"Your task is to transform natural language network intents into JSON-formatted network policies compatible with the OpenDaylight (ODL) SDN controller's configuration datastore.\n",
    "\n",
    "You only reply in JSON, no natural language. The network intents can represent different traffic control behaviors, such as:\n",
    "\n",
    "a. **Traffic Forwarding and Queue-Based Traffic Control Rule:** Define rules for forwarding traffic based on IPv4 destination, TCP/UDP ports, and optionally assign traffic to specific queues for prioritization. \n",
    "b. **Firewall and Blocking:** Define rules to drop traffic based on specific match criteria (e.g., source IP, destination IP).  \n",
    "c. **Port-Based Forwarding:** Redirect traffic entering a specific port to another designated port.\n",
    "\n",
    "### JSON STRUCTURE:\n",
    "\n",
    "1. **Traffic Forwarding and Queue-Based Traffic Control Rule:**  \n",
    "\n",
    "```json\n",
    "{\n",
    "  \"flow-node-inventory:flow\": [\n",
    "    {\n",
    "      \"id\": \"<unique_id>\",\n",
    "      \"priority\": <integer>,\n",
    "      \"table_id\": <integer>,\n",
    "      \"flow-name\": \"<descriptive_name>\",\n",
    "      \"hard-timeout\": <integer>,\n",
    "      \"idle-timeout\": <integer>,\n",
    "      \"match\": {\n",
    "        \"ethernet-match\": {\n",
    "          \"ethernet-type\": {\n",
    "            \"type\": 2048\n",
    "          }\n",
    "        },\n",
    "        \"ipv4-source\": \"<ip_address/mask>\", //**optional**\n",
    "        \"ipv4-destination\": \"<ip_address/mask>\", //**optional**\n",
    "        \"ip-match\": {\n",
    "          \"ip-protocol\": <integer>\n",
    "        },\n",
    "        \"tcp-destination-port\": <integer>,\n",
    "        \"udp-destination-port\": <integer>\n",
    "      },\n",
    "      \"instructions\": {\n",
    "        \"instruction\": [\n",
    "          {\n",
    "            \"order\": 0,\n",
    "            \"apply-actions\": {\n",
    "              \"action\": [\n",
    "                {\n",
    "                  \"order\": 0,\n",
    "                  \"set-queue-action\": {\n",
    "                    \"queue-id\": <queue_id>\n",
    "                  }\n",
    "                },\n",
    "                {\n",
    "                  \"order\": 1,\n",
    "                  \"output-action\": {\n",
    "                    \"output-node-connector\": \"<port_number>\"\n",
    "                  }\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "2. **Blocking or Dropping Rule:**  \n",
    "\n",
    "{\n",
    "  \"flow-node-inventory:flow\": [\n",
    "    {\n",
    "      \"id\": \"<unique_id>\",\n",
    "      \"priority\": <integer>,\n",
    "      \"table_id\": <integer>,\n",
    "      \"flow-name\": \"<descriptive_name>\",\n",
    "      \"hard-timeout\": <integer>,\n",
    "      \"idle-timeout\": <integer>,\n",
    "      \"match\": {\n",
    "        \"ethernet-match\": {\n",
    "          \"ethernet-type\": {\n",
    "            \"type\": <integer>\n",
    "          }\n",
    "        },\n",
    "        \"ipv4-source\": \"<ip_address/mask>\",\n",
    "        \"ipv4-destination\": \"<ip_address/mask>\"\n",
    "      },\n",
    "      \"instructions\": {\n",
    "        \"instruction\": [\n",
    "          {\n",
    "            \"order\": 0,\n",
    "            \"apply-actions\": {\n",
    "              \"action\": [\n",
    "                {\n",
    "                  \"order\": 0,\n",
    "                  \"drop-action\": {}\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "3. **Port-Based Forwarding Rule:**  \n",
    "\n",
    "{\n",
    "  \"flow-node-inventory:flow\": [\n",
    "    {\n",
    "      \"id\": \"<unique_id>\",\n",
    "      \"priority\": <integer>,\n",
    "      \"table_id\": <integer>,\n",
    "      \"flow-name\": \"<descriptive_name_summerizing_the_intent>\",\n",
    "      \"hard-timeout\": <integer>,\n",
    "      \"idle-timeout\": <integer>,\n",
    "      \"match\": {\n",
    "        \"in-port\": <port_number>\n",
    "      },\n",
    "      \"instructions\": {\n",
    "        \"instruction\": [\n",
    "          {\n",
    "            \"order\": 0,\n",
    "            \"apply-actions\": {\n",
    "              \"action\": [\n",
    "                {\n",
    "                  \"order\": 0,\n",
    "                  \"output-action\": {\n",
    "                    \"output-node-connector\": \"<port_number>\"\n",
    "                  }\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "Field Descriptions: \n",
    "id: A number representing a unique identifier for the flow (0 for default).\n",
    "priority: Priority level (higher numbers indicate higher priority). For dropping or blocking or firewall rule, assign priority greater than 300.\n",
    "table_id: An integer representing the flow table identifier (0 for default).\n",
    "flow-name: A short, descriptive flow name that summerizes the intent.\n",
    "hard-timeout: Timeout in seconds after which the flow is removed (0 for default).\n",
    "idle-timeout: Timeout in seconds after which the flow is removed if there's no activity (0 for default).\n",
    "ethernet-type: Ethernet protocol type (e.g., 2048 for IPv4).\n",
    "ipv4-destination: IPv4 address in CIDR notation (e.g., 10.0.0.1/32). Note: This field is optional. Don't include it unless IP address (e.g., 10.0.0.1) is explicitly mentioned in the intent.\n",
    "ipv4-source: Source IP address (optional). Note: This field is optional. Don't include it unless IP address (e.g., 10.0.0.1) is explicitly mentioned in the intent.\n",
    "ip-protocol: Use \"ip-match\" and \"ip-protocol\" when specifying specific transport layer protocols (e.g., 6 for TCP, 17 for UDP, 1 for ICMP (optional)).\n",
    "tcp-source-port: The source port for the connection, usually a random high port on the client (rarely fixed) (optional).\n",
    "tcp-destination-port: The destination port for the connection (i.e., the server port, e.g., 80 for HTTP) (optional).\n",
    "udp-source-port: UDP port number (optional).\n",
    "udp-destination-port: UDP port number (optional).\n",
    "in-port: A value representing incoming interface port number (optional).\n",
    "output-action: Use \"output-action\" and \"output-node-connector\" to specify the output port number (optional).\n",
    "set-queue-action: Use \"set-queue-action\" and \"queue-id\" when the intent specifies assigning traffic to a queue (The \"queue-id\" is an integer (0 for default)).\n",
    "drop-action: Use {} to indicate packet dropping.\n",
    "\n",
    "RULES:\n",
    "Each id must be unique.\n",
    "Set priority values appropriately (higher for critical rules, lower for defaults). Set priority very high (e.g., 500) for queue related rules.\n",
    "Don't include any **optional field** unless it is explicitly mentioned in the intent.\n",
    "Use valid match conditions (ipv4-destination, tcp-destination-port, ipv4-source, in-port) depending on the intent type.\n",
    "When translating HTTP, HTTPS, or other protocol traffic by port, always use 'tcp-destination-port' for the protocol's standard server port (e.g., 80 for HTTP, 443 for HTTPS) unless the intent explicitly says 'source port'.\n",
    "Ensure valid ODL-compliant JSON syntax.\n",
    "Avoid duplicate keys and empty fields.\n",
    "Verify JSON structure for correctness before responding.\n",
    "Always respond with valid JSON only, with no additional text, comments, or explanations.\n",
    "If the intent cannot be mapped, return an empty JSON object {}.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = [0, 1, 3, 6, 9]\n",
    "\n",
    "my_models = [\n",
    "\"marco-o1\",\n",
    "\"mistral\",\n",
    "\"mistral-nemo\",\n",
    "\"deepseek-coder\",\n",
    "\"starcoder\", \n",
    "\"codegemma\",\n",
    "\"starcoder2\",\n",
    "\"openchat\",\n",
    "\"phi3\",\n",
    "\"dolphin-mistral\",\n",
    "\"wizardlm2\",\n",
    "\"phi\",\n",
    "\"yi\",\n",
    "\"zephyr\",\n",
    "\"command-r\",\n",
    "\"llava-llama3\",\n",
    "\"codestral\",\n",
    "\"codellama:34b\",\n",
    "\"codellama\",\n",
    "\"llama2\",\n",
    "\"llama3\",\n",
    "\"llama3.1\",\n",
    "\"llama3.2\",\n",
    "\"qwen\",\n",
    "\"qwen2\",\n",
    "\"qwen2.5\",\n",
    "\"gemma2:27b\",\n",
    "\"huihui_ai/qwq-abliterated\",\n",
    "\"huihui_ai/qwq-fusion\",\n",
    "\"qwq\"\n",
    "]\n",
    "\n",
    "#\"tinyllama\", \"orca-mini\" does not produce meaningful output\n",
    "\n",
    "default_model = \"llama2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_embedding_url = \"http://localhost:11434\"\n",
    "ollama_server_url = \"http://localhost:11435\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_emb = OllamaEmbeddings(\n",
    "    model=default_model,\n",
    "    base_url=ollama_embedding_url,\n",
    ")\n",
    "\n",
    "client = Client(host=ollama_server_url , timeout=120)\n",
    "\n",
    "# Load custom dataset from CSV\n",
    "custom_dataset = pd.read_csv('Intent2Flow-ODL.csv')\n",
    "\n",
    "# Ensure proper column names and format\n",
    "if not {'instruction', 'output'}.issubset(custom_dataset.columns):\n",
    "    raise ValueError(\"The dataset must have 'instruction' and 'output' columns.\")\n",
    "\n",
    "# Split into train and test (50/50 split for example)\n",
    "trainset, testset = train_test_split(custom_dataset, test_size=0.5, random_state=42, shuffle=True)\n",
    "\n",
    "# SYSTEM PROMPT (Manually define)\n",
    "SYSTEM_PROMPT = TRANSLATION_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_odl_value(value):\n",
    "    if isinstance(value, str) and value.isdigit():\n",
    "        return int(value)\n",
    "    return value\n",
    "\n",
    "def dict_equal_odl(d1, d2, ignore_fields=set()):\n",
    "    \"\"\"Recursively compare ODL dictionaries ignoring specified fields.\"\"\"\n",
    "    if isinstance(d1, dict) and isinstance(d2, dict):\n",
    "        keys1 = set(d1.keys()) - ignore_fields\n",
    "        keys2 = set(d2.keys()) - ignore_fields\n",
    "        if keys1 != keys2:\n",
    "            return False\n",
    "        for k in keys1:\n",
    "            if not dict_equal_odl(d1[k], d2[k], ignore_fields):\n",
    "                return False\n",
    "        return True\n",
    "    elif isinstance(d1, list) and isinstance(d2, list):\n",
    "        norm1 = sorted([normalize_odl_value(item) if not isinstance(item, dict) else item for item in d1], key=str)\n",
    "        norm2 = sorted([normalize_odl_value(item) if not isinstance(item, dict) else item for item in d2], key=str)\n",
    "        if len(norm1) != len(norm2):\n",
    "            return False\n",
    "        for x, y in zip(norm1, norm2):\n",
    "            if not dict_equal_odl(x, y, ignore_fields):\n",
    "                return False\n",
    "        return True\n",
    "    else:\n",
    "        return normalize_odl_value(d1) == normalize_odl_value(d2)\n",
    "\n",
    "def compare_odl_json(expected_json, actual_json):\n",
    "    \"\"\"\n",
    "    Returns True if actual ODL output matches expected, ignoring irrelevant fields.\n",
    "    \"\"\"\n",
    "    #ignore_fields = {\"id\", \"flow-name\"}  # Add more if needed, e.g., statistics fields\n",
    "    ignore_fields = {\"id\", \"flow-name\", \"priority\", \"hard-timeout\", \"idle-timeout\"}\n",
    "    \n",
    "    # Defensive deep copy\n",
    "    expected_json = copy.deepcopy(expected_json)\n",
    "    actual_json = copy.deepcopy(actual_json)\n",
    "\n",
    "    # Clean\n",
    "    def clean(json_obj):\n",
    "        for flow in json_obj.get(\"flow-node-inventory:flow\", []):\n",
    "            for field in ignore_fields:\n",
    "                flow.pop(field, None)\n",
    "        return json_obj\n",
    "    expected_json = clean(expected_json)\n",
    "    actual_json = clean(actual_json)\n",
    "\n",
    "    # Now compare the (first) flow dicts\n",
    "    ex = expected_json.get(\"flow-node-inventory:flow\", [])[0] if expected_json.get(\"flow-node-inventory:flow\") else {}\n",
    "    ac = actual_json.get(\"flow-node-inventory:flow\", [])[0] if actual_json.get(\"flow-node-inventory:flow\") else {}\n",
    "\n",
    "    return dict_equal_odl(ex, ac, ignore_fields)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv = \"odl_translation_accuracy_results.csv\"\n",
    "results = []\n",
    "\n",
    "for model in my_models:\n",
    "    row = [model]\n",
    "    for num_context in num_examples:\n",
    "        correct_count = 0\n",
    "        total_count = 0\n",
    "        time_list = []\n",
    "        # setup selector...\n",
    "        example_selector = MaxMarginalRelevanceExampleSelector.from_examples(\n",
    "            [{\"instruction\": trainset.iloc[0][\"instruction\"], \"output\": trainset.iloc[0][\"output\"]}],\n",
    "            ollama_emb,\n",
    "            Chroma,\n",
    "            input_keys=[\"instruction\"],\n",
    "            k=num_context,\n",
    "            vectorstore_kwargs={\"fetch_k\": min(num_context, len(trainset))}\n",
    "        )\n",
    "        example_selector.vectorstore.reset_collection()\n",
    "        for _, row_ in trainset.iterrows():\n",
    "            example_selector.add_example({\n",
    "                \"instruction\": row_[\"instruction\"],\n",
    "                \"output\": row_[\"output\"]\n",
    "            })\n",
    "\n",
    "        for _, testcase in testset.iterrows():\n",
    "            intent = testcase[\"instruction\"]\n",
    "            expected_output = testcase[\"output\"]\n",
    "\n",
    "            system_prompt = SYSTEM_PROMPT\n",
    "            try_count = 0\n",
    "            while True:\n",
    "                try:\n",
    "                    time.sleep(0.1)\n",
    "                    t0 = time.time()\n",
    "                    if num_context > 0:\n",
    "                        examples = example_selector.select_examples({\"instruction\": intent})\n",
    "                        example_str = \"\\n\\n\\n\".join(map(lambda x: \"Input: \" + x[\"instruction\"] + \"\\n\\nOutput: \" + x[\"output\"], examples))\n",
    "                        system_prompt += example_str + \"\\n\\n\\n\"  \n",
    "                    response = client.generate(\n",
    "                        model=model,\n",
    "                        options={\n",
    "                            'temperature': 0.6,\n",
    "                            'num_ctx': 8192,\n",
    "                            'top_p': 0.3,\n",
    "                            'num_predict': 1024,\n",
    "                            'num_gpu': 99,\n",
    "                        },\n",
    "                        stream=False,\n",
    "                        system=system_prompt,\n",
    "                        prompt=intent,\n",
    "                        format='json'\n",
    "                    )\n",
    "                    proc_time_s = (time.time() - t0)\n",
    "                    time_list.append(proc_time_s)\n",
    "                    actual_output = response['response']\n",
    "                    break\n",
    "                except Exception as e:\n",
    "                    print(\"Exception on Input: \", e)\n",
    "                    try_count += 1\n",
    "                    if try_count > 10:\n",
    "                        actual_output = '{}'\n",
    "                        break\n",
    "                    continue\n",
    "\n",
    "            try:\n",
    "                expected_json = json.loads(expected_output)\n",
    "                actual_json = json.loads(actual_output)\n",
    "                total_count += 1\n",
    "\n",
    "                result = compare_odl_json(expected_json, actual_json)\n",
    "\n",
    "                if (not result):\n",
    "                    print(\"\\n\\n\\n\")\n",
    "                    print(expected_json)\n",
    "                    print(\"\\n\")\n",
    "                    print(actual_json)\n",
    "                    print(\"\\n\")\n",
    "                    print(\"Result: \", result)\n",
    "\n",
    "                else:\n",
    "                    correct_count += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"\\n\\n\")\n",
    "                print(expected_json)\n",
    "                print(\"\\n\")\n",
    "                print(actual_json)\n",
    "                print(\"\\n\\n\")\n",
    "                print(\"Exception found: \", e)\n",
    "                total_count += 1  # still count as attempted\n",
    "\n",
    "        accuracy = correct_count / total_count if total_count > 0 else 0\n",
    "        avg_time = sum(time_list) / len(time_list) if time_list else 0\n",
    "        row += [num_context, round(accuracy, 4), round(avg_time, 3)]\n",
    "        print(f\"Model: {model}, Context: {num_context}, Accuracy: {accuracy:.4f}, Avg Time: {avg_time:.2f}\")\n",
    "\n",
    "    results.append(row)\n",
    "\n",
    "# Save to CSV\n",
    "with open(output_csv, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # Write header\n",
    "    header = [\"Model\"]\n",
    "    for num_context in num_examples:\n",
    "        header += [f\"context_{num_context}\", f\"accuracy_{num_context}\", f\"avg_time_{num_context}\"]\n",
    "    writer.writerow(header)\n",
    "    for row in results:\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(\"Results written to\", output_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
