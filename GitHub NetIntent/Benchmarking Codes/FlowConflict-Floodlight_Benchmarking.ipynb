{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from ollama import Client\n",
    "import json\n",
    "import csv\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFLICT_PROMPT_FLOODLIGHT = \"\"\"\n",
    "You are an expert network engineer analyzing two Floodlight (OpenFlow) flow rules to decide whether they conflict.\n",
    "\n",
    "PRIMARY DECISION\n",
    "A conflict exists if BOTH are true:\n",
    "1) The rules apply to the same switch (equal \"switch\"; if both specify \"table\", tables must be equal too).\n",
    "2) Their match conditions overlap (there exists at least one packet that matches both),\n",
    "   AND either:\n",
    "   a) their actions differ, or\n",
    "   b) they are redundant (same action and one rule’s match is a subset of the other).\n",
    "\n",
    "DEFINITIONS & NORMALIZATION\n",
    "- Floodlight drop = the \"actions\" key is absent. (Empty string is treated as drop ONLY if present in the input.)\n",
    "- Actions are a comma-separated list in a single string (e.g., \"set_queue=1,output=2\"). Compare actions as an unordered set of tokens; ignore whitespace and token order.\n",
    "- Consider only top-level match keys (e.g., \"in_port\", \"eth_type\", \"ip_proto\", \"ipv4_src\", \"ipv4_dst\", \"tcp_dst\", \"udp_dst\", \"eth_vlan_vid\", etc.). Keys like \"name\", \"active\", \"priority\" do not affect matching.\n",
    "- Normalize values before comparison:\n",
    "  • eth_type: \"0x800\" == \"0x0800\" (IPv4).  \n",
    "  • ip_proto: accept \"6\"/\"tcp\", \"17\"/\"udp\", \"1\"/\"icmp\".  \n",
    "  • ports and priorities: compare numerically even if strings.  \n",
    "  • IPs may be host (/32) or CIDR; treat \"10.0.0.1\" as \"10.0.0.1/32\".\n",
    "- Match overlap rules:\n",
    "  • If \"eth_type\" differ (e.g., IPv4 vs IPv6), no overlap.  \n",
    "  • If \"ip_proto\" differ (e.g., TCP vs UDP), no overlap.  \n",
    "  • If both specify \"in_port\" with different values, no overlap.  \n",
    "  • IP prefixes overlap if their CIDRs intersect (e.g., 10.0.0.0/24 overlaps 10.0.0.1/32).  \n",
    "  • TCP/UDP port equality is required when both specify the same L4 field.  \n",
    "  • VLAN: \"eth_vlan_vid\" must be equal if both specify it; otherwise the more general one (no VLAN constraint) overlaps the specific one.  \n",
    "  • Absence of a field makes a rule more general on that dimension.\n",
    "\n",
    "GUIDANCE\n",
    "- Different \"switch\" → no conflict. If both specify \"table\" and they differ → no conflict.  \n",
    "- Overlap + different actions → conflict.  \n",
    "- Overlap + same actions:\n",
    "    • If one match ⊂ the other → conflict (Redundancy).  \n",
    "    • If partial overlap without subset and same actions → treat as no conflict for this binary decision.\n",
    "- Priority does not affect the YES/NO decision, but may be used in the explanation (e.g., “more general rule may shadow a specific rule if higher priority”).\n",
    "\n",
    "EXAMPLES\n",
    "\n",
    "Example A: Conflict (Different Action)\n",
    "F1: {\"switch\":\"...:01\",\"eth_type\":\"0x0800\",\"ipv4_dst\":\"10.0.0.1\",\"actions\":\"output=1\"}\n",
    "F2: {\"switch\":\"...:01\",\"eth_type\":\"0x0800\",\"ipv4_dst\":\"10.0.0.1\",\"actions\":\"output=2\"}\n",
    "Output: {\"conflict_status\":1,\"conflict_explanation\":\"Same switch and identical match; actions differ (output=1 vs output=2).\"}\n",
    "\n",
    "Example B: No Conflict (Different Switch)\n",
    "F1: {\"switch\":\"...:01\",\"eth_type\":\"0x0800\",\"ipv4_dst\":\"10.0.0.1\",\"actions\":\"output=3\"}\n",
    "F2: {\"switch\":\"...:02\",\"eth_type\":\"0x0800\",\"ipv4_dst\":\"10.0.0.1\",\"actions\":\"output=3\"}\n",
    "Output: {\"conflict_status\":0,\"conflict_explanation\":\"Different switches.\"}\n",
    "\n",
    "Example C: Conflict (Redundancy)\n",
    "F1: {\"switch\":\"...:04\",\"eth_type\":\"0x0800\",\"ip_proto\":\"6\",\"tcp_dst\":\"80\",\"actions\":\"output=2\"}\n",
    "F2: {\"switch\":\"...:04\",\"eth_type\":\"0x0800\",\"ip_proto\":\"6\",\"actions\":\"output=2\"}\n",
    "Output: {\"conflict_status\":1,\"conflict_explanation\":\"Specific rule is subset of a more general rule with the same action (redundancy).\"}\n",
    "\n",
    "Example D: No Conflict (Protocol Mismatch)\n",
    "F1: {\"switch\":\"...:01\",\"eth_type\":\"0x0800\",\"ip_proto\":\"6\",\"tcp_dst\":\"22\",\"actions\":\"output=1\"}\n",
    "F2: {\"switch\":\"...:01\",\"eth_type\":\"0x0800\",\"ip_proto\":\"17\",\"udp_dst\":\"53\",\"actions\":\"output=1\"}\n",
    "Output: {\"conflict_status\":0,\"conflict_explanation\":\"TCP vs UDP are mutually exclusive.\"}\n",
    "\n",
    "INPUT FORMAT\n",
    "You will be provided with two JSON flow rules:\n",
    "\n",
    "Flow 1:\n",
    "<JSON>\n",
    "\n",
    "Flow 2:\n",
    "<JSON>\n",
    "\n",
    "EXPECTED OUTPUT (strict JSON only):\n",
    "{\n",
    "  \"conflict_status\": <0 or 1>,\n",
    "  \"conflict_explanation\": \"<brief reason or empty string>\"\n",
    "}\n",
    "NO EXTRA TEXT.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model names should match the downloaded ollama model names. \n",
    "# If ollama does not find a model, check ollama model list (write in terminal: \"ollama list\" without quote) and model names. Use the correct model name.\n",
    "\n",
    "my_models=[\n",
    "    \"codegemma:7b\",\n",
    "    \"codestral:22b\",\n",
    "    \"codellama:34b\",\n",
    "    \"codellama:7b\",\n",
    "    \"command-r:35b\",\n",
    "    \"deepseek-coder:1.3b\",\n",
    "    \"Deepseek-coder-v2:16b\",\n",
    "    \"dolphin-mistral:7b\",\n",
    "    \"gemma2:27b\",\n",
    "    \"huihui_ai/qwq-abliterated:latest\",\n",
    "    \"huihui_ai/qwq-fusion:latest\",\n",
    "    \"llama2:7b\",\n",
    "    \"Llama3:8b\",\n",
    "    \"llama3.1:8b\",\n",
    "    \"llama3.2:3b\",\n",
    "    \"llava-llama3:8b\",\n",
    "    \"marco-o1:7b\",\n",
    "    \"mistral:latest\",\n",
    "    \"mistral-nemo:12b\",\n",
    "    \"openchat:7b\",\n",
    "    \"orca-mini:3b\",\n",
    "    \"phi:2.7b\",\n",
    "    \"phi3:3.8b\",\n",
    "    \"qwen:4b\",\n",
    "    \"qwen2:7b\",\n",
    "    \"qwen2.5:7b\",\n",
    "    \"qwq:latest\",\n",
    "    \"starcoder:3b\",\n",
    "    \"starcoder2:3b\",\n",
    "    \"TinyLlama:1.1b\",\n",
    "    \"wizardlm2:7b\",\n",
    "    \"yi:6b\",\n",
    "    \"zephyr:7b\"\n",
    "]\n",
    "\n",
    "very_large_models = [\n",
    "\"llama3.3:latest\",\n",
    "\"llama2:70b\",\n",
    "\"codellama:70b\"]\n",
    "\n",
    "default_model = \"llama2:7b\"\n",
    "\n",
    "#replace with your host IP or use localhost. Make sure the correct port number of ollama server.\n",
    "ollama_embedding_url = \"http://localhost:11434\"\n",
    "ollama_server_url = \"http://localhost:11435\"  \n",
    "\n",
    "ollama_emb = OllamaEmbeddings(\n",
    "    model=default_model,\n",
    "    base_url=ollama_embedding_url,\n",
    ")\n",
    "\n",
    "client = Client(host=ollama_server_url , timeout=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_LLM_conflict(flow_json_1, flow_json_2, model):\n",
    "    \n",
    "    system_prompt = CONFLICT_PROMPT_FLOODLIGHT\n",
    "    count = 0\n",
    "    while True:\n",
    "        count+=1\n",
    "        try:\n",
    "            time.sleep(0.1)\n",
    "\n",
    "            response = client.generate(model=model,\n",
    "                options={'temperature': 0.3, 'num_ctx': 8192, 'top_p': 0.5, 'num_predict': 1024, 'num_gpu': 99},\n",
    "                stream=False,\n",
    "                system=system_prompt,\n",
    "                prompt=f\"Flow 1:\\n{json.dumps(flow_json_1, indent=2)}\\n\\nFlow 2:\\n{json.dumps(flow_json_2, indent=2)}\",\n",
    "                format='json'\n",
    "            )\n",
    "\n",
    "            output = response['response'].strip()\n",
    "\n",
    "            response_json = json.loads(output)\n",
    "\n",
    "            if 'conflict_status' not in response_json:\n",
    "                #print(\"\\nWarning: 'conflict_status' key is missing in the response.\\n\")\n",
    "                break\n",
    "            else:\n",
    "                valid_conflict_response = True\n",
    "                conflict_status = response_json.get('conflict_status', 0)\n",
    "                # Ensure conflict_status is an integer\n",
    "                if isinstance(conflict_status, str):\n",
    "                    conflict_status = int(conflict_status)\n",
    "\n",
    "                return valid_conflict_response, conflict_status, response_json['conflict_explanation']             \n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Exception found for model: \",model, \". Reason: \", e)\n",
    "            sys.stdout.flush()\n",
    "            if(count<15):\n",
    "                continue\n",
    "            else:\n",
    "                print(\"\\n\",model, \" failed to produce valid JSON for conflict info after 15 tries. Going to next model\\n\")\n",
    "                break               \n",
    "    \n",
    "    return False, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_load_flow_json(flow_str, index_number):\n",
    "    try:\n",
    "        return ast.literal_eval(flow_str)\n",
    "    except Exception as e:\n",
    "        print(f\"[Index {index_number}] Error parsing flow JSON from excel using ast.literal_eval: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"FlowConflict-Floodlight.xlsx\")\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "for model in my_models:\n",
    "    TP = FP = TN = FN = 0\n",
    "    times = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "\n",
    "        index_number = row[\"Sl.\"]\n",
    "        flow_rule_1_json = safe_load_flow_json(row[\"Floodlight Flow Rule 1\"], index_number)\n",
    "        flow_rule_2_json = safe_load_flow_json(row[\"Floodlight Flow Rule 2\"], index_number)\n",
    "\n",
    "        ground_truth_conflict = row[\"Conflicting\"].strip().lower()  # 'yes' or 'no'\n",
    "        gt_conflict = (ground_truth_conflict == 'yes')\n",
    "\n",
    "        if (flow_rule_1_json is None) or (flow_rule_2_json is None):\n",
    "            continue\n",
    "\n",
    "        start_conflict_time = time.time()\n",
    "        valid_conflict_response, conflict_status, conflict_details = run_LLM_conflict(\n",
    "            flow_rule_1_json, flow_rule_2_json, model=model)\n",
    "        conflict_duration = time.time() - start_conflict_time\n",
    "        times.append(conflict_duration)\n",
    "\n",
    "        # Only score if a valid result was returned\n",
    "        if conflict_status == 2 or not valid_conflict_response:\n",
    "            continue\n",
    "        detected_conflict = (conflict_status == 1)\n",
    "\n",
    "        # Update counts\n",
    "        if detected_conflict and gt_conflict:\n",
    "            TP += 1\n",
    "        elif detected_conflict and not gt_conflict:\n",
    "            FP += 1\n",
    "        elif not detected_conflict and not gt_conflict:\n",
    "            TN += 1\n",
    "        elif not detected_conflict and gt_conflict:\n",
    "            FN += 1\n",
    "\n",
    "    total = TP + TN + FP + FN\n",
    "    accuracy = (TP + TN) / total if total > 0 else 0\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    fpr = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
    "    avg_time = sum(times) / len(times) if times else 0\n",
    "\n",
    "    summary_rows.append([\n",
    "        model, TP, FP, TN, FN, round(accuracy, 4), round(precision, 4),\n",
    "        round(recall, 4), round(f1, 4), round(fpr, 4), round(avg_time, 4)\n",
    "    ])\n",
    "\n",
    "# ---- Write summary CSV ----\n",
    "with open(\"Floodlight_conflict_detection_model_summaries.csv\", 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Model\", \"TP\", \"FP\", \"TN\", \"FN\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"FPR\", \"Avg Time (s)\"])\n",
    "    for row in summary_rows:\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(\"Processing completed. Model summaries saved to CSV.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onos_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
