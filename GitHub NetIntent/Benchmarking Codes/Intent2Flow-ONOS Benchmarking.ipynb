{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysqlite3\n",
    "import sys\n",
    "sys.modules[\"sqlite3\"] = sys.modules.pop(\"pysqlite3\")\n",
    "import time\n",
    "import jsondiff\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.example_selectors import MaxMarginalRelevanceExampleSelector\n",
    "#from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from ollama import Client\n",
    "import json, jsondiff\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSLATION_PROMPT_ONOS = \"\"\"Your task is to transform natural language network intents into JSON-formatted network policies compatible with the ONOS SDN controller.\n",
    "\n",
    "You only reply in JSON, no natural language. The network intents can represent different traffic control behaviors, such as:\n",
    "\n",
    "1. **Traffic Forwarding, Queue Assignment, and VLAN Rules:** Define rules for forwarding traffic based on IPv4/IPv6 destination, TCP/UDP ports, and optionally assign traffic to specific queues or vlans.\n",
    "2. **Blocking or Dropping Rule:** Define rules to drop traffic based on specific match criteria (e.g., source IP, destination IP). In ONOS, this is done by omitting the `\"treatment\"` field.\n",
    "\n",
    "### **JSON STRUCTUREs FOR ONOS**\n",
    "\n",
    "1. **Traffic Forwarding, Queue Assignment, and VLAN Rules:**  \n",
    "\n",
    "```json\n",
    "{\n",
    "    \"flows\": [\n",
    "        {\n",
    "            \"priority\": <integer>,\n",
    "            \"timeout\": <integer>, // Default: 0\n",
    "            \"isPermanent\": \"true\",\n",
    "            \"deviceId\": \"<switch_id>\",\n",
    "            \"treatment\": {\n",
    "                \"instructions\": [\n",
    "                    {\n",
    "                        \"type\": \"QUEUE\",\n",
    "                        \"queueId\": <integer>\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"L2MODIFICATION\",\n",
    "                        \"subtype\": \"VLAN_ID\",\n",
    "                        \"vlanId\": <integer> // Example: 100 for VLAN tagging\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"OUTPUT\",\n",
    "                        \"port\": \"<integer>\"\n",
    "                    }\n",
    "                ]\n",
    "            },\n",
    "            \"selector\": {\n",
    "                \"criteria\": [\n",
    "                    {\n",
    "                        \"type\": \"ETH_TYPE\",\n",
    "                        \"ethType\": \"<string>\" // Example: \"0x800\" for IPv4\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"IPV4_SRC\",\n",
    "                        \"ip\": \"<ip_address/mask>\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"IPV4_DST\",\n",
    "                        \"ip\": \"<ip_address/mask>\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"IP_PROTO\",\n",
    "                        \"protocol\": <integer> // Example: 6 for TCP, 17 for UDP\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"TCP_DST\",\n",
    "                        \"tcpPort\": <integer>\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"UDP_DST\",\n",
    "                        \"udpPort\": <integer>\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"IN_PORT\",\n",
    "                        \"port\": \"<integer>\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "2. **Blocking or Dropping Rule:**\n",
    "\n",
    "{\n",
    "    \"flows\": [\n",
    "        {\n",
    "            \"priority\": <integer>,\n",
    "            \"timeout\": 0,\n",
    "            \"isPermanent\": \"true\",\n",
    "            \"deviceId\": \"<switch_id>\",\n",
    "            \"selector\": {\n",
    "                \"criteria\": [\n",
    "                    {\n",
    "                        \"type\": \"ETH_TYPE\",\n",
    "                        \"ethType\": \"<string>\" // Example: \"0x800\" for IPv4\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"IPV4_SRC\",\n",
    "                        \"ip\": \"<ip_address/mask>\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"IPV4_DST\",\n",
    "                        \"ip\": \"<ip_address/mask>\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "Field Descriptions\n",
    "priority (Mandatory): Priority level (higher numbers indicate higher priority). For blocking or firewall rules, assign a priority greater than 300.\n",
    "timeout (Mandatory): Timeout in seconds after which the flow is removed (Default: 0).\n",
    "isPermanent (Mandatory): \"true\" (always in quotes, per user preference).\n",
    "deviceId (Mandatory): Switch ID where the rule is installed.\n",
    "ethType (Mandatory): Ethernet protocol type. Use \"0x800\" for IPv4, \"0x86DD\" for IPv6, \"0x806\" for ARP.\n",
    "IPV4_DST (Optional): IPv4 address in CIDR notation (e.g., \"10.0.0.1/32\"). Include only if explicitly mentioned.\n",
    "IPV4_SRC (Optional): Source IP address (include only if explicitly mentioned).\n",
    "IP_PROTO (Optional): Transport layer protocol (6 for TCP, 17 for UDP, 1 for ICMP).\n",
    "TCP_DST (Optional): TCP destination port (e.g., 80 for HTTP).\n",
    "UDP_DST (Optional): UDP destination port (e.g., 161 for SNMP).\n",
    "IN_PORT (Optional): Incoming interface port number (use in port-based forwarding).\n",
    "QUEUE (Optional): Use \"QUEUE\" with \"queueId\" to specify a QoS queue (queue ID is an integer, 0 is default).\n",
    "OUTPUT (Optional): \"OUTPUT\" with \"port\" specifies the output port.\n",
    "VLAN_ID (Optional): Use \"L2MODIFICATION\" with \"subtype\": \"VLAN_ID\" and \"vlanId\" to set a VLAN tag.\n",
    "\n",
    "Rules for Translation\n",
    "Each \"priority\" must be unique.\n",
    "Set priority high (e.g., 1000) for queue-related rules.\n",
    "Do not include VLAN-related fields unless explicitly mentioned in the intent.\n",
    "Do not include optional fields unless explicitly mentioned in the intent.\n",
    "Ensure valid ONOS-compliant JSON syntax.\n",
    "Verify JSON structure before responding.\n",
    "Always respond in valid JSON format only, without comments, explanations, or additional text.\n",
    "If the intent cannot be mapped, return an empty JSON object {}.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_switch_id_ONOS(intent: str):\n",
    "    \"\"\"\n",
    "    Extract the switch ID from a natural language intent for ONOS JSON format.\n",
    "    \n",
    "    Parameters:\n",
    "        intent (str): The natural language intent.\n",
    "    \n",
    "    Returns:\n",
    "        str: Extracted switch ID in ONOS format (e.g., 'of:0000000000000001') or None if not found.\n",
    "    \"\"\"\n",
    "    # Mapping of ordinal words to numeric values\n",
    "    ordinals = {\n",
    "        \"first\": 1,\n",
    "        \"second\": 2,\n",
    "        \"third\": 3,\n",
    "        \"fourth\": 4,\n",
    "        \"fifth\": 5,\n",
    "        \"sixth\": 6,\n",
    "        \"seventh\": 7,\n",
    "        \"eighth\": 8,\n",
    "        \"ninth\": 9,\n",
    "        \"tenth\": 10\n",
    "    }\n",
    "\n",
    "    # Match patterns like 'openflow:1' (convert from OpenFlow to ONOS format)\n",
    "    match = re.search(r'openflow[:\\s](\\d+)', intent, re.IGNORECASE)\n",
    "    if match:\n",
    "        switch_number = int(match.group(1))\n",
    "        return f\"of:{switch_number:016x}\"  # Convert to ONOS 16-digit hex format\n",
    "\n",
    "    # Match patterns like 'switch 1', 'router 2', 'node 3'\n",
    "    match = re.search(r'\\b(?:switch|router|node|openflow|device)(?:\\s*number)?\\s*(\\d+)', intent, re.IGNORECASE)\n",
    "    if match:\n",
    "        switch_number = int(match.group(1))\n",
    "        return f\"of:{switch_number:016x}\"  # Convert to ONOS 16-digit hex format\n",
    "\n",
    "    # Match ordinal words (e.g., 'fourth switch', 'second router')\n",
    "    match = re.search(r'\\b(?:switch|router|node|openflow|device)\\s*(\\w+)', intent, re.IGNORECASE)\n",
    "    if match:\n",
    "        ordinal_word = match.group(1).lower()\n",
    "        if ordinal_word in ordinals:\n",
    "            switch_number = ordinals[ordinal_word]\n",
    "            return f\"of:{switch_number:016x}\"  # Convert to ONOS 16-digit hex format\n",
    "\n",
    "    # Match standalone ordinal words (e.g., 'fourth' without 'switch')\n",
    "    for word, number in ordinals.items():\n",
    "        if word in intent.lower():\n",
    "            return f\"of:{number:016x}\"  # Convert to ONOS 16-digit hex format\n",
    "\n",
    "    return None\n",
    "\n",
    "def normalize_value(value):\n",
    "    \"\"\"Normalize numeric values, including hex representations, for fair comparison.\"\"\"\n",
    "    if isinstance(value, str):\n",
    "        # Handle hex values (like '0x0800' vs '0x800')\n",
    "        if value.lower().startswith(\"0x\"):\n",
    "            return f\"0x{int(value, 16):x}\"  # Convert to int, then back to lowercase hex\n",
    "        # Convert numeric strings to integers\n",
    "        elif value.isdigit():\n",
    "            return int(value)\n",
    "    return value\n",
    "\n",
    "def dict_equal_ignore_order(d1, d2, ignore_fields=set()):\n",
    "    \"\"\"Recursively compare dictionaries ignoring order and normalizing numeric & hex fields.\"\"\"\n",
    "\n",
    "    if isinstance(d1, dict) and isinstance(d2, dict):\n",
    "        keys1 = set(d1.keys()) - ignore_fields\n",
    "        keys2 = set(d2.keys()) - ignore_fields\n",
    "\n",
    "        if keys1 != keys2:\n",
    "            #print(f\" Mismatch in keys!\\nExpected Keys: {keys1}\\nActual Keys: {keys2}\")\n",
    "            return False  \n",
    "\n",
    "        for k in keys1:\n",
    "            if not dict_equal_ignore_order(normalize_value(d1[k]), normalize_value(d2[k]), ignore_fields):\n",
    "                #print(f\" Value Mismatch in Key: {k}\\nExpected: {d1[k]}\\nActual: {d2[k]}\")\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    elif isinstance(d1, list) and isinstance(d2, list):\n",
    "        # Normalize each item inside the lists before comparison\n",
    "        normalized_d1 = sorted([normalize_value(item) if not isinstance(item, dict) \n",
    "                                else {k: normalize_value(v) for k, v in item.items()} for item in d1], key=str)\n",
    "        normalized_d2 = sorted([normalize_value(item) if not isinstance(item, dict) \n",
    "                                else {k: normalize_value(v) for k, v in item.items()} for item in d2], key=str)\n",
    "\n",
    "        if normalized_d1 != normalized_d2:  \n",
    "            #print(f\" List Mismatch!\\nExpected: {normalized_d1}\\nActual: {normalized_d2}\")\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    else:\n",
    "        # Direct value comparison with normalization\n",
    "        if normalize_value(d1) != normalize_value(d2):  \n",
    "            #print(f\" Primitive Value Mismatch!\\nExpected: {d1}\\nActual: {d2}\")\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "def compare_onos_json(expected_json, actual_json):\n",
    "    \"\"\"\n",
    "    Compare expected ONOS JSON with actual ONOS JSON from LLM output.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if translation is correct, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define fields that must match exactly (excluding priority)\n",
    "    exact_match_fields = [\"deviceId\", \"isPermanent\", \"treatment\", \"selector\"]\n",
    "\n",
    "    # Define fields to ignore completely (EXCLUDING priority and timeout)\n",
    "    ignore_fields = {\"id\", \"appId\", \"life\", \"packets\", \"bytes\", \"lastSeen\", \"groupId\", \"liveType\", \"state\"}\n",
    "\n",
    "    #  Deep copy the JSONs before modifying\n",
    "    expected_json = copy.deepcopy(expected_json)\n",
    "    actual_json = copy.deepcopy(actual_json)\n",
    "\n",
    "    #print(\"\\n BEFORE CLEANING:\")\n",
    "    #print(\"Expected JSON:\", expected_json)\n",
    "    #print(\"Actual JSON:\", actual_json)\n",
    "\n",
    "    #  Remove ignored fields from both JSONs (priority and timeout are NOT removed)\n",
    "    def clean_json(json_obj):\n",
    "        for flow in json_obj.get(\"flows\", []):\n",
    "            for field in ignore_fields:\n",
    "                flow.pop(field, None)\n",
    "        return json_obj\n",
    "\n",
    "    expected_json = clean_json(expected_json)\n",
    "    actual_json = clean_json(actual_json)\n",
    "\n",
    "    #print(\"\\n AFTER CLEANING:\")\n",
    "    #print(\"Expected JSON:\", expected_json)\n",
    "    #print(\"Actual JSON:\", actual_json)\n",
    "\n",
    "    # Normalize all numbers in both JSONs before comparison\n",
    "    def normalize_json(json_obj):\n",
    "        for flow in json_obj.get(\"flows\", []):\n",
    "            for key in [\"priority\", \"timeout\"]:  # Normalize relevant numeric fields\n",
    "                if key in flow:\n",
    "                    flow[key] = int(flow[key]) if isinstance(flow[key], str) and flow[key].isdigit() else flow[key]\n",
    "            if \"treatment\" in flow:\n",
    "                for action in flow[\"treatment\"].get(\"instructions\", []):\n",
    "                    if \"port\" in action:\n",
    "                        action[\"port\"] = int(action[\"port\"]) if isinstance(action[\"port\"], str) and action[\"port\"].isdigit() else action[\"port\"]\n",
    "            if \"selector\" in flow:\n",
    "                for criterion in flow[\"selector\"].get(\"criteria\", []):\n",
    "                    if \"port\" in criterion:\n",
    "                        criterion[\"port\"] = int(criterion[\"port\"]) if isinstance(criterion[\"port\"], str) and criterion[\"port\"].isdigit() else criterion[\"port\"]\n",
    "        return json_obj\n",
    "\n",
    "    expected_json = normalize_json(expected_json)\n",
    "    actual_json = normalize_json(actual_json)\n",
    "\n",
    "    #  Separate Check: Ensure \"priority\" exists and is a valid number (but do not require an exact match)\n",
    "    for flow in actual_json.get(\"flows\", []):\n",
    "        if (\"priority\" not in flow) or (not isinstance(flow[\"priority\"], (int, str))):\n",
    "            #print(\" Priority Missing or Invalid!\")\n",
    "            return False  #  Fail if priority is missing or invalid\n",
    "\n",
    "    #  Strictly check timeout field (must match exactly)\n",
    "    for flow in actual_json.get(\"flows\", []):\n",
    "        expected_timeout = expected_json[\"flows\"][0].get(\"timeout\", 0)\n",
    "        actual_timeout = flow.get(\"timeout\", 0)\n",
    "\n",
    "        if expected_timeout != actual_timeout:\n",
    "            #print(f\" Timeout Mismatch!\\nExpected: {expected_timeout}\\nActual: {actual_timeout}\")\n",
    "            return False  #  Timeout must match exactly\n",
    "\n",
    "    #  Strictly compare exact match fields, ignoring priority\n",
    "    for field in exact_match_fields:\n",
    "        if field in expected_json[\"flows\"][0] and field in actual_json[\"flows\"][0]:\n",
    "            #print(f\"\\n Comparing Field: {field}\")\n",
    "            if not dict_equal_ignore_order(expected_json[\"flows\"][0][field], actual_json[\"flows\"][0][field], ignore_fields):\n",
    "                #print(f\" Mismatch in Field: {field}\")\n",
    "                return False  #  Fail if any exact match field differs\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected_json = {'flows': [{'priority': 80, 'timeout': 0, 'isPermanent': 'true', 'deviceId': 'of:0000000000000004', 'treatment': {'instructions': [{'type': 'OUTPUT', 'port': '1'}]}, 'selector': {'criteria': [{'type': 'ETH_TYPE', 'ethType': '0x800'}]}}]}\n",
    "# actual_json = {'flows': [{'priority': '', 'timeout': '0', 'isPermanent': 'true', 'deviceId': 'of:0000000000000004', 'treatment': {'instructions': [{'type': 'OUTPUT', 'port': 1}]}, 'selector': {'criteria': [{'type': 'ETH_TYPE', 'ethType': '0x800'}]}}]}\n",
    "\n",
    "# print(compare_onos_json(expected_json, actual_json))  # ✅ Should return True\n",
    "\n",
    "# expected_json = {'flows': [{'priority': 102, 'timeout': 0, 'isPermanent': 'true', 'deviceId': 'of:0000000000000001', 'treatment': {'instructions': [{'type': 'OUTPUT', 'port': '3'}]}, 'selector': {'criteria': [{'type': 'ETH_TYPE', 'ethType': '0x0800'}, {'type': 'IP_PROTO', 'protocol': 1}, {'type': 'IPV4_DST', 'ip': '10.0.0.1/32'}]}}]}\n",
    "# actual_json = {'flows': [{'priority': '501', 'timeout': '0', 'isPermanent': 'true', 'deviceId': 'of:0000000000000001', 'treatment': {'instructions': [{'type': 'OUTPUT', 'port': 3}]}, 'selector': {'criteria': [{'type': 'ETH_TYPE', 'ethType': '0x0800'}, {'type': 'IP_PROTO', 'protocol': '1'}, {'type': 'IPV4_DST', 'ip': '10.0.0.1/32'}]}}]}\n",
    "\n",
    "# print(compare_onos_json(expected_json, actual_json))  # ✅ Should return True\n",
    "\n",
    "# expected_json = {'flows': [{'priority': 110, 'timeout': 0, 'isPermanent': 'true', 'deviceId': 'of:0000000000000001', 'treatment': {'instructions': [{'type': 'OUTPUT', 'port': '2'}]}, 'selector': {'criteria': [{'type': 'ETH_TYPE', 'ethType': '0x800'}, {'type': 'IPV4_DST', 'ip': '10.0.0.3/32'}, {'type': 'IP_PROTO', 'protocol': 6}, {'type': 'TCP_DST', 'tcpPort': 80}]}}]}\n",
    "# actual_json = {'flows': [{'priority': 150, 'timeout': 0, 'isPermanent': 'true', 'deviceId': 'of:0000000000000001', 'treatment': {'instructions': [{'type': 'OUTPUT', 'port': '2'}]}, 'selector': {'criteria': [{'type': 'ETH_TYPE', 'ethType': '0x800'}, {'type': 'IP_PROTO', 'protocol': 6}, {'type': 'TCP_DST', 'tcpPort': 80}, {'type': 'IPV4_DST', 'ip': '10.0.0.3/32'}]}}]}\n",
    "\n",
    "# print(compare_onos_json(expected_json, actual_json))  # ✅ Should return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_models_real = [\n",
    "\"marco-o1\",\n",
    "\"mistral\",\n",
    "\"mistral-nemo\",\n",
    "\"deepseek-coder\",\n",
    "\"starcoder\", \n",
    "\"codegemma\",\n",
    "\"starcoder2\",\n",
    "\"openchat\",\n",
    "\"phi3\",\n",
    "\"dolphin-mistral\",\n",
    "\"wizardlm2\",\n",
    "\"phi\",\n",
    "\"yi\",\n",
    "\"zephyr\",\n",
    "\"command-r\",\n",
    "\"llava-llama3\",\n",
    "\"codestral\",\n",
    "\"codellama:34b\",\n",
    "\"codellama\",\n",
    "\"llama2\",\n",
    "\"llama3\",\n",
    "\"llama3.1\",\n",
    "\"llama3.2\",\n",
    "\"qwen\",\n",
    "\"qwen2\",\n",
    "\"qwen2.5\",\n",
    "\"gemma2:27b\",\n",
    "\"huihui_ai/qwq-abliterated\",\n",
    "\"huihui_ai/qwq-fusion\",\n",
    "\"qwq\",\n",
    "\"llama3.3\",\n",
    "\"llama2:70b\",\n",
    "\"codellama:70b\"\n",
    "]\n",
    "\n",
    "default_model = \"llama2\"\n",
    "\n",
    "num_context_examples = [0,1,3,6,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_embedding_url = \"http://localhost:11434\"\n",
    "ollama_server_url = \"http://localhost:11435\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_emb = OllamaEmbeddings(\n",
    "    model=default_model,\n",
    "    base_url=ollama_embedding_url,\n",
    ")\n",
    "\n",
    "client = Client(host=ollama_server_url , timeout=120)\n",
    "\n",
    "# Load custom dataset from CSV\n",
    "custom_dataset = pd.read_csv('ONOS_intent_translation_dataset_for_LLM_Evaluation.csv') #dataset for intent translation task.\n",
    "\n",
    "# Ensure proper column names and format\n",
    "if not {'instruction', 'output'}.issubset(custom_dataset.columns):\n",
    "    raise ValueError(\"The dataset must have 'instruction' and 'output' columns.\")\n",
    "\n",
    "# Split into train and test (50/50 split for example)\n",
    "trainset, testset = train_test_split(custom_dataset, test_size=0.5, random_state=42, shuffle=True)\n",
    "\n",
    "# SYSTEM PROMPT (Manually define)\n",
    "SYSTEM_PROMPT = TRANSLATION_PROMPT_ONOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = f\"Intent_translation_accuracies_ONOS_{int(time.time())}.csv\"\n",
    "output_file = f\"Intent_translation_details_ONOS_{int(time.time())}.txt\"\n",
    "# Open the file in write mode\n",
    "file = open(output_file, \"w\")  # Use \"w\" for write mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for num_examples in num_context_examples:\n",
    "    for model in my_models_real:\n",
    "\n",
    "        correct_translations = 0\n",
    "        total_samples = len(testset)\n",
    "        processing_times = []\n",
    "\n",
    "        # create example selector with one example, then clear the data and add all examples\n",
    "        # this is a trick to reset data and remove data from continuous learning in previous run\n",
    "        example_selector = MaxMarginalRelevanceExampleSelector.from_examples(\n",
    "            [{\"instruction\": trainset.iloc[0][\"instruction\"], \"output\": trainset.iloc[0][\"output\"]}],\n",
    "            ollama_emb,\n",
    "            Chroma,\n",
    "            input_keys=[\"instruction\"],\n",
    "            k=num_examples,\n",
    "            vectorstore_kwargs={\"fetch_k\": min(num_examples, len(trainset))}\n",
    "            )\n",
    "\n",
    "        # Clear and add all remaining examples from the trainset\n",
    "        example_selector.vectorstore.reset_collection()\n",
    "        for _, row in trainset.iterrows():\n",
    "            example_selector.add_example({\n",
    "                \"instruction\": row[\"instruction\"],\n",
    "                \"output\": row[\"output\"]\n",
    "            })\n",
    "\n",
    "        for _, testcase in testset.iterrows():\n",
    "            intent = testcase[\"instruction\"]\n",
    "            expected_output = testcase[\"output\"]\n",
    "            system_prompt = SYSTEM_PROMPT\n",
    "            count = 0\n",
    "            while True:\n",
    "                count+=1\n",
    "                try:\n",
    "                    time.sleep(0.1)\n",
    "                    current_time = time.time()\n",
    "                    if num_examples > 0:\n",
    "                        examples = example_selector.select_examples({\"instruction\": intent})\n",
    "                        example_str = \"\\n\\n\\n\".join(map(lambda x: \"Input: \" + x[\"instruction\"] + \"\\n\\nOutput: \" + x[\"output\"], examples))\n",
    "                        system_prompt += example_str + \"\\n\\n\\n\"  \n",
    "                    \n",
    "                    response = client.generate(\n",
    "                        model=model,\n",
    "                        options={\n",
    "                            'temperature': 0.6,\n",
    "                            'num_ctx': 8192,\n",
    "                            'top_p': 0.3,\n",
    "                            'num_predict': 1024,\n",
    "                            'num_gpu': 99,\n",
    "                            },\n",
    "                        stream=False,\n",
    "                        system=system_prompt,\n",
    "                        prompt=intent,\n",
    "                        format='json'\n",
    "                    )\n",
    "                    actual_output = response['response']\n",
    "                    proc_time_s = (time.time() - current_time)\n",
    "                    processing_times.append(proc_time_s)\n",
    "                    break\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error in generating translation for {model} with {num_examples} examples: {e}\") \n",
    "                    sys.stdout.flush()\n",
    "                    \n",
    "                    if(count<15):\n",
    "                        continue\n",
    "                    else:\n",
    "                        print(\"\\n\",model, \" failed to produce valid JSON for translation info after 15 tries. Going to next model\\n\")\n",
    "                        break\n",
    "\n",
    "            try:\n",
    "                expected_output = json.loads(expected_output)\n",
    "                actual_output = json.loads(actual_output)\n",
    "\n",
    "                device_id = extract_switch_id_ONOS(intent)\n",
    "                \n",
    "                for flow in actual_output.get(\"flows\", []):  # Iterate over all flows\n",
    "                    flow[\"deviceId\"] = device_id  # Replace the device ID\n",
    "\n",
    "                # Check correctness\n",
    "                if compare_onos_json(expected_output, actual_output):\n",
    "                    correct_translations += 1            \n",
    "\n",
    "                file.write(f\"Input: {intent}\")\n",
    "                file.write(\"\\nExpected Output\\n\")\n",
    "                file.write(f\"Expected: {expected_output}\")\n",
    "                file.write(\"\\nActual Output\\n\")\n",
    "                file.write(f\"Actual: {actual_output}\")\n",
    "\n",
    "                # Write the first output\n",
    "                file.write(f\"\\nResult: model: {model}, num context examples: {num_examples}, processing time: {round(proc_time_s, 2)}\\n\")\n",
    "                # Write the second output\n",
    "                file.write(f\"Diff: {jsondiff.diff(expected_output, actual_output)}\\n\\n\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"Exception found in post-translation processing: \", e)\n",
    "\n",
    "            print(\"========End of a testcase===========\\n\")\n",
    "        print(\"\\n************Next MODEL***********\")\n",
    "        file.write(f\"*************************Next MODEL*************************\\n\\n\")\n",
    "\n",
    "        # Compute accuracy\n",
    "        accuracy = round((correct_translations / total_samples) * 100, 2)\n",
    "        avg_time = round(sum(processing_times) / total_samples, 2)\n",
    "\n",
    "        # Store results\n",
    "        results.append({\n",
    "            \"model\": model,\n",
    "            \"context_example\": num_examples,\n",
    "            \"num_test_samples\": total_samples,\n",
    "            \"correct_translations\": correct_translations,\n",
    "            \"accuracy (%)\": accuracy,\n",
    "            \"avg_time_per_translation (s)\": avg_time\n",
    "            })\n",
    "\n",
    "# Save to CSV\n",
    "pd.DataFrame(results).to_csv(csv_file, mode='a', header=not os.path.exists(csv_file), index=False) \n",
    "\n",
    "\n",
    "# Close the file explicitly\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onos_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
